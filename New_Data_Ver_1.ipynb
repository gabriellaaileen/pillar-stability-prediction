{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOV019gxgRkGnd1uvLT13zg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabriellaaileen/pillar-stability-prediction/blob/main/New_Data_Ver_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Requirements**"
      ],
      "metadata": {
        "id": "zOwTXp6JvuNG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "40Vwm6YLQVyo"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, Bidirectional\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow import nn\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "fWUwFrLYVn1V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P data/ https://raw.githubusercontent.com/gabriellaaileen/pillar-stability-prediction/main/\"Relabel SF6.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJvso9XNwybh",
        "outputId": "9c736869-883e-455e-e376-77f23ecc5c0e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-12 13:59:36--  https://raw.githubusercontent.com/gabriellaaileen/pillar-stability-prediction/main/Relabel%20SF6.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12591 (12K) [text/plain]\n",
            "Saving to: ‘data/Relabel SF6.csv’\n",
            "\n",
            "\rRelabel SF6.csv       0%[                    ]       0  --.-KB/s               \rRelabel SF6.csv     100%[===================>]  12.30K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-09-12 13:59:36 (73.9 MB/s) - ‘data/Relabel SF6.csv’ saved [12591/12591]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/data/Relabel SF6.csv')"
      ],
      "metadata": {
        "id": "2ON_hw__13t5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Exploratory Data Analysis**"
      ],
      "metadata": {
        "id": "JCrrhwPQ2HLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JhNPeWT72K5N",
        "outputId": "a2c44dbc-fe2e-484c-8beb-353e78633268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Depth    BW     PW    MH     Ratio Stability Relabel_6\n",
              "0   76.2  6.10   4.88  1.37  3.562044    Failed    Failed\n",
              "1   87.8  6.10   6.10  1.98  3.080808    Failed    Failed\n",
              "2   55.5  6.62   7.43  3.80  1.955263    Failed    Failed\n",
              "3   78.2  6.47  10.53  5.16  2.040698    Failed    Failed\n",
              "4   73.5  6.60   8.40  3.65  2.301370    Failed    Failed"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04a6ac9a-1044-4b15-b454-0718ceb5fca4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Depth</th>\n",
              "      <th>BW</th>\n",
              "      <th>PW</th>\n",
              "      <th>MH</th>\n",
              "      <th>Ratio</th>\n",
              "      <th>Stability</th>\n",
              "      <th>Relabel_6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>76.2</td>\n",
              "      <td>6.10</td>\n",
              "      <td>4.88</td>\n",
              "      <td>1.37</td>\n",
              "      <td>3.562044</td>\n",
              "      <td>Failed</td>\n",
              "      <td>Failed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>87.8</td>\n",
              "      <td>6.10</td>\n",
              "      <td>6.10</td>\n",
              "      <td>1.98</td>\n",
              "      <td>3.080808</td>\n",
              "      <td>Failed</td>\n",
              "      <td>Failed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>55.5</td>\n",
              "      <td>6.62</td>\n",
              "      <td>7.43</td>\n",
              "      <td>3.80</td>\n",
              "      <td>1.955263</td>\n",
              "      <td>Failed</td>\n",
              "      <td>Failed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>78.2</td>\n",
              "      <td>6.47</td>\n",
              "      <td>10.53</td>\n",
              "      <td>5.16</td>\n",
              "      <td>2.040698</td>\n",
              "      <td>Failed</td>\n",
              "      <td>Failed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>73.5</td>\n",
              "      <td>6.60</td>\n",
              "      <td>8.40</td>\n",
              "      <td>3.65</td>\n",
              "      <td>2.301370</td>\n",
              "      <td>Failed</td>\n",
              "      <td>Failed</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04a6ac9a-1044-4b15-b454-0718ceb5fca4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-04a6ac9a-1044-4b15-b454-0718ceb5fca4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-04a6ac9a-1044-4b15-b454-0718ceb5fca4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzQVwS9a2Pnm",
        "outputId": "73cd9abe-80a3-4a86-8165-5a713a2115b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(290, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSjO5wv42S2h",
        "outputId": "8bcdb05c-f023-4fa8-88aa-37ab71d2ac79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 290 entries, 0 to 289\n",
            "Data columns (total 7 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   Depth      290 non-null    float64\n",
            " 1   BW         290 non-null    float64\n",
            " 2   PW         290 non-null    float64\n",
            " 3   MH         290 non-null    float64\n",
            " 4   Ratio      290 non-null    float64\n",
            " 5   Stability  290 non-null    object \n",
            " 6   Relabel_6  290 non-null    object \n",
            "dtypes: float64(5), object(2)\n",
            "memory usage: 16.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Menghitung presentase missing values dari masing-masing variabel\n",
        "(df.isnull().sum()/len(df)*100).to_frame('Persentase Missing Value Dataset (%)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "E8pCTb9L3EIA",
        "outputId": "6eba7237-f4e4-4dae-8ae2-8269dd42e98b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Persentase Missing Value Dataset (%)\n",
              "Depth                                       0.0\n",
              "BW                                          0.0\n",
              "PW                                          0.0\n",
              "MH                                          0.0\n",
              "Ratio                                       0.0\n",
              "Stability                                   0.0\n",
              "Relabel_6                                   0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5fa57066-80b8-428a-b5d7-264d5b910fc5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Persentase Missing Value Dataset (%)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Depth</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BW</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PW</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MH</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ratio</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stability</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Relabel_6</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5fa57066-80b8-428a-b5d7-264d5b910fc5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5fa57066-80b8-428a-b5d7-264d5b910fc5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5fa57066-80b8-428a-b5d7-264d5b910fc5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "t38-aeGa3Ikf",
        "outputId": "5b787e18-0c3f-4864-9000-c7ecd6b568a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Depth          BW          PW          MH       Ratio\n",
              "count  290.000000  290.000000  290.000000  290.000000  290.000000\n",
              "mean    77.193448    6.039379   10.359483    2.845724    4.086694\n",
              "std     46.767135    0.590025    5.269283    1.093174    2.520439\n",
              "min     13.220000    3.690000    2.910000    1.000000    0.866521\n",
              "25%     41.025000    5.840000    6.160000    2.000000    2.377593\n",
              "50%     62.490000    6.000000    9.140000    2.800000    3.422189\n",
              "75%    101.157500    6.300000   12.800000    3.500000    5.009494\n",
              "max    223.380000    8.530000   35.000000    6.200000   16.190476"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-517ea190-94df-4833-a942-99c081200ad7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Depth</th>\n",
              "      <th>BW</th>\n",
              "      <th>PW</th>\n",
              "      <th>MH</th>\n",
              "      <th>Ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>290.000000</td>\n",
              "      <td>290.000000</td>\n",
              "      <td>290.000000</td>\n",
              "      <td>290.000000</td>\n",
              "      <td>290.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>77.193448</td>\n",
              "      <td>6.039379</td>\n",
              "      <td>10.359483</td>\n",
              "      <td>2.845724</td>\n",
              "      <td>4.086694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>46.767135</td>\n",
              "      <td>0.590025</td>\n",
              "      <td>5.269283</td>\n",
              "      <td>1.093174</td>\n",
              "      <td>2.520439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>13.220000</td>\n",
              "      <td>3.690000</td>\n",
              "      <td>2.910000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.866521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>41.025000</td>\n",
              "      <td>5.840000</td>\n",
              "      <td>6.160000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.377593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>62.490000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>9.140000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>3.422189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>101.157500</td>\n",
              "      <td>6.300000</td>\n",
              "      <td>12.800000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>5.009494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>223.380000</td>\n",
              "      <td>8.530000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>6.200000</td>\n",
              "      <td>16.190476</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-517ea190-94df-4833-a942-99c081200ad7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-517ea190-94df-4833-a942-99c081200ad7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-517ea190-94df-4833-a942-99c081200ad7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.groupby(['Relabel_6']).agg({\"Relabel_6\": \"count\"}), end=\"\\n\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKwt2csJJhqO",
        "outputId": "190f7c03-ddba-404f-b753-0cb70b45226d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Relabel_6\n",
            "Relabel_6           \n",
            "Failed            65\n",
            "Intact           195\n",
            "Unstable          30\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.io as pio\n",
        "import plotly.express as px\n",
        "import plotly.offline as py\n",
        "\n",
        "fig = px.scatter(df, x=\"Depth\", y=\"PW\", color=\"Stability\", size=\"BW\")\n",
        "fig"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "nvuXxO1t389g",
        "outputId": "41662c24-3a43-4ab9-f1ee-ca6f37e82de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"8f58586c-a0ed-4599-8544-eaaecfa8e3da\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8f58586c-a0ed-4599-8544-eaaecfa8e3da\")) {                    Plotly.newPlot(                        \"8f58586c-a0ed-4599-8544-eaaecfa8e3da\",                        [{\"hovertemplate\":\"Stability=Failed<br>Depth=%{x}<br>PW=%{y}<br>BW=%{marker.size}<extra></extra>\",\"legendgroup\":\"Failed\",\"marker\":{\"color\":\"#636efa\",\"size\":[6.1,6.1,6.62,6.47,6.6,5.66,5.0,6.0,6.0,5.49,5.49,5.49,7.62,7.62,6.0,6.5,6.6,6.0,6.45,6.48,5.5,6.0,5.5,5.49,6.4,6.1,6.7,6.7,6.0,5.4,6.4,6.2,6.5,6.1,6.1,6.4,6.4,6.4,6.4,6.5,6.2,6.5,6.2,6.1,7.62,7.62,6.4,8.53,8.23,7.01,7.92,7.62,6.71,7.62,6.4,5.79,6.55,6.4,6.86,6.4,5.5,5.8,6.4,6.0,5.0,6.1,6.0],\"sizemode\":\"area\",\"sizeref\":0.021324999999999997,\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"Failed\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[76.2,87.8,55.5,78.2,73.5,57.66,165.7,195.0,205.0,167.6,193.2,184.7,36.6,62.5,101.0,100.0,97.0,51.5,112.0,108.0,112.0,96.0,128.0,128.0,57.9,152.4,34.0,34.0,90.0,57.0,62.0,62.0,56.0,62.0,62.0,41.0,41.0,41.0,32.0,32.5,43.0,86.4,102.0,61.0,61.0,57.9,41.1,25.9,21.3,29.6,27.4,36.6,33.5,30.5,53.3,68.6,88.4,57.9,61.0,30.5,42.0,28.5,33.0,104.0,74.0,53.0,88.0],\"xaxis\":\"x\",\"y\":[4.88,6.1,7.43,10.53,8.4,5.3,15.0,17.0,17.0,15.85,15.85,15.85,6.1,6.1,9.0,8.5,9.0,6.0,10.55,10.55,11.5,12.0,12.8,9.75,5.18,12.19,3.5,3.5,7.5,3.6,7.5,7.3,5.1,6.1,6.1,6.4,6.4,6.4,3.3,3.2,4.8,7.5,7.6,6.1,6.1,6.1,4.27,3.66,3.96,5.18,3.66,4.57,6.1,4.57,5.18,3.35,7.16,5.18,4.72,3.35,4.5,3.8,6.4,12.0,10.0,5.6,11.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Stability=Intact<br>Depth=%{x}<br>PW=%{y}<br>BW=%{marker.size}<extra></extra>\",\"legendgroup\":\"Intact\",\"marker\":{\"color\":\"#EF553B\",\"size\":[5.49,6.1,5.49,6.43,6.0,6.26,6.15,5.0,6.0,6.0,6.0,6.0,6.19,6.0,6.29,6.06,5.98,6.11,7.63,7.11,6.89,5.07,5.68,5.21,5.38,4.97,5.22,5.18,5.08,5.7,5.52,6.36,6.3,6.25,6.17,6.16,5.96,6.54,5.5,5.23,5.37,6.54,6.12,6.13,6.2,6.08,5.74,5.94,6.82,6.65,6.0,5.05,5.86,5.62,6.0,5.18,6.0,6.0,6.0,6.0,5.6,6.0,6.0,6.0,6.0,5.49,6.1,6.71,6.0,6.0,5.49,5.49,5.49,5.49,6.1,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,5.0,5.0,6.1,6.1,5.7,6.0,6.0,6.2,6.02,6.11,6.34,6.4,5.69,6.13,6.08,6.0,4.88,6.4,6.1,6.1,6.1,5.49,6.0,5.0,5.0,5.49,6.0,6.0,6.0,6.1,6.0,6.0,6.0,6.02,6.0,6.0,6.0,6.0,6.1,5.49,6.1,6.1,4.88,6.0,6.1,5.0,6.0,6.0,6.0,6.0,5.0,5.0,5.0,6.0,6.71,6.4,6.4,6.0,6.0,6.43,6.35,6.04,5.49,6.0,6.0,6.0,6.0,5.84,6.0,5.84,6.35,5.49,5.49,6.6,6.6,5.49,6.0,6.0,6.0,6.0,6.0,7.1,6.32,5.96,6.0,6.0,6.48,6.93,6.71,6.71,3.69,5.49,5.49,6.0,6.0,5.0,5.89,5.89,5.73,6.18,6.0,6.0,6.93,6.0,6.1,6.32,6.81,5.0,5.0,5.0,6.1,6.0,6.0,6.0,7.5,5.53,5.09,6.08,5.49,6.37,5.49,5.49,5.99,6.38,6.0,7.11,6.65,6.3,6.3,6.1,5.0,7.0],\"sizemode\":\"area\",\"sizeref\":0.021324999999999997,\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"Intact\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[140.21,91.44,106.68,167.68,170.0,154.0,151.0,215.05,178.49,195.15,203.42,203.42,169.0,138.89,146.2,30.35,41.35,63.15,40.86,30.55,47.07,42.61,23.0,23.76,23.54,26.75,19.4,20.8,23.33,58.89,33.94,39.1,36.5,24.15,25.7,18.58,21.5,54.0,112.0,98.15,64.79,25.15,35.73,55.7,22.62,28.75,22.3,37.7,36.26,37.08,39.33,64.24,59.98,17.91,29.56,45.72,108.0,174.0,64.47,50.0,34.6,55.75,55.75,34.15,36.53,45.72,76.2,30.48,63.64,70.79,60.96,114.0,91.44,114.0,39.62,62.48,62.48,62.48,70.0,40.07,40.07,83.43,44.55,44.55,40.3,37.36,70.76,61.5,61.5,58.71,58.71,94.28,94.28,51.82,48.77,50.0,59.3,64.92,55.0,65.0,51.0,68.0,46.0,74.0,68.0,54.0,93.8,36.58,48.77,45.72,60.96,76.2,33.53,70.0,70.0,70.0,38.1,79.4,138.89,79.4,30.48,42.8,67.8,36.3,51.8,68.9,33.8,52.8,52.8,91.44,35.05,50.6,76.2,35.05,22.0,19.81,29.77,58.53,58.53,42.59,13.22,65.78,54.65,54.99,70.1,21.34,30.48,41.15,78.54,78.54,49.0,51.0,97.27,121.92,108.0,208.0,208.0,166.0,77.65,108.75,137.0,106.0,146.3,93.88,122.0,122.0,143.26,101.21,114.35,119.41,130.75,108.63,68.0,70.0,77.0,93.8,93.8,109.0,92.28,122.0,122.0,167.64,140.21,146.0,83.92,87.6,110.5,84.0,84.0,124.9,110.0,82.0,67.8,183.83,150.0,106.68,165.45,171.7,223.38,173.22,215.05,91.44,111.91,140.72,114.3,106.0,25.98,26.83,39.95,42.67,54.6,68.58,91.44,57.34,52.5,87.53,72.0,57.0,75.0,78.0,45.72,110.5,38.0],\"xaxis\":\"x\",\"y\":[12.8,7.62,6.71,12.98,22.0,21.37,23.85,35.0,19.0,20.0,19.0,19.0,21.81,17.78,19.89,8.96,8.0,8.02,7.55,8.07,8.29,4.38,4.0,4.3,4.24,4.54,4.26,4.24,4.37,8.06,8.17,6.63,7.25,6.1,6.15,4.86,5.09,6.0,17.0,12.56,13.03,4.39,5.0,6.85,4.8,5.0,6.24,7.05,6.23,6.29,8.05,5.59,6.19,4.31,6.2,5.49,9.0,17.0,9.0,10.0,12.21,10.28,11.0,8.0,7.0,4.27,7.62,5.49,14.0,12.0,9.75,12.8,12.8,17.37,6.1,10.0,15.0,9.0,15.0,8.0,7.5,12.0,12.0,12.0,8.0,10.0,14.0,9.47,9.26,11.0,7.0,10.0,10.0,9.14,9.14,9.3,11.0,20.57,11.8,10.98,8.89,11.66,8.6,11.31,10.87,8.92,14.92,7.32,7.32,6.1,7.62,9.14,6.71,12.0,20.57,15.44,4.27,24.0,31.06,19.47,6.1,7.0,11.73,8.0,10.98,12.9,8.0,8.0,11.3,12.19,9.75,6.1,9.14,7.32,6.0,7.62,14.0,11.42,14.0,15.0,8.0,10.0,10.0,9.47,12.0,6.1,6.4,6.4,14.0,14.0,8.57,8.65,8.63,12.8,9.0,17.0,17.0,17.0,12.0,14.0,21.82,15.84,17.37,9.75,15.4,15.4,12.8,12.0,12.0,15.0,15.0,18.5,12.9,10.68,10.04,14.0,14.7,17.5,17.07,21.0,21.2,14.33,17.37,16.46,11.47,12.0,12.0,11.0,11.5,18.27,17.82,12.0,11.0,12.99,9.0,9.14,11.66,21.19,28.0,25.0,25.0,10.67,13.4,15.0,12.0,16.47,3.11,2.91,6.89,5.49,5.67,5.18,6.1,9.07,5.66,12.0,12.89,9.35,10.7,10.7,4.88,12.0,5.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Depth\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"PW\"}},\"legend\":{\"title\":{\"text\":\"Stability\"},\"tracegroupgap\":0,\"itemsizing\":\"constant\"},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8f58586c-a0ed-4599-8544-eaaecfa8e3da');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Preprocessing**"
      ],
      "metadata": {
        "id": "x5oVRrPJ_9ht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['Stability','Ratio'], axis=1)"
      ],
      "metadata": {
        "id": "SSONvwLoPo1-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Imbalance dataset"
      ],
      "metadata": {
        "id": "Mo56jiL3JuBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = df.drop('Relabel_6', axis=1),df['Relabel_6']"
      ],
      "metadata": {
        "id": "IrYqYWE511PJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Oversampling"
      ],
      "metadata": {
        "id": "VYX9UHdFat2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example of random oversampling to balance the class distribution\n",
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler"
      ],
      "metadata": {
        "id": "3EBW5mTG4Kdi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ros = RandomOverSampler(random_state=0)\n",
        "X_resampled, y_resampled = ros.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "x-qut00e4mCI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hasil"
      ],
      "metadata": {
        "id": "r5ompXBkkVqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.concat([X_resampled, y_resampled], axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7kdDSahz5g3R",
        "outputId": "e39e68cf-6b14-423e-8492-daaf190cf7c7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Depth    BW     PW    MH Relabel_6\n",
              "0   76.2  6.10   4.88  1.37    Failed\n",
              "1   87.8  6.10   6.10  1.98    Failed\n",
              "2   55.5  6.62   7.43  3.80    Failed\n",
              "3   78.2  6.47  10.53  5.16    Failed\n",
              "4   73.5  6.60   8.40  3.65    Failed"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ba847f9-a11f-4385-97ce-5f9a2d9493b3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Depth</th>\n",
              "      <th>BW</th>\n",
              "      <th>PW</th>\n",
              "      <th>MH</th>\n",
              "      <th>Relabel_6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>76.2</td>\n",
              "      <td>6.10</td>\n",
              "      <td>4.88</td>\n",
              "      <td>1.37</td>\n",
              "      <td>Failed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>87.8</td>\n",
              "      <td>6.10</td>\n",
              "      <td>6.10</td>\n",
              "      <td>1.98</td>\n",
              "      <td>Failed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>55.5</td>\n",
              "      <td>6.62</td>\n",
              "      <td>7.43</td>\n",
              "      <td>3.80</td>\n",
              "      <td>Failed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>78.2</td>\n",
              "      <td>6.47</td>\n",
              "      <td>10.53</td>\n",
              "      <td>5.16</td>\n",
              "      <td>Failed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>73.5</td>\n",
              "      <td>6.60</td>\n",
              "      <td>8.40</td>\n",
              "      <td>3.65</td>\n",
              "      <td>Failed</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ba847f9-a11f-4385-97ce-5f9a2d9493b3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0ba847f9-a11f-4385-97ce-5f9a2d9493b3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0ba847f9-a11f-4385-97ce-5f9a2d9493b3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.groupby(['Relabel_6']).agg({\"Relabel_6\": \"count\"}), end=\"\\n\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRLkjs1R2_7y",
        "outputId": "0a58998b-febf-4d42-c110-e48d0e33464c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Relabel_6\n",
            "Relabel_6           \n",
            "Failed           195\n",
            "Intact           195\n",
            "Unstable         195\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Label Encoding"
      ],
      "metadata": {
        "id": "xDEGW3E7JxTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Split dataset menjadi feature (X) dan label (y)\n",
        "y = df['Relabel_6']\n",
        "X = df.drop(columns=['Relabel_6'])"
      ],
      "metadata": {
        "id": "gfe_Qhgo__b1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ],
      "metadata": {
        "id": "QFuZzxGaAJjF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary={}\n",
        "for i in range(len(list(le.classes_))):\n",
        "  dictionary[list(le.classes_)[i]]=i\n",
        "dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03niHLRGATeL",
        "outputId": "8fc9dfae-b1c3-4131-ae19-50b4381a8a1f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Failed': 0, 'Intact': 1, 'Unstable': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Split Dataset (Train - Val - Test)"
      ],
      "metadata": {
        "id": "SevU4vcbkiGZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train - Test Split**"
      ],
      "metadata": {
        "id": "4ww6_lfufasU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Split train dan test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)"
      ],
      "metadata": {
        "id": "ZtBSX-k3DWJA"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train - Val - Test Split**"
      ],
      "metadata": {
        "id": "p8hw-9yYfdue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In the first step we will split the data in training and remaining dataset\n",
        "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.8)\n",
        "\n",
        "# Now since we want the valid and test size to be equal (10% each of overall data). \n",
        "# we have to define valid_size=0.5 (that is 50% of remaining data)\n",
        "test_size = 0.75\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.75)"
      ],
      "metadata": {
        "id": "S_QuaSt9fdbV"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQFYybLRP8yE",
        "outputId": "e2a273b5-bea1-4772-8a71-77a97916a56b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(409, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KCB08IvfsVU",
        "outputId": "c1c2107d-1c53-4c0f-efc8-a5f7f6295e7f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdVX-ee0biZt",
        "outputId": "6216fd36-2c75-49a4-e52f-3f0190b85c93"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Build Model**"
      ],
      "metadata": {
        "id": "wuGgHL2ZDmUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adam = Adam(learning_rate=0.001)"
      ],
      "metadata": {
        "id": "v6tqFfbXUNZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Callback\n",
        "callback = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    mode='auto'\n",
        ")"
      ],
      "metadata": {
        "id": "I8TjODiSOLEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model 1 (Activation function: Linear)"
      ],
      "metadata": {
        "id": "SngpqzcnDpBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(512, input_shape=[4],activation=tf.keras.activations.linear),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.linear),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.linear),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.keras.activations.linear),\n",
        "                                    tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
        "                                    ])"
      ],
      "metadata": {
        "id": "qK4OTL56x73y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.compile(loss=SparseCategoricalCrossentropy(from_logits=False),optimizer=adam,metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "DVKMRz3FQ16Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65ec3ac3-c777-490b-eded-d102d4b9d692",
        "id": "u3usHijX2YEM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 512)               2560      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 232,963\n",
            "Trainable params: 232,963\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_1.fit(X_train, y_train, batch_size=16, epochs=400, callbacks=callback,  verbose=1)"
      ],
      "metadata": {
        "id": "xU_z2-xOfq22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_1.fit(X_train, y_train, validation_data = (X_valid,y_valid), batch_size=16, epochs=100,  verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84f0d04c-16d9-4468-b156-2b0da980e8e2",
        "id": "7alC3JPe2YEN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 15.8787 - accuracy: 0.3203 - val_loss: 7.7960 - val_accuracy: 0.3409\n",
            "Epoch 2/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2.3442 - accuracy: 0.4230 - val_loss: 1.1072 - val_accuracy: 0.5568\n",
            "Epoch 3/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.9471 - accuracy: 0.5501 - val_loss: 0.9541 - val_accuracy: 0.5114\n",
            "Epoch 4/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.8855 - accuracy: 0.6161 - val_loss: 0.7973 - val_accuracy: 0.6136\n",
            "Epoch 5/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8066 - accuracy: 0.6406 - val_loss: 1.0739 - val_accuracy: 0.4318\n",
            "Epoch 6/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.9239 - accuracy: 0.5623 - val_loss: 0.7683 - val_accuracy: 0.6023\n",
            "Epoch 7/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7001 - accuracy: 0.6919 - val_loss: 0.7156 - val_accuracy: 0.7386\n",
            "Epoch 8/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6677 - accuracy: 0.7042 - val_loss: 0.6663 - val_accuracy: 0.7500\n",
            "Epoch 9/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7013 - accuracy: 0.6528 - val_loss: 0.6729 - val_accuracy: 0.7045\n",
            "Epoch 10/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6207 - accuracy: 0.6993 - val_loss: 0.7600 - val_accuracy: 0.6818\n",
            "Epoch 11/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.7057 - accuracy: 0.6724 - val_loss: 1.2270 - val_accuracy: 0.4886\n",
            "Epoch 12/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.0006 - accuracy: 0.5819 - val_loss: 0.9800 - val_accuracy: 0.5795\n",
            "Epoch 13/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7501 - accuracy: 0.6846 - val_loss: 0.7515 - val_accuracy: 0.6364\n",
            "Epoch 14/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6233 - accuracy: 0.7359 - val_loss: 0.6234 - val_accuracy: 0.7614\n",
            "Epoch 15/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6561 - accuracy: 0.6919 - val_loss: 0.9552 - val_accuracy: 0.5795\n",
            "Epoch 16/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.6944 - val_loss: 0.6271 - val_accuracy: 0.7386\n",
            "Epoch 17/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.7579 - val_loss: 0.6102 - val_accuracy: 0.7045\n",
            "Epoch 18/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6624 - accuracy: 0.6944 - val_loss: 0.8082 - val_accuracy: 0.6136\n",
            "Epoch 19/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6457 - accuracy: 0.7066 - val_loss: 0.6661 - val_accuracy: 0.7045\n",
            "Epoch 20/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.7237 - val_loss: 0.6023 - val_accuracy: 0.7500\n",
            "Epoch 21/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5721 - accuracy: 0.7408 - val_loss: 1.0818 - val_accuracy: 0.5568\n",
            "Epoch 22/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.7053 - accuracy: 0.6797 - val_loss: 0.6136 - val_accuracy: 0.7045\n",
            "Epoch 23/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.7139 - val_loss: 0.8113 - val_accuracy: 0.7159\n",
            "Epoch 24/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8779 - accuracy: 0.5672 - val_loss: 0.7024 - val_accuracy: 0.6932\n",
            "Epoch 25/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.9167 - accuracy: 0.6479 - val_loss: 1.5197 - val_accuracy: 0.5114\n",
            "Epoch 26/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7658 - accuracy: 0.6504 - val_loss: 0.9531 - val_accuracy: 0.5909\n",
            "Epoch 27/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.8675 - accuracy: 0.6137 - val_loss: 0.7056 - val_accuracy: 0.5909\n",
            "Epoch 28/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6908 - accuracy: 0.6773 - val_loss: 0.6677 - val_accuracy: 0.6932\n",
            "Epoch 29/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6090 - accuracy: 0.7164 - val_loss: 0.6598 - val_accuracy: 0.6705\n",
            "Epoch 30/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5908 - accuracy: 0.7286 - val_loss: 0.6691 - val_accuracy: 0.7159\n",
            "Epoch 31/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7800 - val_loss: 0.6731 - val_accuracy: 0.6932\n",
            "Epoch 32/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5702 - accuracy: 0.7482 - val_loss: 0.7901 - val_accuracy: 0.6136\n",
            "Epoch 33/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6068 - accuracy: 0.7017 - val_loss: 0.7120 - val_accuracy: 0.6705\n",
            "Epoch 34/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.7359 - val_loss: 0.5979 - val_accuracy: 0.7273\n",
            "Epoch 35/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.9160 - accuracy: 0.6210 - val_loss: 0.5808 - val_accuracy: 0.7386\n",
            "Epoch 36/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.7139 - val_loss: 0.6211 - val_accuracy: 0.7500\n",
            "Epoch 37/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6370 - accuracy: 0.7090 - val_loss: 0.7064 - val_accuracy: 0.6591\n",
            "Epoch 38/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5953 - accuracy: 0.7139 - val_loss: 0.6840 - val_accuracy: 0.6364\n",
            "Epoch 39/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.7751 - val_loss: 0.6578 - val_accuracy: 0.6818\n",
            "Epoch 40/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5982 - accuracy: 0.7359 - val_loss: 0.6534 - val_accuracy: 0.7159\n",
            "Epoch 41/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5337 - accuracy: 0.7531 - val_loss: 0.6329 - val_accuracy: 0.7159\n",
            "Epoch 42/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.7579 - val_loss: 0.6294 - val_accuracy: 0.6932\n",
            "Epoch 43/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7628 - val_loss: 0.5817 - val_accuracy: 0.6705\n",
            "Epoch 44/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5525 - accuracy: 0.7457 - val_loss: 0.7954 - val_accuracy: 0.6818\n",
            "Epoch 45/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5677 - accuracy: 0.7359 - val_loss: 0.6189 - val_accuracy: 0.7159\n",
            "Epoch 46/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5521 - accuracy: 0.7579 - val_loss: 0.6048 - val_accuracy: 0.6932\n",
            "Epoch 47/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5305 - accuracy: 0.7628 - val_loss: 0.6512 - val_accuracy: 0.7273\n",
            "Epoch 48/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7555 - val_loss: 0.6778 - val_accuracy: 0.6591\n",
            "Epoch 49/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5704 - accuracy: 0.7433 - val_loss: 0.6690 - val_accuracy: 0.7045\n",
            "Epoch 50/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6612 - accuracy: 0.7115 - val_loss: 0.6222 - val_accuracy: 0.7500\n",
            "Epoch 51/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6037 - accuracy: 0.7506 - val_loss: 0.5817 - val_accuracy: 0.7500\n",
            "Epoch 52/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.7677 - val_loss: 0.6300 - val_accuracy: 0.7159\n",
            "Epoch 53/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.7628 - val_loss: 0.6230 - val_accuracy: 0.6818\n",
            "Epoch 54/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7531 - val_loss: 0.6538 - val_accuracy: 0.6932\n",
            "Epoch 55/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4917 - accuracy: 0.7702 - val_loss: 0.6062 - val_accuracy: 0.6818\n",
            "Epoch 56/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4949 - accuracy: 0.7531 - val_loss: 0.6249 - val_accuracy: 0.6932\n",
            "Epoch 57/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6883 - accuracy: 0.7115 - val_loss: 0.6222 - val_accuracy: 0.6250\n",
            "Epoch 58/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5404 - accuracy: 0.7555 - val_loss: 0.5866 - val_accuracy: 0.6705\n",
            "Epoch 59/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5554 - accuracy: 0.7433 - val_loss: 0.7750 - val_accuracy: 0.6932\n",
            "Epoch 60/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5822 - accuracy: 0.7090 - val_loss: 0.6275 - val_accuracy: 0.7045\n",
            "Epoch 61/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6019 - accuracy: 0.7286 - val_loss: 0.6066 - val_accuracy: 0.6705\n",
            "Epoch 62/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.7628 - val_loss: 1.0222 - val_accuracy: 0.6250\n",
            "Epoch 63/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.7557 - accuracy: 0.6675 - val_loss: 0.6640 - val_accuracy: 0.6932\n",
            "Epoch 64/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6037 - accuracy: 0.7188 - val_loss: 0.6192 - val_accuracy: 0.6818\n",
            "Epoch 65/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7482 - val_loss: 0.5868 - val_accuracy: 0.7159\n",
            "Epoch 66/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4895 - accuracy: 0.7751 - val_loss: 0.5758 - val_accuracy: 0.7159\n",
            "Epoch 67/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7653 - val_loss: 0.6222 - val_accuracy: 0.6932\n",
            "Epoch 68/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5734 - accuracy: 0.7213 - val_loss: 0.6254 - val_accuracy: 0.7386\n",
            "Epoch 69/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7482 - val_loss: 0.5990 - val_accuracy: 0.6818\n",
            "Epoch 70/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.5788 - accuracy: 0.7139 - val_loss: 0.5725 - val_accuracy: 0.7273\n",
            "Epoch 71/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.6059 - accuracy: 0.7286 - val_loss: 0.8408 - val_accuracy: 0.6136\n",
            "Epoch 72/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.6081 - accuracy: 0.7213 - val_loss: 0.6176 - val_accuracy: 0.6818\n",
            "Epoch 73/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.7702 - val_loss: 0.5959 - val_accuracy: 0.7273\n",
            "Epoch 74/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5448 - accuracy: 0.7482 - val_loss: 0.5838 - val_accuracy: 0.7159\n",
            "Epoch 75/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.7555 - val_loss: 0.5758 - val_accuracy: 0.7386\n",
            "Epoch 76/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7751 - val_loss: 0.5720 - val_accuracy: 0.7386\n",
            "Epoch 77/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.7164 - val_loss: 0.7120 - val_accuracy: 0.7045\n",
            "Epoch 78/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6195 - accuracy: 0.7506 - val_loss: 2.0009 - val_accuracy: 0.5795\n",
            "Epoch 79/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7602 - accuracy: 0.7335 - val_loss: 0.6044 - val_accuracy: 0.6932\n",
            "Epoch 80/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7506 - val_loss: 0.6676 - val_accuracy: 0.6705\n",
            "Epoch 81/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5979 - accuracy: 0.7628 - val_loss: 0.6337 - val_accuracy: 0.7273\n",
            "Epoch 82/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5695 - accuracy: 0.7457 - val_loss: 0.6601 - val_accuracy: 0.6818\n",
            "Epoch 83/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4902 - accuracy: 0.7873 - val_loss: 0.6193 - val_accuracy: 0.7045\n",
            "Epoch 84/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.7579 - val_loss: 0.5779 - val_accuracy: 0.7045\n",
            "Epoch 85/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7604 - val_loss: 0.6618 - val_accuracy: 0.6477\n",
            "Epoch 86/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7531 - val_loss: 0.7213 - val_accuracy: 0.6932\n",
            "Epoch 87/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7506 - val_loss: 0.6694 - val_accuracy: 0.7159\n",
            "Epoch 88/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.7531 - val_loss: 0.6175 - val_accuracy: 0.7159\n",
            "Epoch 89/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7604 - val_loss: 0.6013 - val_accuracy: 0.6932\n",
            "Epoch 90/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5629 - accuracy: 0.7359 - val_loss: 0.6087 - val_accuracy: 0.7273\n",
            "Epoch 91/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6022 - accuracy: 0.7213 - val_loss: 0.5954 - val_accuracy: 0.7273\n",
            "Epoch 92/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7579 - val_loss: 0.6141 - val_accuracy: 0.6932\n",
            "Epoch 93/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7531 - val_loss: 0.5669 - val_accuracy: 0.7273\n",
            "Epoch 94/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7702 - val_loss: 0.6313 - val_accuracy: 0.6818\n",
            "Epoch 95/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7531 - val_loss: 0.5941 - val_accuracy: 0.6932\n",
            "Epoch 96/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7628 - val_loss: 0.6487 - val_accuracy: 0.6818\n",
            "Epoch 97/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.7555 - val_loss: 0.6409 - val_accuracy: 0.6932\n",
            "Epoch 98/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.7628 - val_loss: 0.5810 - val_accuracy: 0.6818\n",
            "Epoch 99/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7579 - val_loss: 0.5679 - val_accuracy: 0.7273\n",
            "Epoch 100/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5560 - accuracy: 0.7457 - val_loss: 0.6218 - val_accuracy: 0.7159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Loss & Accuracy\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "val_acc=history.history['val_accuracy']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "24664c85-64d1-49d4-f754-6f6da07295e9",
        "id": "ZgHGUcncTxTv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRL8Vx3-g2Ds",
        "outputId": "e028459a-9dde-4ea9-dd9b-bc4027b0d82b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 3ms/step - loss: 0.5542 - accuracy: 0.7273\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5542144179344177, 0.7272727489471436]"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.evaluate(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Tz-pxXPSIc2",
        "outputId": "0c079710-f59e-4b83-fcfd-09c0a3893805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 1ms/step - loss: 0.5218 - accuracy: 0.7702\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5217604637145996, 0.7701711654663086]"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model 2 (Activation function: ReLU)"
      ],
      "metadata": {
        "id": "DNRTMw9bx8W0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(512, input_shape=[4],activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
        "                                    ])"
      ],
      "metadata": {
        "id": "LevK5x1CuIoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.compile(loss=SparseCategoricalCrossentropy(from_logits=False),optimizer=adam,metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "kufUl54L2YEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "id": "sQvNNHKU7fyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_2.fit(X_train, y_train, batch_size=16, epochs=400, callbacks=callback, verbose=1)"
      ],
      "metadata": {
        "id": "SCupuSacf5Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_2.fit(X_train, y_train, validation_data = (X_valid,y_valid), batch_size=16, epochs=100, verbose=1)"
      ],
      "metadata": {
        "id": "AyK-OiQBfOVU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a33644f7-0560-4fb1-bf4f-ad7e984afcca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "26/26 [==============================] - 1s 8ms/step - loss: 2.8086 - accuracy: 0.3178 - val_loss: 1.1405 - val_accuracy: 0.3977\n",
            "Epoch 2/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.1056 - accuracy: 0.3839 - val_loss: 1.0482 - val_accuracy: 0.5341\n",
            "Epoch 3/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.9890 - accuracy: 0.5257 - val_loss: 0.9133 - val_accuracy: 0.5341\n",
            "Epoch 4/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.8279 - accuracy: 0.6137 - val_loss: 0.6930 - val_accuracy: 0.7500\n",
            "Epoch 5/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6618 - accuracy: 0.6650 - val_loss: 0.5541 - val_accuracy: 0.6932\n",
            "Epoch 6/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.7139 - val_loss: 0.6273 - val_accuracy: 0.7386\n",
            "Epoch 7/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.7384 - val_loss: 0.5354 - val_accuracy: 0.7273\n",
            "Epoch 8/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.7555 - val_loss: 0.5159 - val_accuracy: 0.7614\n",
            "Epoch 9/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7702 - val_loss: 0.3999 - val_accuracy: 0.7727\n",
            "Epoch 10/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7897 - val_loss: 0.5454 - val_accuracy: 0.7500\n",
            "Epoch 11/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.7971 - val_loss: 0.6116 - val_accuracy: 0.7386\n",
            "Epoch 12/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7775 - val_loss: 0.4577 - val_accuracy: 0.7614\n",
            "Epoch 13/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7702 - val_loss: 0.5348 - val_accuracy: 0.7045\n",
            "Epoch 14/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8240 - val_loss: 0.3499 - val_accuracy: 0.8636\n",
            "Epoch 15/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.7873 - val_loss: 0.4676 - val_accuracy: 0.7727\n",
            "Epoch 16/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7848 - val_loss: 0.3818 - val_accuracy: 0.8182\n",
            "Epoch 17/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3570 - accuracy: 0.8484 - val_loss: 0.4284 - val_accuracy: 0.7500\n",
            "Epoch 18/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4015 - accuracy: 0.7897 - val_loss: 0.3417 - val_accuracy: 0.8523\n",
            "Epoch 19/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3398 - accuracy: 0.8337 - val_loss: 0.3438 - val_accuracy: 0.8182\n",
            "Epoch 20/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3723 - accuracy: 0.8264 - val_loss: 0.3238 - val_accuracy: 0.8523\n",
            "Epoch 21/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3698 - accuracy: 0.8362 - val_loss: 0.3188 - val_accuracy: 0.8295\n",
            "Epoch 22/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.7946 - val_loss: 0.3389 - val_accuracy: 0.9091\n",
            "Epoch 23/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.8191 - val_loss: 0.3257 - val_accuracy: 0.8182\n",
            "Epoch 24/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3795 - accuracy: 0.8215 - val_loss: 0.3644 - val_accuracy: 0.8068\n",
            "Epoch 25/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3398 - accuracy: 0.8460 - val_loss: 0.3350 - val_accuracy: 0.8295\n",
            "Epoch 26/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3342 - accuracy: 0.8337 - val_loss: 0.3846 - val_accuracy: 0.8636\n",
            "Epoch 27/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3222 - accuracy: 0.8557 - val_loss: 0.3252 - val_accuracy: 0.8636\n",
            "Epoch 28/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3072 - accuracy: 0.8509 - val_loss: 0.3014 - val_accuracy: 0.8864\n",
            "Epoch 29/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3786 - accuracy: 0.8191 - val_loss: 0.3180 - val_accuracy: 0.8182\n",
            "Epoch 30/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3412 - accuracy: 0.8337 - val_loss: 0.3017 - val_accuracy: 0.9091\n",
            "Epoch 31/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3554 - accuracy: 0.8166 - val_loss: 0.4734 - val_accuracy: 0.7727\n",
            "Epoch 32/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3510 - accuracy: 0.8386 - val_loss: 0.2854 - val_accuracy: 0.9091\n",
            "Epoch 33/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3542 - accuracy: 0.8240 - val_loss: 0.3672 - val_accuracy: 0.8182\n",
            "Epoch 34/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7922 - val_loss: 0.4917 - val_accuracy: 0.7614\n",
            "Epoch 35/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8117 - val_loss: 0.3270 - val_accuracy: 0.8409\n",
            "Epoch 36/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3200 - accuracy: 0.8557 - val_loss: 0.3419 - val_accuracy: 0.8523\n",
            "Epoch 37/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3065 - accuracy: 0.8606 - val_loss: 0.2982 - val_accuracy: 0.8864\n",
            "Epoch 38/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3286 - accuracy: 0.8386 - val_loss: 0.4242 - val_accuracy: 0.7727\n",
            "Epoch 39/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3098 - accuracy: 0.8484 - val_loss: 0.2797 - val_accuracy: 0.8750\n",
            "Epoch 40/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2792 - accuracy: 0.8778 - val_loss: 0.2916 - val_accuracy: 0.8864\n",
            "Epoch 41/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2785 - accuracy: 0.8680 - val_loss: 0.2857 - val_accuracy: 0.9091\n",
            "Epoch 42/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2807 - accuracy: 0.8778 - val_loss: 0.3025 - val_accuracy: 0.8864\n",
            "Epoch 43/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3094 - accuracy: 0.8484 - val_loss: 0.4619 - val_accuracy: 0.7727\n",
            "Epoch 44/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3378 - accuracy: 0.8191 - val_loss: 0.3095 - val_accuracy: 0.8864\n",
            "Epoch 45/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2597 - accuracy: 0.8924 - val_loss: 0.2804 - val_accuracy: 0.9205\n",
            "Epoch 46/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2577 - accuracy: 0.8949 - val_loss: 0.3426 - val_accuracy: 0.8182\n",
            "Epoch 47/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3620 - accuracy: 0.8117 - val_loss: 0.5254 - val_accuracy: 0.7727\n",
            "Epoch 48/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3425 - accuracy: 0.8631 - val_loss: 0.3110 - val_accuracy: 0.8636\n",
            "Epoch 49/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2998 - accuracy: 0.8557 - val_loss: 0.3187 - val_accuracy: 0.8750\n",
            "Epoch 50/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2607 - accuracy: 0.8998 - val_loss: 0.3071 - val_accuracy: 0.8977\n",
            "Epoch 51/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2899 - accuracy: 0.8729 - val_loss: 0.3104 - val_accuracy: 0.8864\n",
            "Epoch 52/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.8484 - val_loss: 0.6592 - val_accuracy: 0.7500\n",
            "Epoch 53/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3650 - accuracy: 0.8337 - val_loss: 0.3024 - val_accuracy: 0.8750\n",
            "Epoch 54/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2545 - accuracy: 0.8826 - val_loss: 0.2644 - val_accuracy: 0.8977\n",
            "Epoch 55/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2377 - accuracy: 0.9071 - val_loss: 0.2856 - val_accuracy: 0.9205\n",
            "Epoch 56/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2124 - accuracy: 0.9095 - val_loss: 0.2666 - val_accuracy: 0.9091\n",
            "Epoch 57/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2510 - accuracy: 0.8998 - val_loss: 0.4485 - val_accuracy: 0.7955\n",
            "Epoch 58/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2899 - accuracy: 0.8729 - val_loss: 0.3230 - val_accuracy: 0.8864\n",
            "Epoch 59/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2784 - accuracy: 0.8680 - val_loss: 0.3310 - val_accuracy: 0.8864\n",
            "Epoch 60/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2802 - accuracy: 0.8802 - val_loss: 0.2960 - val_accuracy: 0.9091\n",
            "Epoch 61/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2803 - accuracy: 0.8729 - val_loss: 0.2909 - val_accuracy: 0.8409\n",
            "Epoch 62/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2646 - accuracy: 0.8973 - val_loss: 0.2485 - val_accuracy: 0.9091\n",
            "Epoch 63/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2322 - accuracy: 0.9095 - val_loss: 0.3020 - val_accuracy: 0.9205\n",
            "Epoch 64/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3755 - accuracy: 0.8215 - val_loss: 0.4734 - val_accuracy: 0.8295\n",
            "Epoch 65/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3355 - accuracy: 0.8606 - val_loss: 0.3134 - val_accuracy: 0.8523\n",
            "Epoch 66/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2657 - accuracy: 0.8900 - val_loss: 0.3085 - val_accuracy: 0.8977\n",
            "Epoch 67/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2590 - accuracy: 0.8924 - val_loss: 0.2681 - val_accuracy: 0.8864\n",
            "Epoch 68/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2178 - accuracy: 0.9095 - val_loss: 0.2820 - val_accuracy: 0.9091\n",
            "Epoch 69/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2229 - accuracy: 0.9046 - val_loss: 0.2558 - val_accuracy: 0.9318\n",
            "Epoch 70/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1898 - accuracy: 0.9218 - val_loss: 0.2978 - val_accuracy: 0.8523\n",
            "Epoch 71/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2243 - accuracy: 0.9095 - val_loss: 0.2592 - val_accuracy: 0.9205\n",
            "Epoch 72/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2162 - accuracy: 0.9095 - val_loss: 0.2495 - val_accuracy: 0.9205\n",
            "Epoch 73/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2649 - accuracy: 0.8778 - val_loss: 0.2436 - val_accuracy: 0.9205\n",
            "Epoch 74/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2372 - accuracy: 0.8875 - val_loss: 0.2810 - val_accuracy: 0.8864\n",
            "Epoch 75/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2059 - accuracy: 0.9169 - val_loss: 0.2482 - val_accuracy: 0.9205\n",
            "Epoch 76/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2292 - accuracy: 0.8949 - val_loss: 0.2732 - val_accuracy: 0.9318\n",
            "Epoch 77/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2136 - accuracy: 0.9218 - val_loss: 0.3759 - val_accuracy: 0.8295\n",
            "Epoch 78/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2516 - accuracy: 0.9022 - val_loss: 0.2403 - val_accuracy: 0.9432\n",
            "Epoch 79/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1918 - accuracy: 0.9242 - val_loss: 0.2258 - val_accuracy: 0.9318\n",
            "Epoch 80/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1951 - accuracy: 0.9193 - val_loss: 0.2300 - val_accuracy: 0.9318\n",
            "Epoch 81/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1744 - accuracy: 0.9364 - val_loss: 0.2440 - val_accuracy: 0.9318\n",
            "Epoch 82/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1608 - accuracy: 0.9438 - val_loss: 0.2464 - val_accuracy: 0.9545\n",
            "Epoch 83/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1752 - accuracy: 0.9364 - val_loss: 0.2619 - val_accuracy: 0.8977\n",
            "Epoch 84/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2153 - accuracy: 0.9144 - val_loss: 0.2638 - val_accuracy: 0.8977\n",
            "Epoch 85/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1935 - accuracy: 0.9267 - val_loss: 0.2527 - val_accuracy: 0.9205\n",
            "Epoch 86/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2108 - accuracy: 0.9022 - val_loss: 0.4920 - val_accuracy: 0.8182\n",
            "Epoch 87/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2596 - accuracy: 0.8924 - val_loss: 0.3116 - val_accuracy: 0.9091\n",
            "Epoch 88/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3265 - accuracy: 0.8631 - val_loss: 0.3716 - val_accuracy: 0.8977\n",
            "Epoch 89/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2333 - accuracy: 0.8949 - val_loss: 0.2689 - val_accuracy: 0.8864\n",
            "Epoch 90/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2126 - accuracy: 0.9267 - val_loss: 0.2635 - val_accuracy: 0.8636\n",
            "Epoch 91/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2166 - accuracy: 0.9046 - val_loss: 0.2517 - val_accuracy: 0.9318\n",
            "Epoch 92/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9193 - val_loss: 0.2378 - val_accuracy: 0.9205\n",
            "Epoch 93/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2105 - accuracy: 0.9095 - val_loss: 0.2367 - val_accuracy: 0.9432\n",
            "Epoch 94/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1936 - accuracy: 0.9267 - val_loss: 0.2587 - val_accuracy: 0.9432\n",
            "Epoch 95/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1905 - accuracy: 0.9144 - val_loss: 0.2225 - val_accuracy: 0.9318\n",
            "Epoch 96/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1740 - accuracy: 0.9315 - val_loss: 0.2674 - val_accuracy: 0.9318\n",
            "Epoch 97/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1855 - accuracy: 0.9315 - val_loss: 0.3138 - val_accuracy: 0.7841\n",
            "Epoch 98/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3126 - accuracy: 0.8802 - val_loss: 0.3798 - val_accuracy: 0.8409\n",
            "Epoch 99/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2165 - accuracy: 0.9144 - val_loss: 0.2373 - val_accuracy: 0.9205\n",
            "Epoch 100/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1655 - accuracy: 0.9291 - val_loss: 0.3082 - val_accuracy: 0.9205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Loss & Accuracy\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "val_acc=history.history['val_accuracy']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RN5Fun988WWB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "8e4a58c6-9ef4-4761-e956-53eb8f880ba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3iUVfbHPzcVQmgJCYQECGBoooAgYFsLiyIWUHZVrNi7YF1cG7vr7qo/144FO6iLHVGxwIoVQSKgdIIhQgIkgZBAEkLa/f1x5p3MJJNkEpIMSc7neeaZed+5875n2vc999xzzzXWWhRFUZTmT1CgDVAURVEaBhV0RVGUFoIKuqIoSgtBBV1RFKWFoIKuKIrSQlBBVxRFaSGooCuHFMaYz4wxlzV0W0VpDRjNQ1cOFmNMvsdmBHAAKHNtX2utfbPprVKU1ocKutKgGGPSgKustYt8PBdirS1tequaF/o5KfVFQy5Ko2GMOckYk26M+YsxZifwqjGmszHmE2NMtjFmj+txgsdrvjbGXOV6PMUY870x5lFX2y3GmNPr2ba3MeZbY8w+Y8wiY8xMY8wb1dhdm41RxphXjTHbXc/P83hugjFmlTFmrzHmN2PMONf+NGPMHz3azXDOb4xJNMZYY8yVxpitwFeu/e8aY3YaY/Jcth/u8fq2xpj/GGN+dz3/vWvfp8aYmyu9n1+NMefU9ftTmh8q6Epj0w2IAnoB1yC/uVdd2z2B/cAzNbx+FLAR6AI8ArxsjDH1aPsW8BMQDcwALqnhnLXZOAcJLR0OxAKPAxhjRgKzgTuBTsAfgLQazlOZE4GBwGmu7c+AJNc5VgCeoatHgeHAscjnexdQDrwOXOw0MsYMAeKBT+tgh9JcsdbqTW8NdkME7I+uxycBxUCbGtoPBfZ4bH+NhGwApgCbPZ6LACzQrS5tEVEuBSI8nn8DeMPP9+S2EYhDhLOzj3YvAI/X9rm4tmc45wcSXbb2qcGGTq42HZELzn5giI92bYA9QJJr+1Hg2UD/LvTWNDf10JXGJttaW+RsGGMijDEvuEIFe4FvgU7GmOBqXr/TeWCtLXQ9jKxj2+5Ajsc+gG3VGVyLjT1cx9rj46U9gN+qO64fuG0yxgQbYx5yhW32UuHpd3Hd2vg6l+uzfhu42BgTBExGehRKK0AFXWlsKo+63w70B0ZZazsgYQmA6sIoDcEOIMoYE+Gxr0cN7WuycZvrWJ18vG4b0LeaYxYgvQaHbj7aeH5WFwITgD8iXnmihw27gKIazvU6cBEwBii01v5YTTulhaGCrjQ17ZFwQa4xJgp4oLFPaK39HUgGZhhjwowxxwBn1cdGa+0OJLb9rGvwNNQY4wj+y8DlxpgxxpggY0y8MWaA67lVwAWu9iOAP9Vidnsk/XM3ciH4l4cN5cArwGPGmO4ub/4YY0y46/kfkbDQf1DvvFWhgq40NU8AbREvcynweROd9yLgGEQgH0TCEgeqaVubjZcAJcAGIAuYBmCt/Qm4HBkkzQO+QQZWAe5DPOo9wN+QQdqamA38DmQA61x2eHIHsBpYDuQAD+P9f54NHIGMFSitBM1DV1olxpi3gQ3W2kbvIQQCY8ylwDXW2uMDbYvSdKiHrrQKjDFHG2P6ukIh45D49LzaXtcccY0V3ADMCrQtStOigq60FrohaY75wFPA9dbalQG1qBEwxpwGZAOZ1B7WUVoYGnJRFEVpIaiHriiK0kIICdSJu3TpYhMTEwN1ekVRlGbJzz//vMtaG+PruYAJemJiIsnJyYE6vaIoSrPEGPN7dc9pyEVRFKWFoIKuKIrSQlBBVxRFaSGooCuKorQQVNAVRVFaCCroiqIoLQQVdEVRlBaCCrqiKIcUWVkwR6u41wsVdEVRDimmT4dLL4W0tEBb0vxQQVcU5ZAhOxvectWIXL06sLY0R1TQFUU5ZHjhBTjgWkdqzZrA2tIcUUFXFKVRufVWGD++Qqiro7gYZj5dxrjon+jJ76x+ey2UlzeNkT6YMQPCwipuRx4JO3YEzBy/UEFXFKVR+e47+OwzuPzymvX53ftXszMrmGn7HuSI6B2s+aUMTj8dMjObzlgXe/fCY4/BiBFwxx1yUUpNhbPOgvz8JjfHb1TQFUVpVDIzIToa/vtfuPde323s67N54uEiBoT9xqk//5vBV45iQ/DhlHyzBI46SoLrTcgrr8C+ffDUU/Cvf8HDD8PcubByJUyeDKWlTWqO3wSsfK6iKIFh3z5YtAjOOadhj/vVV9CzJxx2WMU+ayUNcdo02LMH/v1vKCyEHj08XlhYSM6/dpHM0Tz3f8WYwWEccSSUlAWzcc4SBl94JMycKTGQRuDnn8XOESNku6xMhPy44yr2AZx5JjzzDNxwA1x4IYwaBZSW0m37z1w0YpM06tRJGhrTKLbWirU2ILfhw4dbRVGanltvtRasTUtruGN++KG1xlh7ySXe+3Nz5Vz/+Y+1JSXWTpwo275u3WOKbX6+vG7VKtn33/9aa88809ouXawtLGw4gz0YMcLaiAhrly+X7Xnz5NzvvOO7/T33VLV9KwkVG8uWVX+y4mJrL7zQ2p9+qre9QLKtRlc15KIorYi9e+Gll+RxamrDHPOnn8RjtRYyMryfc8LfsbEQEgIfvFfO3j1l7N0rtuxdtp69QZ3Ye+WtpGWE0q6dtB8wAIKDXamLt98Ou3bB7NkVB96wQUZaN2+un9G33QZPPYW1cqjCQnGs09LgiSekB+HVg3nnHfjzn6GwkAcflDj63qXreMtcBMCuj5bADz9I25oW7vn3vyUvc9u2+tldG9UpfWPf1ENXlKbnyScrHMlXXrHWlpVZm5xsbXl5vY7322/WxsRY26ePtSeeaO3AgR5PZGTY776Tc335pWv/5ZdbGxVl7YMPWpuXZ+3YsdZ26mRtdnaVYw8aZO3ZZ1ux7aijrO3XT+zds8fapCQ58HXX1d3o7Gxrg4Ksbd/e7tiYZ8Ha668XM3r1ksM+8kil9p06yRPnny/2lJdbe8opdnHkmRasXbTIZWdUlLVXXeX7vCtXWhsSIh76QYB66EprYMcOGD4c1q9v+nN/9hkccwz8Xu3iYAfH/v2SYfGf/9T/GOXlEhseMQKCglwzMf/5T9nxn/+wZQv06gVdulS9xcVJjNwTa2HCBIk5L1gARxzhSusrL4cxY2DcOLJ2SlpLbCxywtdfh8hIGR2Nj4eFC+Fvf5OTVGLwYJeHbox46Zs2wccfw4UXsiXVMjRiIymzf5RBgbrwySdi4759pDzxKQBnnw3z5sH2jHIiwku56iqP9g88IOe45hp4+2145BH46CP46is633ghIOMDGCMDuCtXep1u925IOszSZUQvupRl0uXzObz2Wt1M9pvqlL6xb+qhKw3NzJniRL38ctOet7zc2mHD5NyDBokD2ZCUlVk7aZIc/49/rP9x5s+XY8yda22PHtZeOinf2rZtJYAcFGTn3PmLBWsvvdTaG2/0vnXoYO2UKd7H+2VVuQVrX7huhbVWnG6wtvCzr93dgGevSrZg7fbt1tpp08RD3bpVegUTJ8obKi72ae8//iGH2bvXSpuEBGvbtbMW7M0n/2rB2jlcZO0LL9Ttg5g4UY514on25c63W7B282ZrbVqa/arteDufMytc9F9/FW/+5pvli77gAhksiImx9vDD7e+/lViwdtYs17HvvNPasDCv9/S//8n7mMS79sYzttgbb7T222/rZrIn1OChq6ArLYbx4+UX/eCDTXveb76R8152mbWhodaefLK1Bw403PFvu02O37mzR0ijHowZIzpWXGztCSdYe2LsWmvbtLF2zRprjzzS3h/+kA0KKrdFRVVfO3mytbGxcnFx+NdNGSLWPUdZW1pqX35Z7EyddIe17dtb27+/nRHztAVri7P2WBsZae1FF/lt74cfyvGWLnXtePRRa8HmTplqIyNdoZG4x+Rq6m/IqKBALmI33WTtxx/b6fzLhgSX2ZIDZfIBtWtn7VlnycEfeki+zKgoa3fvrni9c/VeuNDu3SsPH37Ydfz//ld2rFrlPuXLD2VVfC4NgAp6C2PlSpfH00iUlkrM09d/ZNGiah2qBicnx9rFi/1rW1go2gTiUTYl554r//mCAmtnP7VHvNyR6235fh/KWA2LF7s80Uo884y8p5tvtvaWMzbb9u1K62Xjr5+L+P77vgJrrbUXn5Zpe7HF2vvukwapqXZy2Hu2d+hWa//yF7ndf7+7uzFnjtjhZIJYa+3xCVvsUSTLE++/bxcskIdL2p5i7ZVXWjt3rr2BZ2x0ZJF4vGDtihV+27x5s7zkxRddO4qLrf3wQ/vYI+IVBwVZe+sYVzqMR2bJokU19JKcFJaFC60tK7OT2n9u+4dvqejePf+8pONceKG7l2FnzvQ+RlaWtQsWWGvlPxISYu306a7nNmyQ17z6qrv5facttUGU2uINv/n93mvioAUdGAdsBDYD03083wv4H/Ar8DWQUNsxVdDrT7du1Y+7NAQffSS/jJUrvfenpMj+t95qvHN7csUVcr7162tv64iJMSKwTcWWLSIs0y/bbu2AAdaCvYuHpBv/h8ut3b+/1mMsX27dqX2elJdLqGPsWGtLP5xv/w8JD+Tl1dHI8nJ7VbePbVsK7K52Pa29+257b7cXbTAltiQ3391sRP88e2rYV9aGh8vNw6jsbPlsZ8yQtrt3ldsgSu29iXNkRPTYY+3KlS5t5xzptpSV2UkdvrADw1KsjY8Xb7cOlJVJNGjq1Ip9paXWJiZKD6NvX2svmFQsXvXll1trrd21S2wYPbqaLMcpU6zt2NHtlRwRv8ueyXxR5VNPrfBiSkutvfZa8dpLSmq0MyZGmrqNbtdOrsAuLum+0PYMyajTe6+JmgS91kFRY0wwMBM4HRgETDbGDKrU7FFgtrX2SODvwL8PNrav+GbfPti5E7ZsabxzOMeuXLfC2W7McztkZcGbb8rjp56qvf2nn0JEhAxMNmW9jWeekbGwG3+/S0a//u//GPPURAC2f5sCEyfKiGYNPPGE3FcezN25U1L7zh65k+BLLyKBdADS0+tmY/Yr85mz849cMnQN0WeMhoceInHnj5QRQvoeyRO0Fjbt6EDS1SdDUZHchgyRkUJkzHLUKBn8BPjyhS2UE8wZkzvIrKElS4jLkHS9HVGD4fjjISiIrPhhxBanSz7jHXfUye6gIDj8cO+qi/Pny9jq1KkyULtzdyhcdJFM48zNZetWabd0KVxySaVSA6WlMqh65pkQGkp5OWzOiSKpbYb8eF56qWJCUHAwPP+8zMAKqXn+ZefOrkFRx+ihQysGRgsKSNvRhl5da/4NNBT+ZLmMBDZba1OttcXAXGBCpTaDAGcMfLGP55UGwsmiqOufui44x96923u/s92Y53Zwqu6deKIkRrj/MD6wVgR9zBjo3VuEsF58+22VDIWayM8XDfjT6fkkfPOmTCG84w5iT+gPQNb1M+DLLyUVpLjY5zG2b5cUZ4CUFO/nnO1+r94NbduScExPoI6ff2Ehs27fxAHaMHX2cMnSWLOGxLvOBypqjmdny8UjKcnjtRMnSm61a9r9+PGwfLlcbBe8tYcuZHP0rcdLkZZOnejy0B0EUcaOQWNE2ICs8i507VQsKSvjxtXBcOGII7wF/cknJRNnwgQR9B07gOuuk4vmlVeSniZz8i+6CN5/H+680+NgS5bIj3iCyNP27bB/vyHpltNh8eJK01f9p3NnyMnx2DFsGKxaJVeTr77id9uDxIER9Tp2XfFH0OMBzyz4dNc+T34BznU9Pgdob4yJrnwgY8w1xphkY0xydhPXZmgpOH/A9HQRssbAmRzi9SP12G5sQS8uhmefhdNOkz9wYWHFZBhfbNwon8v48dCtm/zJ6/PZ3H7GBu499SdsuX8vfv11yMuDaVFzxLNz5bp17SrPZx0xRry8hQtFXXzw3HPiOB5/fPWCnpT1A7z/PgnHiOCkbymp1qZZs+C888TBBih+6DGezbuQU4/OYdARwbJz0CASrzkVqPg9uc/lKegTJogoffIJAGecIZ/rgk8tn61PZFz31QTHREka4nXXEfz9N3Qlkx3dhrkPkZVliP3TH0Qwg+qeJT14sFxPeveW2zffwE03idPsfNcMGwaPPw4ffED63+SH8vDDcMstUmDr6addB5s3T8omui4s7vf8x16SblhPvDx0XPbk58Nvv1Hy8eekk0Di0TH1Pn5daKg89DuAE40xK4ETgQygrHIja+0sa+0Ia+2ImJimeYMtDecPWFAgHlVjUJuHXnk2YEPzzjviZU+bJr3+k06S0EZ1BZE+lVRixo+HuLJtFBVB3phz5R//9dd+nXPD4h08ln8N/9x1LQ9Pqz1mU14uF5uRR5cz+vMZ0o1PSAAqUqozMxGR79nTe5aji6Ii0fuzzhKN2b7du5Jfyg9ZhHGAng9cDscfT/dBnQBIX1f9F//qq/DuuzBlCpRv2sx7D21mO/FMnRHl1a5HD7kG1SjoQ4eK7a6wy9Ch8pH+64ED7CqPZvxZwRVtb74ZQkOJa7eXnYUdALkw79kDsT3b+Mwz94fzzpOP8IQT5Hb99XDttfJcXJz8BwoLkR/Lk0+S8csugk0Z3Tof4LHHpJMxbRp8NM/K+xgzBtq3r/4914Mqgu5cHFasIP3TXygnmMTDmqZslj+CngF49kUSXPvcWGu3W2vPtdYOA+5x7cttMCsVN54TVxrLU3aOW9lDb4qQi7UilAMGwKniRDJ1Kmzd6taVKixYIJ5cz8INxD3xFwB2bCsVRf3+e7/O+9S/CwiniAnM4+6nu7tXzamOzz8XQZh2zDKJQVx3nfu50FCIipLdBAVJMPfLL0WxPXjrLZnRPm0a9Osn+zxnsqd8k0Efs4XgG0TBwnrH05WdpP/mu7D4gQOwYoWld4ddvP02/LX/ezxRehP9epdUiXaEhUH37t6CHhICiYkejYwRRfzySygoIChILpop29oQRBmn/WVoRdvu3eH994k7qrt7DMPphDs9lvoQHw8vvijXw9mzpefm0mPi4uTePWZyyy2kj5pEd5tB8DNPEhws4zAjRsDkyZaftnTxms+fkgLh4fWOtLiJiqok6IMGyY/gjTdI2x4KVPpcGxF/BH05kGSM6W2MCQMuAOZ7NjDGdDHGOMe6G3ilYc1UHDzXWTxYYS0qqlp2ory8wgOv7KE7Ap+VVftiBb74/ffavfslS8SmW26p6KGfdZZ0t598smr7vXul3vb48cDatcQh/+6ds+bL9ERnlKwG9uyB1xf34KLgt3n7zDf4Q+gSLr/c8u231b/miSdEw/70y/3yb3WuPi66dnUJOrhH5+ybb/HZZxLGfvttmfV55JHSA3G8RHfYJT+flLRQkuILRTEAEhJIIJ30bb5DQr/8AsXFhkcKb+a6hE94mOkstyO45fZQn9GOxERvQe/dW3TIi4kT5Yfy5ZcAjD9FBveO6byRqN4dvduedRZx/Tu4BdZ5/7GxPs09aBxB9xwzSY8cSEJkntTqRcY6P/4YurXN4yw+ZsuQie62mzZJZch6RIK86NwZcnM9BmDDwiT4/8knpJEIHEKCbq0tBW4CvgDWA+9Ya9caY/5ujDnb1ewkYKMxZhPQFfhnI9nb6klLg/4y5nbQgv7Xv8Lo0d7exa5dFeN31YVcoIqz6RdnnFHRXfZFXp44ulFRskiwQ3CwzLr+/vuqA57Ll0NJCYwdC6SmugV9xw4kXODHXPyXXoLC0nCmDv2G8Gsu48OSM4nrtJ/77/fdfu1aCYvfeF42od8sgquvFiM9iI31WJehf38YNYrlz//M+PFwwQVyW7dOakQZU1Fy1hH08rfmklLel6Tju1UcNCGBeDJIz6ysusLShRKKOeaGYTy95UzOOktCJJdd5vt9eAr6pk3VhB5OOEEUa948yM9n7Mxz6Egufzo/2EdjOV9WlpQD8CzM1Rh0c300nllN6emQ0DdcBiU3bXKf/7O4KzkQHMHUBytCvSkpBx9uAfl4rK0UAh0m4whpsaMICnJH4xodv65N1toF1tp+1tq+1tp/uvbdb62d73r8nrU2ydXmKmttPfw3xR/S0uDYY+XxwQi6U3WvrMz9u/c6pjG+B0WdrK66njs1VYSwuiJzxcUwaZJUvnvnHdxV9xyckERlQXe2e/UCfvuNbp3larRjh2tnLR56aSk8/VQ5J5vFHDm2K4wbR1RMCCPDVlWbLfPUU9CmDVwT/LII+RVXVGkTG+vhoQNceilbUsWF+/hjEfOUFNeFy1oiF39MXNcyt6BnPPMhRbQl6Q9xFceIiCAhfBcZub4zJpbO20kC24i/ejwhIVJuJCVFxix9kZgo32NJiYR6fIpbSIiMD3z8MZx+Oh1+WkTaK4u5ZWZ/n8eMixNPNSur4v0fTMilJiqHXKx1CfrRrifefVfut26l/7oPueWk1XzyibzXsjL47beGE3TwMTAKpMWOJD5enPamQItzNSPy88WD7tdP/iQHI+ivvVZR08iXoCcl+fbQnT9AXc/92Wdy72s1MWvFA//f/+Clv6Yy5scHq4yAds0TIzO3e4+1e3mBv/1Gx8NiaNOmkodeQ8rLvHmwLT2IqfYJuVKGhsKFFxK1fS27d1VdL233bpgzBy6+GLqsXixd627dqrTzCrkAXHAB6UG9AHF6Bw4Ur9wYZMT37LNJyllGyvI9kJxMymoJbST1814oISGqkJwDkTIQWImlayIZ3X6dJG8jx65OzEEEvaxMQlwFBTWI28SJolZLl8LcuXS6/JxqwxSeYZDGDrl06SLXG0fQ8/LkfSQMbC+rU7z9tjwxXyLE18/oSkiIZL1s2yZOREMKupcDdPLJ0KYNaWFJTRZuARX0ZoUTPUhMlC5cfQXdWZHFqbrnmS7nHHPIEN+DokOGeLfzFycTJTu76rqSzzwjKYAzZsBl318N990n63yVuNLzli0j9pYLAMj6ep3Xa7OyxPvp0AFITcX07VORn9yzp+QnV74yuSgpkfS2PlF7OJNPZFYSwKWXEl2eRU5OVVtfeUUOOfUWK0vdDB/u89ixsRJXdaefR0WR3ucEIk0+Hdp6pB1+9ZUsWDl2LP3abWfT2hK48EJSQkWUnZ6JQ0JXeW3lsYis1ZlsKerOqNHG79VyHKFZuFDuqxW3ceOk+/Tee/CnP9V4TE+vOTNTejI1XVQOhqAguXA6gu78JhMSgPPPlwT29evlqj1gAHHH9+X88+U7/PlnaVv5860PPj30QYNkUtGu9tJ7bCJU0JsRjqD36iU/2vqmDy5YIN3NO++UY3kKekaGeD0DB4rH4+ko5+RI+w4d6ibohYWShhwZKQJZ+UKxaJGEme+/NlPSDIcOFfG44AKZ7HPqqcR2Ec/cl6DHxoIpLZEPqG9fmUG4E9z/JB9xdKdXkJwMDya+THBS34rUumHDiO4aSrkNqpIa+uuvIoSD2/8uFwrPNco8cLxSTy89PXY4CXYbZswp8qa3bJG8vH794L33SLr9bLKJJS8lk5QBZ9GmjWR5eJLQU/6ylT//ZU//BMDoS/x3OSsLerXiFhEh38eE2ucLesa1s7JEcBtzNbZu3SrCbl6CPmmSnHjWLPlNTZTB0GnTpKd7333StiE8dGfMuvLkt9LyIDIymm5AFFTQmxXOANbBeuhPPCGvP+cc+UFX9tC7dwdnmoDzIy0slGSH6Oi6n/vrr+W1550n25XDLjt3ivaaD94XxX/jDfdEEU48EWJj6fDtp4QHFZP5a6bXrMvMTFeMdts26Xr0qeShg884+j/+IWGnB+63TN72SMXABIAxRJ0iKXk533tfQLKzXZ+Nkx5UjaC7Jxd5Cnp5HAkDImVAYexYCdeUlUmwu0MHkg6XQGvKqz+Q0uMUnxkYCYe1kWNVSl1c+tkeQijhqEm9fdrjCyddb+lS6eUcbPoeVBX0xgq3OLi/ayoJevfu8Ic/SFe0rMwt6MOHSzRm/XoZp4mL833cuuDTQ3fZU1amgt6s2b+/4Zb2qkxamuTNdu0qP9o9eyRmWBu5uZI3/fnnEv/96iuZbRcaKl5ZSkpFmDk9XY7teB1OtMLxqqOixGusi6A7dVb+/GfZ9ootI3/IuDgk5jlokMSAp02TWTennAJff43pkUBsVBlZBzpIsJ2KYznxcwD69q2YQViNh/76K2U88IBkfzxw8W+i0p6CDkSfKeGX3a96Zeiya5eHoIeGiij7wKeHnm6IH9VDbH32WXmv77zjdhPdqYvhg9mUGuLTe4wfJKmCXpOL0tNZmh7PkO7ZRNRhhnl4uOheaSn07VslUadetGkjAueEXJpS0DMyxCl3i/R554mDEBcHRx/tfs20aXLvHsM4SKoTdE8HrKlQQW9gnntOcourKd1xUKSliUZ5pkH5E3aZNg1OP11ul14qoY+rr5bnkpIk48URHkfQo12FGxxBd+7r6qFbKyGeP/4RehRuBLxFzlrx0OPa75OE8vPPr3jy2mtFvF1xh9ie4WSFdK8Y7MKHoLs89Nxc2B8RDW3bennotqycm68q5MSOq5j1QAbmxyXyhBM/dxHVS2av5CxY6rUizq5drshMcrJ80eHhPt+3I2ROb6SsTIQnIQFRveuvl8U4x451v6ZvXxGY9evFKfAl6BGHdSeK3aRvLnLvK3vnfX5iJKNOqnu9EEdsGiL04OCEvJrKQ8/OlotSero4O+5c+kmT5Co1YYJXV2fiRPmshw3zfcy6EhEh51RBb4Fs2yZec33ytGsjLa3ix+HEVmsT1rIyKcUxYQL8+KPc1qyp8MA9J7Q4aV/x8RWC7njmlQV9587qp+J7smGD2H3Gb08RO+l4ADJ3Vow07t4tg5PdMlaIAY4b74Ou3YLI7NBPBrkOHMBaj5BLaqqIa3x8RaZFpqmSurgrOY19tj3n5r1C2NFDpBfQoYN4yx64L2hFEe5JKuAS9GjXgGg14Rao6qFnZsp3UVM+ctu2Evb46qsaMjB69KgyuWj9f1eRT3tGj+tU/cGrobEEffv2ihh6Y9Ktm/xssrIqnBE3XbuKk/BP72kxISFyLX3mmYaxwRgfBbqQ370xDRPK8hcV9AYm11XwoDGmx3sKuvPDre08y5eLaE6eLJOIRu+cR69rx0kcxFovQc/NlVh5ba7lYxYAACAASURBVCGXhATpyfpT1fDTKz8A4PTtLxP9p1MIooysHytiUk53OW7d/yR8MXBgtceKjYWsoK4yWvvll+zbJzNW3R56794QFOQ9g7DS5KKMb2RufcKt58kb+fFH+WAqxRvcF7TuR4joW8v+/XKx7hKUIx9WDYLevr044p49H6h9gklSkpjkPK5CfLwIujO5aP9+lq6UXsLo0TUf2xeNIejdusmFvKSkaTx0kN9RFUEH6XlFRVV5XVRU1bkOB0OVei7I/7Upc9BBBb3BcQTd3wyU/HyZGV5ZmMvKJCyybJlsFxRI17KuHvqnn0pv89RTXQe96y744guZLHL00SSmLCQkRATdU3Rq89D9OXd5YRHvL+3OER1/p8fWHwh66w1ignaT9d0GdxvnohC3cXHFqGk1xMZC1t422E6d4Z13vPOcU1OhTx85lueEk0oeevpP0nVKOHekjAY++CDcc0+Vczlx0d1Dx0hJ3eXL2bVL9sXsc12QahB0Y7xni9ZF0J1USZ9ZJ+HhxLfJqZhc9OOPLCkbSVT7Yvds07rg/J4aIn3PwQl5wSEg6E1EdYLelOEWUEFvcPzy0IuKJIujpISff5akjsqrgC9bJjM5775bth1Ncn4gERHiZdR24ViwQMb7OndGZvulpMjI6Msvw549hJx1Or17lFQR9A4dxGmtzkOv9T0C06/exVI7mhsm50rgPjRURG57mbvuuNtDZ0etgt61q9QqyTvzIvjoIzK3SqZHbIwVD71vX6DSlPCePcVNdi0y4QwmJvQJExf6nnskG6ISISHQsSPs7jFEXLnnnnMLepfMtRLecU3gqQ7P2aJ1EXSQj8vHfCU5RucCMvd3pLgY9n3+A+8zidNOq98A3/jxUplx1Ki6v7Y6PDNHGjvk4pxr82b57wVK0KsU6EIFvUWQlyf3NYrdp59KEY8vvnALmrMSjIOzvXix5D77GmCpcXDytdfYceODrFghNVQAqQbVq5fkd19xhdhRVka/iAw2baq4OCQkiDhERXl76G3bys0fQX/uOfi/txK4kWe4dkbFPzy2f2eyguLEFmDHYlmmp9vxSbW6ie649Mnnw759ZH25CoCuYXtk4NLlocfESK/EK9Nl2zawlvTfSwk2ZX4JTVQU5OSHywIOs2eT7epZdPn9Z5lhVaWSlTees0XT0+UaEF1llQBvnI+gpgyMhG4yeLF9O7z+fiR76cgtt9evXx8fLyV365IdUxuegt7YHrrzPS5fLveHiofuDNI25aQiUEFvcPzy0De4Qg5r17oFfelS3B4giKAPGSJ/tCefrBB0zx9ItYJeVAS3385nz0poYPx4ZBTo++8l5cVZUmvAAOjfn6R9K9i8WTTPM+0rOto7y8URo86dxbmt7j1+8omkRZ7ZdTlP9Hka07XiX901PpSs9n0kU+X559kxeyGRQQVEfvRmDR+Y4Bb0PqMhOpqsr2Qpm9hC14fj8tCDg+WP7o6hg7vUY3phFN07FfqVoud+/w8+CPHx7HpIFk/osmlJjeEWT3srZw/V5kU7HnpNMW1nctHWTUU8mXomo+K21it+3lh49iwaW9DDw+XC60wLOFQEPSOj6XPQQQW9wamvoFsroW0Qz2vlSnGkL71UajovXy6DK55/lmoF/b33ICeHBZ0vIoFtHLFlvnjEHTvClVd6t504kaT0xRQWiuZ361bheEZFeYdcoqIszJ6Nyd1TY+/g6qthyBDLXHs+Icd59+VjYyGrNEoCxddfz46OA4nr3cbnwFVlHG8sc3cITJpE5ioJwMfkSDqkI+jgkZ/sXAG3boWVK0kngYR4/1Ykio529VA6doSXX2bXDslFjSlMq5Ogu4tG+SE2vXtLuMUpseALZ3LRrH9msZkkpl2aU33jAOA4BMbUe12LOp/PqUcUSEHPyxMRh4osWhX0Zkx5uZ8hFw9B37lTnMiYmIowi1PIavx4qQt+4ADMfq2MXrGFXjMHExKqqU3+/PMUHzaIL0tPYXyX5ZiLLxKRv+aaitUBHCZMIKlc7PnuO+8/hFvQcHnopVkyG+eKK0hIsD7fY26ueMaTT82hXdaWKvndsbGQXxBE4TXTYOxYdg48mbh4/2a0eKUCnnceWSWdiIo8QOhW17+nd8UsSbegx8dL/OX33ysEPamtX+fzvKAxdizZR40jiDI6UXOGi0PXrpLpkZvrv6CHhUmI7bbbqm+TMFC+wze/7Uk86Uy6q2/1jQOAZw+vlvWVG/R8ULVUQlPhlNB1/v9r18p9LcMsDY4KegOSny+iHhEhYuIzT9vaCkFfv54d2y3du8ukn88/K6es30AWPLyahAQrWXwJ+xjXeSllNpjE4k1eh3IEwivnfc0a+OEHfvjjA+zbZxj/0AliUFCQXB0qM2oUSV2kW1FQ4DrmF19A375EmRwPD90StX21KM68eSSUbPEp6O4CYoWuKfOVZmC6p8T/5T/w5ZfsyA7xe/q14+1lZQEnnkhWeA9izS5xh7p3lwC/C/ds0dBQeW7rVuzPK0g3PYjvVXPs28Hzggawa9hYooJyCW4bXmN6pYPn5KKMDP/Fpndvr7dShQ7942iPDO7e2ONjQqPaV984AHToIPY3drjFwfMC0qZN05yzMpVni65eLfZUN7DdWKigNyBOuOXww70L/HvhLBx51FGwfz87thYTFyfeeM6eIL5L6crClF6ML56HWbMaTj+dqXn/ACBx769epWB9pi6+8AKEhfFp0JmEhcGY82OkwNWnn/p2EYOC6DFxOGGImx8fXSSDgKmpRK9YRE6OnG/3zhKic3+TgP5xx5GQ/BEZGbZKNUK3oG9fIrGDwYO9nq884WbHDv9/9KGh8ifJygJCQsiKHkhsQar8e1wDog5xcRULLTi56HtXbKbAtvO7Wx4VJd+p043elRdKl8RIma7vh+vpvNe1a2WiUIOFA1yTi9qwn2vO3VV7+ybGGYdp7AwXB+f3E6hwC1Qt0LVmjfz0G7MwmS9U0BsQR9AdDfMZdnG880mTANix0xAXJ3niwaaMe8y/2EcHztj3tkwtX7aMU+dewZXHbeBPRW94VdKqkm1SUACzZ1N07oXMeS+C005zlS7t37/KEmmeBJ87gcNwTbhJnicJ79dfT1T6LxQUGIqKICc3iKi2RRJyefVVEsq3UlpqyM7yjke7s3E2fiG5cD5W8gG52OXny60uBZI8c7szQ+LpWr5DZm329Q47OAstZGcjcfRffyU93Xp9brURHS3XT+dPmp0NMfHhksPvB46grVhBnc5bK927cxUv8y/+SvQZh9BoqAfXXSfzK5oC5/cTSEH39NCtFUGvpsxPo6KC3oC4BX3RE0Atgn7uuRwgjJx9YcTFyQ/i2PZrWGKPJSwMTvnpIZkG/8EHBP15Ei+9aDmVhRLodlGlnsubb8LevcztfTdZWb4jLD455RSSgrfIMVd9LLnZTz9NdLz0+3//fD2lNoTo4wdKXzopiYTLxsh7fH2R16HS0iAiwtJl7TdVwi3gXYXQPamojoLuePdZ+RHERuTLhg8PHTxy0XNySEc+sLoIOlSEXdx1XOpgKzSCoIeGclv3udwaOtPnZ3wocOed0tFrCg41Qf/9d8mirdQ5bRJU0BsQt6Bvk9HNyoKekwNs3CgDk/37kxkn1YG6dQOKixlf+B4gFWMjBydK1/6ss+TFAwaImngIeocO0D6ilPRXF0ri8rXXYgcfwZOfJXH44TBmjJ+Gh4eT1FdiJwmHtRVBDw4m+ipZIT1litTC8PQG468eL+/xQ+9VptPSIDGmAGPLqwyIQkVZ3qwsj0lFdRB0J7e7pARycgyxg11XCB8eOnhnutRV0CuXP6iroHfpIl1uZzGFBhWcfv2kDmxDzl9vphxqgr5mjTxWD72Z4wh6H1IJDy71msX56aciRltX7hZxNoYdiSJ4cXHAL79wVqnUPTn7bKpiDBx/vJegs38/vQ9sYOGGBPb1HwGPPca3f1vMqlWGadPqFr8bPL4nhnJ6z7zDnbcYdYIM0W/KE1czKrGDu32PXvLT+X3FLjzXQ0tLg8Rwl1L7SI6OiJAwUGZm/QTdCblkZ7u2xxwhVzaP8qgg46DgWsPUlYue3vFw7/KqteDpoVvrUTrXT0JC5BjZ2fK4QQcJ33rLq+pka8bJTK1P6YOGwnMZutUyPUI99OZO7i5Ja+nMHhJCd3p56AsXStbLLxvCRdCBHbGSbBwXUwpLlnA46/jpkyyuvbaaE5xwgtQscdJa3n2Xh8vuYCP9uYC5lN58K0++EU10NFx0Ud1sv+j/hrL8J+h56gD3PkfQUnqc4rUNIk6d25ewriRJVt9xkZYGvYo2SfVC51deCcfLdgS9LpkAztJuzmfb9eiesqPSLNMePeT0yclUeOidjqBrV/+LJXmWEHYGR+uaV+2IePfuDVNv3E1cXNOlkRziJCbK91zL6niNStu28rtyPPSePV3LIjYxKugNSG6KuI0dk7qSUPQb6WkVeYtOka2UXZ0qBL2DrJwedyANliyBnj05+ozY6meUn3CC3Dte+vPPM67fFp591rBggUxE+ugjKSNeU9qbL0JCYPjR3j8HJ+SQ0u9Mr20Q73/wkGBWBw+VcrZIXfU9eyAxc1mNsV0nDr5jR0Xmir84MXgnzzc2Fp9dEWOkg7B0KSLoYWGkh/epU56y835zcipm8dZX0AMZDmgNDB/eNDnv1eGUytizRzz0QIRbwE9BN8aMM8ZsNMZsNsZM9/F8T2PMYmPMSmPMr8aY8Q1v6qFPbmoOkewj5I5pJLCN9FRJBTxwoGJgLIUkyToBdoZLmCNm52qpmeoj5uzFsGESM/3uO5l98uOPcN11XHOtYfp0eP99STe/4YaGeT9uDz3Fe9vhiCODWBN0JHb+x1BWVpGyeGCDpDlUgxM22blTvPO6hIYcgXS6tTU5qaNGifDvte3hp5/ICOtdJ2Ht2FE+z9276y/ozgVIBb3l07mzOCobNgQm3AJQ6zXNGBMMzATGAunAcmPMfGut52KL9wLvWGufM8YMAhYAiY1g7yFNbno+nUweXHIJCTc9S0Z2GOXlsGqV5CEbY9lk+8EAiTHsKI0llixCFn0uwd7aMhZCQkT0v/tOgrrh4ZJGiNTwLy6Wbl5DzZaLiJBTbNsm25Vn5w8eDHtLIti2uy09lywhLX0YEEniCT3FZaqG2Fi5FrmXnqsDlQW9plzn0aPlY1q+HMaMGUJ6BvzhRP/PFRQkf9Lduyti9nWJoXvaq4Le8uncWXriJSWHtoc+EthsrU211hYDc4HKy39bwIkYdQQaYb2eQ5/crGI6tSmCtm1JSIqguDyUXbtc3X7g5F5bxEN3jd7s2BVKXNhuGeCC2j10kLDL6tUwe7aUm3WpbFCQlGt54IGGez9ON9JaScypHApyfrSrQ46CefNIm/0tAIkPXFbjcbt2FY83I6PuM+kcAV+zRi42lSsZeDJypNwvXSop+nv21F1YndmiGnJRaqNz54o5EoeyoMcD2zy20137PJkBXGyMSUe885t9HcgYc40xJtkYk5ztuDzNBWulcPm771b7fG4udOrgmrwyWv7B6ct3sHSp/KFPbLecbfRkf7msMLNjB8R13C+za9q2haFDa7fjhBPElvz8GsMaDYUTZvEV53a6lav7TIB33yXtq99oG3yAmFNq/jXHxsqkn02b6u+h79wpj2sK13TuLMMVy5Z5lwauC07FxYMNuQSqxojSdDg5AMHB7qhqk9NQg6KTgdestQnAeGCOMabKsa21s6y1I6y1I2Lq2ncNJHl5snjxJZdI+UMnPcOTjAzySiPoFCNRrIRTZY3K9M9Ws2yZdP+T9kog3anE5jXt/eija62vDUhgODRU1NQfj/4gccIsvoohduokArmm0/GwbRtpxd1J7GVrjYk7olxSUndBj4ysqNfhz9TyUaPEQ3fCRnUVdKcmfHa29AjqmvbtnM+jbpjSQnEEvX//atcOb3T8EfQMwHOZ0wTXPk+uBN4BsNb+CLQBmqBwZhPw888yGPnBBzL9rbQUHnqoartVq8ilEx3j5B+f8AeZufjz4r1s2QKjR5aTlPk9IIOM5eXSPYtLdH3z/opzRAQ89ZSscNsEhSJq8tBBupar8xMhKIi0TsNI7F97dSRPIa6roBtT8Xp/svZGjxYxdhKDDsZDj4mp+0d+2mmS1elHcUalmeMIeqDCLeCfoC8HkowxvY0xYcAFwPxKbbYCYwCMMQMRQW9mMRUfFBXJLJ/SUilw9cgjMgj5wgtV13775Rdy6USnRFl5PbarIcSU8v4GmZwzOmoTScUyhWzTJhGIsjKIG9pV+mg11FqpwnXXyXTSJqA2QR88GDZsDqXki69IM4l+1X/2FOK6Crrn6/0VdJDqwVD30Ifjodd1lqhDUJDM2G3qIk1K0+P0YgOV4QJ+CLq1thS4CfgCWI9ks6w1xvzdGOPMabwduNoY8wvwX2CKtdb6PmIzYtYsmcQze3ZFBsq994oS//vfXk3tKpegx8qslaAg6B5bytrygYRQwlFXDaMje4ntXExKiscsySGxohannNKU78xvagq5gHgjxcWwssOJ5OwJ8mvJLU8hrk950boI+uDB0qlZu1beQ13z86OjpS7H9u1Ns1iD0nw5FDx0v1LxrbULkMFOz333ezxeBxzXsKYFmP37RbRPOkluDomJsh7niy/CX/4iUxKB/FWbKSeYTp0qmib0bcPWTBjS/wBtL7kXtm8naWWIt6DHgdeLDjH8CbmArD8N/q3QEhUlnZKysvp56E7IxZ8YekiIhDu+/bZ+mSbO+960ye8ii0orZdQoGQo7LoBKqDNFq+P55yWV4m9/q/rcPfdIpsl998l9QQG5myUNwkvQXQIy+o+R8pqZM0nqH0RKSkWlwaYugF9XavPQBwwQcf7kE9n2R9CDgiri0fWpmV0XDx0qwi71EXTnfefn1z0HXWld9O8vyzgGsiengu4Dm1+A/fdDEvz8wx+qNujZE6ZOhddfh4kT4ZtvyKUjUI2ge9SoSkoS79yZfVkfD7Upqc1Db9NG3tOqVbLt7xqKsbHyw/cnscfXaz3va+NgBN3zfWvIRTnUUUGvRHY2HJlUyG3Z03175w6PPAJPPCELgE6YQC6i5J6C7sSTPQXdqSH13XcytbyuMd2mxp/whhN2adPGf5GNj6//ZBtnYNOpqFgbzufvT3y/Mp49ExV05VAngOVsDj3274ezxxWzZmcMm8yNTD8sjGp1zBjx0o87Ds4/n9zcvpDjLehTpsikUM+ynklJcr9sWZU1GQ5JjjlGasTUVFt98GCZb5WY6H82x+OPSxJRfZg4ET780P8FeOPi4PPPq1TY9QtPD11DLsqhjnroLsrK4OKLLctWhPBQyL0U2zBeeMGPF44YAWvWkPv3pwBvQe/QQdYK9cQR9+LiQz9+DiLQ555bc+lXx0P3N9wCEm8cMqR+NoWFiajXJRXwtNOqHweoCQ25KM0JFXQX06fDBx8YHuM2/vJoDOPHw7PPSqVEX6xcCQucvJ+2bcktl1I2tSWstGtXESo41OPn/uLk3dZF0JsL7dpVxPlV0JVDHRV0pGjT449bLg+Zw7QTV8HNNzN1qszkfOedqu2thYsvlioATra9s1pRx461n88Ju7QUQe/TR0Izh2gq/UFhTIWXroKuHOqooANffmEpKzNcHfIqvPIKBAUxdiwMHCix3spTpBYtgnXrZEq4k36Ym+vtzdVESxP04GBZn+PPfw60JY2DE6pRQVcOdVTQgU+f20o0uxj58CT3SKUz5rlyJXz/vXf7J5+siN86C8Lm5vo/P8jJdGkOMXRFPPSOHeuXYqkoTUmLFPStWyVVfOPG2tuWF+zns+8jGddpKcE3eC/mecklMp33vvukMiBI/vinn1asCuQstFAXQXdKa2pJ1eZBbKwu36k0D1qkoG/YIOVSFy+uvW3yHXPZVR7N+Bt6V1mUMCJCQi7ffCP1sKyVQodhYVLSpWvX+nnop58ukR1fc5aUQ4+//U2+L0U51GmReej5+XLveM/VkpHBpy/tIIgyTrvNd1LzZZdJ/fJ//ENiqK+9BpMnS7hk8OCKc+Tl+R9CCQ2Fyy/3r60SePzNd1eUQNMiPfSCArl3vGdP/vtfWcgVgOnTWVB2KqOPKqlx5fm//U3CL488IheLqVNl/xFHSBW/8vK6eeiKoiiNQYv30K2tGMDctAkuvFDWq/jmld8oeGMhyczhwXNrPp4x8NJLItqhofJ6EA99/35ITVVBVxQl8LRoQd+zR+pYO4OPP/4o9ytXwnnnljDJnA0Wzjij9mOGhcH8+d4pjO5FkleLoPuTg64oitJYtMiQiyPo4B12WbpUpuM//3QJn28ZwNSgp4iLq9sUdM/p5k5sdelSKR2gHrqiKIGkRQp6QYHU3AbvgdFly2DkSLg2+j3u5l8UlrVh/Pj6Lw/Wrp2krTvrVaqgK4oSSFqkoOfnS0ZK9+4Vgl5QAL/+6iql+vzzPNj7FV6aVV5jhVx/OOIISE6WxyroiqIEkhYr6O3ayaClE3L5+WcJi4yO3wbffkvQdddw5dVBBz25Z/DgiklHKuiKogSSFinoBQUQGSne87p1IuRLl8pzI1c8L6kqU6Y0yLk8F4RVQVcUJZC0SEHPzxdBHzxYFlH47TcR9L59LDHvPguTJjXYXG4VdEVRDhVatKB7phUuXQqjk3ZLfmEDlgVMSqoo2qSCrihKIPFL0I0x44wxG40xm40x0308/7gxZpXrtskYk9vwpvqPE0MfNEgyWBYskIWZR3dYJw3qsxZZNYSGSpld0Dx0RVECS60Ti4wxwcBMYCyQDiw3xsy31q5z2lhrb/VofzMwrBFs9Rsnht62rSz5Nneu7B+9f7GEWuq7OnE1DB4MmzfL5CNFUZRA4Y+HPhLYbK1NtdYWA3OBCTW0nwz8tyGMqy9OyAUk7FJYCOHhcGTqPBg+vP6J59Vw110wc2aDHlJRFKXO+CPo8cA2j+10174qGGN6Ab2Br6p5/hpjTLIxJjk7O7uutvqNp6A7610OH1ZG2IZfZVHnBmbIkAZLmlEURak3DT0oegHwnrW2zNeT1tpZ1toR1toRMTExDXxqoaxMCma1ayfbzsDo6MRMKYvYCIKuKIpyKOCPoGcAPTy2E1z7fHEBAQ63FBbKveOhjxwpse1TO/0kO1TQFUVpofgj6MuBJGNMb2NMGCLa8ys3MsYMADoDPzasiXXDKczlCHrPnrKY82kFH8iqzN27B844RVGURqRWQbfWlgI3AV8A64F3rLVrjTF/N8ac7dH0AmCutZ4FZpueyoLufpycLAOiiqIoLRS/6qFbaxcACyrtu7/S9oyGM6v+OKsVOTF0APbtk4VGzz8/IDYpiqI0BS1upqgvD51Vq2RlCo2fK4rSgmkdgu7Ut9WQi6IoLZjWI+gJCdCtW0BsUhRFaQpanKD7jKEnJ2u4RVGUFk+LE/QqHnpeHmzapOEWRVFaPC1f0FetknsVdEVRWjgtUtCNkUqLAKxYIfdHHRUwmxRFUZqCFifoBQUSP3cXVFy5UmaIdu0aULsURVEamxYn6J6VFgHx0NU7VxSlFdCyBX3/fpkhOiyg620oiqI0CS1b0Fevlnq6KuiKorQCWpygOzF0QAdEFUVpVbQ4Qffy0FeuhM6doVevgNqkKIrSFLRsQV+xQsItDbyGqKIoyqFIixP0ggKXoJeUSAxd4+eKorQSWpyg5+e7YugbNsCBAxo/VxSl1dAiBT0ykooBUfXQFUVpJbQoQS8tFac8MhIZEI2IgH79Am2WoihKk9CiBN0pnev20IcMgeDggNqkKIrSVLQoQXcqLbZrWy5VFjXcoihKK6JFCnpkYZYsDK0DooqitCJapqDnbpMHgwYFzhhFUZQmxi9BN8aMM8ZsNMZsNsZMr6bNecaYdcaYtcaYtxrWTP9wx9D37ZQHPXoEwgxFUZSAEFJbA2NMMDATGAukA8uNMfOttes82iQBdwPHWWv3GGNiG8vgmnDH0HMzZDA0Li4QZiiKogQEfzz0kcBma22qtbYYmAtMqNTmamCmtXYPgLU2q2HN9A93yCVnK3TvrhkuiqK0KvwR9Hhgm8d2umufJ/2AfsaYH4wxS40x43wdyBhzjTEm2RiTnJ2dXT+La8At6NlbNNyiKEqro6EGRUOAJOAkYDLwojGmU+VG1tpZ1toR1toRMTExDXTqCtwx9J2bISGhwY+vKIpyKOOPoGcAnu5ugmufJ+nAfGttibV2C7AJEfgmxR1D356iHrqiKK0OfwR9OZBkjOltjAkDLgDmV2ozD/HOMcZ0QUIwqQ1op1/k50NwsCX8QJ4KuqIorY5aBd1aWwrcBHwBrAfesdauNcb83RhztqvZF8BuY8w6YDFwp7V2d2MZXR0FBRDZtgwDKuiKorQ6ak1bBLDWLgAWVNp3v8djC9zmugWM/HxoF1YiGyroiqK0MlrcTNHIkCLZ0EFRRVFaGS1P0E0hhIZC166BNkdRFKVJaVGCXlAAkXYvxMdDUIt6a4qiKLXSolQvPx/alWiGi6IorZMWJ+iRxbtV0BVFaZW0MEG3RO7P1gFRRVFaJS1K0AvyLZHle9VDVxSlVdKiBD0/H9pRoIKuKEqrpMUIenExlJQGEUm+CrqiKK2SFiPo7kqLKuiKorRSWoygu2uhhxyALl0Ca4yiKEoAaHGC3i4qHIwJrDGKoigBoMUJemRsRGANURRFCRAtRtDdMfS49oE1RFEUJUD4VT73UOXbb+HMMyXDpazMAob2CR0DbZaiKEpAaNaCvmIF7NsHt94KYcX5dJr5T4YM7x1osxRFUQJCsxb03bulqOKjj0LQ8nUw82Ho9XGgzVIURQkIzTqGnpMDnTu7KuVu3y474+MDapOiKEqgaNaCvns3REV5bIDmoCuK0mpp9oIeHe3a2LNH7t0KryiK0rpo1oKek+Mh6Dk5EBYGEZqHrihK66RZC7pXyCUnRzZ049n9MgAAFANJREFUlqiiKK0UvwTdGDPOGLPRGLPZGDPdx/NTjDHZxphVrttVDW9qVap46J07N8VpFUVRDklqTVs0xgQDM4GxQDqw3Bgz31q7rlLTt621NzWCjT4pLpYc9CoeuqIoSivFHw99JLDZWptqrS0G5gITGtes2snJkXsvD10FXVGUVow/gh4PbPPYTnftq8wkY8yvxpj3jDE+C5IbY64xxiQbY5Kzs7PrYW4FKuiKoijeNNSg6MdAorX2SGAh8LqvRtbaWdbaEdbaETExMQd1QiftXEMuiqIogj+CngF4etwJrn1urLW7rbUHXJsvAcMbxrzq8fLQS0qkfq4KuqIorRh/BH05kGSM6W2MCQMuAOZ7NjDGxHlsng2sbzgTfePloeukIkVRlNqzXKy1pcaYm4AvgGDgFWvtWmPM34Fka+184BZjzNlAKZADTGlEm4FKHnqGa0MFXVGUVoxf1RattQuABZX23e/x+G7g7oY1rWZ274aQEIiMpELdNQ9dUZRWTLOdKerUcTGGCkFXD11RlFZMsxX0KrNEQQVdUZRWTbMV9Cp1XEAFXVGUVk2zFfQqHrox0FHXE1UUpfXSbAW9iofuXrpIURSlddJsFbDK4hYablEUpZXTLAV9/34oKtI6LoqiKJ40S0H3WcdFc9AVRWnlNEtB10qLiqIoVWmWgq6VFhVFUarSrAU9OhooL9dBUUVRFJqpoHuFXPLywFoVdEVRWj3NUtC9Qi46S1RRFAVopoKekwNt28pNa6EriqIIzVLQfdZx0bRFRVFaOc1W0LXSoqIoijfNUtC1dK6iKEpVmqWga8hFURSlKs1S0Kt46JGREBYWUJsURVECTbMTdGt9eOgablEURWl+gr5vH5SWah0XRVGUyjQ7Qa8yBqqCriiKAvgp6MaYccaYjcaYzcaY6TW0m2SMscaYEQ1nojdedVxAJhbpgKiiKAohtTUwxgQDM4GxQDqw3Bgz31q7rlK79sBUYFljGOqgpXOVlkhJSQnp6ekUFRUF2hTlEKFNmzYkJCQQGhrq92tqFXRgJLDZWpsKYIyZC0wA1lVq9w/gYeBOv89eD7zquFirgq60CNLT02nfvj2JiYkYYwJtjhJgrLXs3r2b9PR0evfu7ffr/Am5xAPbPLbTXfvcGGOOAnpYaz+t6UDGmGuMMcnGmOTs7Gy/jfTEy0MvLITiYhV0pdlTVFREdHS0irkCgDGG6OjoOvfYDnpQ1BgTBDwG3F5bW2vtLGvtCGvtiJiYmHqdLyQEevRwhc11lqjSglAxVzypz+/BH0HPAHp4bCe49jm0BwYDXxtj0oDRwPzGGhi95hrYutU1j0gFXVEUxY0/gr4cSDLG9DbGhAEXAPOdJ621edbaLtbaRGttIrAUONtam9woFnuigq4oDcLu3bsZOnQoQ4cOpVu3bsTHx7u3i4uLa3xtcnIyt9xyS63nOPbYYxvKXKUaah0UtdaWGmNuAr4AgoFXrLVrjTF/B5KttfNrPkIjonVcFKVBiI6OZtWqVQDMmDGDyMhI7rjjDvfzpaWlhIT4losRI0YwYkTtHfIlS5Y0jLFNSFlZGcHBwYE2w2/8yXLBWrsAWFBp3/3VtD3p4M3yk6wsue/SpclOqSiNzrRp4BLXBmPoUHjiiTq9ZMqUKbRp04aVK1dy3HHHccEFFzB16lSKiopo27Ytr776Kv379+frr7/m0Ucf5ZNPPmHGjBls3bqV1NRUtm7dyrRp09zee2RkJPn5+Xz99dfMmDGDLl26sGbNGoYPH84bb7yBMYYFCxZw22230a5dO4477jhSU1P55JNPvOxKS0vjkksuoaCgAIBnnnnG7f0//PDDvPHGGwQFBXH66afz0EMPsXnzZq677jqys7MJDg7m3XffZdu2bW6bAW666SZGjBjBlClTSExM5Pzzz2fhwoXcdddd7Nu3j1mzZlFcXMxhhx3GnDlziIiIIDMzk+uuu47U1FQAnnvuOT7//HOioqKYNm0aAPfccw+xsbFMnTq1/t9dHfBL0A9ZUlIgIgLi4gJtiaK0SNLT01myZAnBwcHs3buX7777jpCQEBYtWsRf//pX3n///Sqv2bBhA4sXL2bfvn3079+f66+/vkou9cqVK1m7di3du3fnuOOO44cffmDEiBFce+21fPvtt/Tu3ZvJkyf7tCk2NpaFCxfSpk0bUlJSmDx5MsnJyXz22Wd89NFHLFu2jIiICHJcPfiLLrqI6dOnc84551BUVER5eTnbtm3zeWyH6OhoVqxYAUg46uqrrwbg3nvv5eWXX+bmm2/mlltu4cQTT+TDDz+krKyM/Px8unfvzrnnnsu0adMoLy9n7ty5/PTTT3X+3OtL8xb0jRshKQmCml0FA0Wpnjp60o3Jn//8Z3fIIS8vj8suu4yUlBSMMZSUlPh8zRlnnEF4eDjh4eHExsaSmZlJQkKCV5uRI0e69w0dOpS0tDQiIyPp06ePO+968uTJzJo1q8rxS0pKuOmmm1i1ahXBwcFs2rQJgEWLFnH55ZcTEREBQFRUFPv27SMjI4NzzjkHkMk6/nD++ee7H69Zs4Z7772X3Nxc8vPzOe200wD46quvmD17NgDBwcF07NiRjh07Eh0dzcqVK8nMzGTYsGFEu2dBNj7NW9A3bYJhwwJthaK0WNq1a+d+fN9993HyySfz4YcfkpaWxkknneTzNeHh4e7HwcHBlJaW1qtNdTz++ON07dqVX375hfLycr9F2pOQkBDKy8vd25XzvT3f95QpU5g3bx5Dhgzhtdde4+uvv67x2FdddRWvvfYaO3fu5IorrqizbQdD83Vti4thyxbo3z/QlihKqyAvL4/4eJlT+NprrzX48fv3709qaippaWkAvP3229XaERcXR1BQEHPmzKGsrAyAsWPH8uqrr1JYWAhATk4O7du3JyEhgXnz5gFw4MABCgsL6dWrF+vWrePAgQPk5ubyv//9r1q79u3bR1xcHCUlJbz55pvu/WPGjOG5554DZPA0Ly8PgHPOOYfPP/+c5cuXu735pqL5CnpqKpSVQb9+gbZEUVoFd911F3fffTfDhg2rk0ftL23btuXZZ59l3LhxDB8+nPbt29OxY8cq7W644QZef/11hgwZwoYNG9ze9Lhx4zj77LMZMWIEQ4cO5dFHHwVgzpw5PPXUUxx55JEce+yx7Ny5kx49enDeeecxePBgzjvvPIbV0NP/xz/+wahRozjuuOMYMGCAe/+TTz7J4sWLOeKIIxg+fDjr1kk1lLCwME4++WTOO++8Js+QMdbaJj2hw4gRI2xy8kGkqs+fDxMmwLJlMHJkwxmmKAFg/fr1DBw4MNBmBJz8/HwiIyOx1nLjjTeSlJTErbfeGmiz6kR5eTlHHXUU7777LklJSQd1LF+/C2PMz9Zan3mizddD37hR7g/yA1MU5dDhxRdfZOjQoRx++OHk5eVx7bXXBtqkOrFu3ToOO+wwxowZc9BiXh+a76Dopk0QE6OTihSlBXHrrbc2O4/ck0GDBrnz0gNB8/XQN23SAVFFURQPmq+gb9yoA6KKoigeNE9Bz8uDzEz10BVFUTxonoKekiL36qEriqK4aZ6C7mS4qIeuKA3CySefzBdffOG174knnuD666+v9jUnnXQSTurx+PHjyc3NrdJmxowZ7nzw6pg3b547hxvg/vvvZ9GiRXUxX3HRPAV90yap39KnT6AtUZQWweTJk5k7d67Xvrlz51ZbIKsyCxYsoFOnTvU6d2VB//vf//7/7d17bFR5FcDx7+GxWxcIDzGblS62Is86DB0eIu9d+wespJV3QSJNNyE0EBc0PAwGogmJCNHFpNmEwOJqdFvEBsoCGsUFSRqxMHYKW6jbSt3twpaH7lJ5LdXjH/d2HNvOMoUZZufO+SQTeh8z93dyhtOZX+89l7y8vId6rWRpv1o12VKzoNfXQ1YWRPSDMMYr1q6FWbPi+3C7uUa1cOFCjhw5Er6ZRVNTE5cvX2b69OmUlJQwYcIEcnJy2Lp1a5fPz8rK4vr16wBs27aNESNGMG3aNOrbv03jnGM+ceJE/H4/CxYs4Pbt21RVVVFZWcn69esZN24cjY2NFBUVceDAAQCOHz9Obm4uPp+P4uJi7t27Fz7e1q1bCQQC+Hw+Ll682GlMTU1NTJ8+nUAgQCAQ+L9+7Nu3b8fn8+H3+9m0aRMADQ0N5OXl4ff7CQQCNDY2cuLECebOnRt+3po1a8JtD7Kysti4cWP4IqKu4gNoaWlh3rx5+P1+/H4/VVVVbNmyhZcjmrBt3ryZXbt2fXySYpCaBd1OWTQmrgYNGsSkSZM4duwY4Hw6X7x4MSLCtm3bOHPmDLW1tZw8eZLa2tqor3P27FnKysqoqanh6NGjVFdXh7fNnz+f6upqQqEQo0ePZu/evUyZMoX8/Hx27NhBTU0Nw4YNC+9/9+5dioqKKC8v59y5c7S1tYV7pwAMHjyYYDBISUlJl9M67W12g8Eg5eXl4b7skW12Q6EQGzZsAJw2u6tXryYUClFVVcUzMbTlbm+zW1hY2GV8QLjNbigUIhgMkpOTQ3FxcbhTY3ub3eXLlz/weA+SehcWqToFfcaMZI/EmIRIVvfc9mmXgoICysrKwgVp//797N69m7a2Nq5cuUJdXR1jx47t8jVOnTrFvHnzwi1s8/Pzw9uitaGNpr6+nuzsbEa4Jz+sWLGC0tLS8M0j5s+fD8D48eOpqKjo9Px0bLObegX98mW4dcs+oRsTZwUFBaxbt45gMMjt27cZP348ly5dYufOnVRXVzNw4ECKioo6tZqNVXfb0D5IewveaO1307HNbupNubi/Ze2URWPiq2/fvjz33HMUFxeH/xh68+ZN+vTpQ//+/WlpaQlPyUQzY8YMDh48yJ07d2htbeXw4cPhbdHa0Pbr14/W1tZOrzVy5EiamppoaGgAnK6JM2fOjDmedGyzm3oF3U5ZNCZhli5dSigUChd0v99Pbm4uo0aNYtmyZUydOvVjnx8IBFiyZAl+v585c+YwceLE8LZobWgLCwvZsWMHubm5NDY2htdnZGSwb98+Fi1ahM/no0ePHqxatSrmWNKxzW7qtc89dAj27YOKCrv1nPEMa5+bfmJps+v99rkFBXDwoBVzY0zKSlSb3Zj+KCois4FdQE9gj6r+oMP2VcBq4N/Av4CVqlrX6YWMMcYkrM3uAz/mikhPoBSYA4wBlorImA67/VJVfao6Dvgh8KO4j9QYj0vW9Kf5ZHqY90Ms8xaTgAZV/ZuqfgSUAQUdDnwzYrEPYO9MY7ohIyODGzduWFE3gFPMb9y40e1TLWOZchkCvBux3Ax8qeNOIrIa+BbwBPB8Vy8kIiuBlQBDhw7t1kCN8bLMzEyam5u5du1asodiPiEyMjLIzMzs1nPidmGRqpYCpSKyDPgusKKLfXYDu8E5yyVexzYm1fXu3Zvs7OxkD8OkuFimXN4Dno1YznTXRVMGfO1RBmWMMab7Yino1cBwEckWkSeAQqAycgcRiTzv5qvA2/EbojHGmFg8cMpFVdtEZA3wW5zTFl9V1bdE5PvAGVWtBNaISB5wH/gnXUy3GGOMSaykXSkqIteAvz/k0wcD1+M4nFSRjnGnY8yQnnGnY8zQ/bg/p6qf6WpD0gr6oxCRM9EuffWydIw7HWOG9Iw7HWOG+MZt188bY4xHWEE3xhiPSNWCvjvZA0iSdIw7HWOG9Iw7HWOGOMadknPoxhhjOkvVT+jGGGM6sIJujDEekXIFXURmi0i9iDSIyKZkjycRRORZEXlTROpE5C0RecldP0hEficib7v/Dkz2WONNRHqKyF9E5A13OVtETrv5LnevVvYUERkgIgdE5KKIXBCRL6dJrte57+/zIvK6iGR4Ld8i8qqIXBWR8xHrusytOH7ixl4rIoHuHi+lCnqMvdm9oA34tqqOASYDq904NwHHVXU4cNxd9pqXgAsRy9uBH6vqF3CuQn4xKaNKrF3Ab1R1FODHid/TuRaRIcA3gQmq+kWcq9AL8V6+fwrM7rAuWm7nAMPdx0rgle4eLKUKOjH0ZvcCVb2iqkH351ac/+BDcGJ9zd3tNTzWBE1EMnF6Ae1xlwWnFfMBdxcvxtwfmAHsBVDVj1T1Azyea1cv4FMi0gt4CriCx/Ktqn8E/tFhdbTcFgA/U8efgAEi8kx3jpdqBb2r3uxDkjSWx0JEsoBc4DTwtKpecTe9DzydpGElysvABuA/7vKngQ9Utc1d9mK+s4FrwD53qmmPiPTB47lW1feAncA7OIX8Q+As3s83RM/tI9e3VCvoaUVE+gK/BtZ2uCsU6pxv6plzTkVkLnBVVc8meyyPWS8gALyiqrnALTpMr3gt1wDuvHEBzi+0z+Lc6azj1ITnxTu3qVbQu9ubPWWJSG+cYv4LVa1wV7e0fwVz/72arPElwFQgX0SacKbSnseZWx7gfiUHb+a7GWhW1dPu8gGcAu/lXAPkAZdU9Zqq3gcqcN4DXs83RM/tI9e3VCvoD+zN7gXu3PFe4IKqRt5wu5L/tSZeARx63GNLFFX9jqpmqmoWTl7/oKpfB94EFrq7eSpmAFV9H3hXREa6q74C1OHhXLveASaLyFPu+709bk/n2xUtt5XAN9yzXSYDH0ZMzcRGVVPqAbwA/BVoBDYnezwJinEaztewWqDGfbyAM6d8HOcGIr8HBiV7rAmKfxbwhvvz54E/Aw3Ar4Ankz2+BMQ7Djjj5vsgMDAdcg18D7gInAd+DjzptXwDr+P8jeA+zrexF6PlFhCcs/gagXM4ZwB163h26b8xxnhEqk25GGOMicIKujHGeIQVdGOM8Qgr6MYY4xFW0I0xxiOsoBtjjEdYQTfGGI/4LyrPka1vJgE6AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oaZH-D3hxaA",
        "outputId": "1a740497-2422-4c58-bba2-9d0c1e81731c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.8977\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.24692033231258392, 0.8977272510528564]"
            ]
          },
          "metadata": {},
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.evaluate(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBFLMG-GSZ74",
        "outputId": "b7f86bc5-9de3-494f-e3e4-399bdb1658c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 1ms/step - loss: 0.1985 - accuracy: 0.9144\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.19852496683597565, 0.9144254326820374]"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model 3"
      ],
      "metadata": {
        "id": "ylcxYzKw3PMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(512, input_shape=[4],activation=tf.keras.activations.elu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.elu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.elu),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.keras.activations.elu),\n",
        "                                    tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
        "                                    ])"
      ],
      "metadata": {
        "id": "Fd1MXWcR3Rie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.compile(loss=SparseCategoricalCrossentropy(from_logits=False),optimizer=adam,metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "i7P4x0oqSna2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_3.fit(X_train, y_train, batch_size=16, epochs=400, callbacks=callback,  verbose=1)"
      ],
      "metadata": {
        "id": "ky8Gq981gQqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_3.fit(X_train, y_train, validation_data = (X_valid,y_valid), batch_size=16, epochs=100,  verbose=1)"
      ],
      "metadata": {
        "id": "yzt42fQV3Rif",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c3bdbcf-09ca-4610-f67e-f29c0af62b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 3.9186 - accuracy: 0.3472 - val_loss: 1.0802 - val_accuracy: 0.3750\n",
            "Epoch 2/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1.1872 - accuracy: 0.4205 - val_loss: 1.0478 - val_accuracy: 0.5341\n",
            "Epoch 3/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1.0969 - accuracy: 0.4401 - val_loss: 1.0395 - val_accuracy: 0.4091\n",
            "Epoch 4/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1.0395 - accuracy: 0.4841 - val_loss: 0.9290 - val_accuracy: 0.6250\n",
            "Epoch 5/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8457 - accuracy: 0.6088 - val_loss: 0.9191 - val_accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.7270 - accuracy: 0.6553 - val_loss: 0.6528 - val_accuracy: 0.6136\n",
            "Epoch 7/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5925 - accuracy: 0.7164 - val_loss: 0.5708 - val_accuracy: 0.7159\n",
            "Epoch 8/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.8020 - val_loss: 0.5166 - val_accuracy: 0.7614\n",
            "Epoch 9/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7873 - val_loss: 0.4909 - val_accuracy: 0.7727\n",
            "Epoch 10/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.8117 - val_loss: 0.4187 - val_accuracy: 0.8409\n",
            "Epoch 11/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3957 - accuracy: 0.8264 - val_loss: 0.4132 - val_accuracy: 0.8068\n",
            "Epoch 12/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8044 - val_loss: 0.7198 - val_accuracy: 0.7273\n",
            "Epoch 13/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7751 - val_loss: 0.5445 - val_accuracy: 0.7955\n",
            "Epoch 14/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.8093 - val_loss: 0.4937 - val_accuracy: 0.7841\n",
            "Epoch 15/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3715 - accuracy: 0.8460 - val_loss: 0.4698 - val_accuracy: 0.8295\n",
            "Epoch 16/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3730 - accuracy: 0.8460 - val_loss: 0.3635 - val_accuracy: 0.8409\n",
            "Epoch 17/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3635 - accuracy: 0.8411 - val_loss: 0.3891 - val_accuracy: 0.8409\n",
            "Epoch 18/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3620 - accuracy: 0.8313 - val_loss: 0.3849 - val_accuracy: 0.8750\n",
            "Epoch 19/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.8215 - val_loss: 0.4130 - val_accuracy: 0.7955\n",
            "Epoch 20/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3180 - accuracy: 0.8606 - val_loss: 0.2999 - val_accuracy: 0.8750\n",
            "Epoch 21/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3111 - accuracy: 0.8631 - val_loss: 0.3384 - val_accuracy: 0.8295\n",
            "Epoch 22/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3017 - accuracy: 0.8680 - val_loss: 0.3074 - val_accuracy: 0.8750\n",
            "Epoch 23/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3017 - accuracy: 0.8680 - val_loss: 0.6330 - val_accuracy: 0.7273\n",
            "Epoch 24/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3758 - accuracy: 0.8386 - val_loss: 0.3048 - val_accuracy: 0.8750\n",
            "Epoch 25/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3180 - accuracy: 0.8680 - val_loss: 0.4714 - val_accuracy: 0.7841\n",
            "Epoch 26/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2803 - accuracy: 0.8753 - val_loss: 0.2609 - val_accuracy: 0.8864\n",
            "Epoch 27/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2356 - accuracy: 0.8998 - val_loss: 0.4029 - val_accuracy: 0.7841\n",
            "Epoch 28/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3437 - accuracy: 0.8386 - val_loss: 1.1077 - val_accuracy: 0.6023\n",
            "Epoch 29/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.7702 - val_loss: 0.2940 - val_accuracy: 0.8523\n",
            "Epoch 30/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2651 - accuracy: 0.8949 - val_loss: 0.3279 - val_accuracy: 0.8750\n",
            "Epoch 31/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2760 - accuracy: 0.8949 - val_loss: 0.5011 - val_accuracy: 0.7500\n",
            "Epoch 32/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2603 - accuracy: 0.8924 - val_loss: 0.2749 - val_accuracy: 0.9091\n",
            "Epoch 33/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3480 - accuracy: 0.8606 - val_loss: 0.3565 - val_accuracy: 0.7841\n",
            "Epoch 34/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2836 - accuracy: 0.8631 - val_loss: 0.2560 - val_accuracy: 0.8636\n",
            "Epoch 35/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2993 - accuracy: 0.8533 - val_loss: 0.2624 - val_accuracy: 0.8864\n",
            "Epoch 36/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.8875 - val_loss: 0.2454 - val_accuracy: 0.9091\n",
            "Epoch 37/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2005 - accuracy: 0.9193 - val_loss: 0.3863 - val_accuracy: 0.8636\n",
            "Epoch 38/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2109 - accuracy: 0.9169 - val_loss: 0.2366 - val_accuracy: 0.8977\n",
            "Epoch 39/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2698 - accuracy: 0.8729 - val_loss: 0.4747 - val_accuracy: 0.7955\n",
            "Epoch 40/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2698 - accuracy: 0.8973 - val_loss: 0.2722 - val_accuracy: 0.8977\n",
            "Epoch 41/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1965 - accuracy: 0.9218 - val_loss: 0.3951 - val_accuracy: 0.8523\n",
            "Epoch 42/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2630 - accuracy: 0.8900 - val_loss: 0.3971 - val_accuracy: 0.8523\n",
            "Epoch 43/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8362 - val_loss: 0.3976 - val_accuracy: 0.8182\n",
            "Epoch 44/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3072 - accuracy: 0.8704 - val_loss: 0.3276 - val_accuracy: 0.8977\n",
            "Epoch 45/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2788 - accuracy: 0.8753 - val_loss: 0.3393 - val_accuracy: 0.8409\n",
            "Epoch 46/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1995 - accuracy: 0.9267 - val_loss: 0.4069 - val_accuracy: 0.8182\n",
            "Epoch 47/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2685 - accuracy: 0.8729 - val_loss: 0.2741 - val_accuracy: 0.8977\n",
            "Epoch 48/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2305 - accuracy: 0.9022 - val_loss: 0.2256 - val_accuracy: 0.9318\n",
            "Epoch 49/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1606 - accuracy: 0.9389 - val_loss: 0.3582 - val_accuracy: 0.8182\n",
            "Epoch 50/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2436 - accuracy: 0.8900 - val_loss: 0.2038 - val_accuracy: 0.8977\n",
            "Epoch 51/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1719 - accuracy: 0.9291 - val_loss: 0.2383 - val_accuracy: 0.9318\n",
            "Epoch 52/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2200 - accuracy: 0.9120 - val_loss: 0.2369 - val_accuracy: 0.9205\n",
            "Epoch 53/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2588 - accuracy: 0.8973 - val_loss: 0.2093 - val_accuracy: 0.8864\n",
            "Epoch 54/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1728 - accuracy: 0.9438 - val_loss: 0.1998 - val_accuracy: 0.9318\n",
            "Epoch 55/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2019 - accuracy: 0.9242 - val_loss: 0.2268 - val_accuracy: 0.9432\n",
            "Epoch 56/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1803 - accuracy: 0.9315 - val_loss: 0.2339 - val_accuracy: 0.9091\n",
            "Epoch 57/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1564 - accuracy: 0.9438 - val_loss: 0.2262 - val_accuracy: 0.9091\n",
            "Epoch 58/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1637 - accuracy: 0.9438 - val_loss: 0.3221 - val_accuracy: 0.8750\n",
            "Epoch 59/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.8509 - val_loss: 0.3126 - val_accuracy: 0.8750\n",
            "Epoch 60/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1960 - accuracy: 0.9340 - val_loss: 0.3059 - val_accuracy: 0.8295\n",
            "Epoch 61/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1601 - accuracy: 0.9364 - val_loss: 0.2564 - val_accuracy: 0.9205\n",
            "Epoch 62/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2614 - accuracy: 0.8875 - val_loss: 0.7136 - val_accuracy: 0.7386\n",
            "Epoch 63/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2647 - accuracy: 0.8973 - val_loss: 0.3933 - val_accuracy: 0.8295\n",
            "Epoch 64/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2217 - accuracy: 0.9046 - val_loss: 0.1912 - val_accuracy: 0.9318\n",
            "Epoch 65/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1587 - accuracy: 0.9413 - val_loss: 0.2024 - val_accuracy: 0.8977\n",
            "Epoch 66/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1925 - accuracy: 0.9144 - val_loss: 0.2755 - val_accuracy: 0.9205\n",
            "Epoch 67/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3068 - accuracy: 0.8729 - val_loss: 0.3629 - val_accuracy: 0.8636\n",
            "Epoch 68/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1654 - accuracy: 0.9438 - val_loss: 0.5851 - val_accuracy: 0.7614\n",
            "Epoch 69/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2455 - accuracy: 0.9046 - val_loss: 0.2490 - val_accuracy: 0.9318\n",
            "Epoch 70/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1738 - accuracy: 0.9315 - val_loss: 0.2376 - val_accuracy: 0.8977\n",
            "Epoch 71/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1730 - accuracy: 0.9364 - val_loss: 0.2032 - val_accuracy: 0.9205\n",
            "Epoch 72/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1506 - accuracy: 0.9487 - val_loss: 0.2209 - val_accuracy: 0.9432\n",
            "Epoch 73/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1437 - accuracy: 0.9487 - val_loss: 0.2055 - val_accuracy: 0.9318\n",
            "Epoch 74/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1776 - accuracy: 0.9389 - val_loss: 0.2103 - val_accuracy: 0.9318\n",
            "Epoch 75/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1647 - accuracy: 0.9413 - val_loss: 0.2586 - val_accuracy: 0.9318\n",
            "Epoch 76/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1810 - accuracy: 0.9291 - val_loss: 0.2125 - val_accuracy: 0.9432\n",
            "Epoch 77/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1126 - accuracy: 0.9633 - val_loss: 0.1991 - val_accuracy: 0.8977\n",
            "Epoch 78/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1734 - accuracy: 0.9242 - val_loss: 0.4034 - val_accuracy: 0.8523\n",
            "Epoch 79/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2061 - accuracy: 0.9218 - val_loss: 0.1945 - val_accuracy: 0.9318\n",
            "Epoch 80/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2033 - accuracy: 0.9169 - val_loss: 0.2315 - val_accuracy: 0.8750\n",
            "Epoch 81/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1505 - accuracy: 0.9487 - val_loss: 0.2992 - val_accuracy: 0.8977\n",
            "Epoch 82/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1237 - accuracy: 0.9609 - val_loss: 0.1772 - val_accuracy: 0.9318\n",
            "Epoch 83/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1198 - accuracy: 0.9682 - val_loss: 0.2422 - val_accuracy: 0.9205\n",
            "Epoch 84/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1326 - accuracy: 0.9560 - val_loss: 0.1787 - val_accuracy: 0.9432\n",
            "Epoch 85/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1381 - accuracy: 0.9413 - val_loss: 0.2110 - val_accuracy: 0.9432\n",
            "Epoch 86/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1536 - accuracy: 0.9560 - val_loss: 0.2374 - val_accuracy: 0.9318\n",
            "Epoch 87/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1473 - accuracy: 0.9438 - val_loss: 0.2319 - val_accuracy: 0.9318\n",
            "Epoch 88/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4827 - accuracy: 0.8362 - val_loss: 1.2201 - val_accuracy: 0.5795\n",
            "Epoch 89/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.7531 - val_loss: 0.4627 - val_accuracy: 0.7727\n",
            "Epoch 90/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2813 - accuracy: 0.8680 - val_loss: 0.2470 - val_accuracy: 0.9205\n",
            "Epoch 91/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1679 - accuracy: 0.9364 - val_loss: 0.2192 - val_accuracy: 0.9091\n",
            "Epoch 92/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9535 - val_loss: 0.2090 - val_accuracy: 0.9205\n",
            "Epoch 93/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1587 - accuracy: 0.9487 - val_loss: 0.1837 - val_accuracy: 0.9432\n",
            "Epoch 94/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1694 - accuracy: 0.9340 - val_loss: 0.1830 - val_accuracy: 0.9318\n",
            "Epoch 95/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1184 - accuracy: 0.9658 - val_loss: 0.2034 - val_accuracy: 0.9432\n",
            "Epoch 96/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.1420 - accuracy: 0.9511 - val_loss: 0.2130 - val_accuracy: 0.9205\n",
            "Epoch 97/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1463 - accuracy: 0.9487 - val_loss: 0.2450 - val_accuracy: 0.9318\n",
            "Epoch 98/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1370 - accuracy: 0.9535 - val_loss: 0.1531 - val_accuracy: 0.9432\n",
            "Epoch 99/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1195 - accuracy: 0.9560 - val_loss: 0.1741 - val_accuracy: 0.9432\n",
            "Epoch 100/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1897 - accuracy: 0.9413 - val_loss: 0.4190 - val_accuracy: 0.8295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Loss & Accuracy\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "val_acc=history.history['val_accuracy']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "687cb377-ff8a-4515-b5b6-812ee8ef382d",
        "id": "AgrvNtHaZKzl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RO5IVjI7ldsp",
        "outputId": "15849a08-c9ca-4166-8796-cf61d7750f57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.2304 - accuracy: 0.9322\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.23038947582244873, 0.9322034120559692]"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.evaluate(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeEYl0JDSsvl",
        "outputId": "2e24b9d1-5a51-4286-d285-44052e842bde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.9209\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1868014633655548, 0.9209401607513428]"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model 4"
      ],
      "metadata": {
        "id": "QqJUVXHD45IL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_4 = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(512, input_shape=[4],activation=tf.keras.activations.gelu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.gelu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.gelu),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.keras.activations.gelu),\n",
        "                                    tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
        "                                    ])"
      ],
      "metadata": {
        "id": "Hw2Po1Ey49W1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.compile(loss=SparseCategoricalCrossentropy(from_logits=False),optimizer=adam,metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "_R6y_8E1S23U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_4.fit(X_train, y_train, batch_size=16, epochs=400, callbacks=callback,  verbose=1)"
      ],
      "metadata": {
        "id": "-jopgpjGgdxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_4.fit(X_train, y_train, validation_data = (X_valid,y_valid), batch_size=16, epochs=100,  verbose=1)"
      ],
      "metadata": {
        "id": "v_POrlYb49W2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de743203-9a28-49fe-f881-1be7157fcd90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "26/26 [==============================] - 1s 9ms/step - loss: 2.9453 - accuracy: 0.3545 - val_loss: 1.1688 - val_accuracy: 0.3977\n",
            "Epoch 2/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1.1041 - accuracy: 0.4328 - val_loss: 1.1962 - val_accuracy: 0.3068\n",
            "Epoch 3/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1.0176 - accuracy: 0.4792 - val_loss: 0.8439 - val_accuracy: 0.5909\n",
            "Epoch 4/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.8400 - accuracy: 0.6137 - val_loss: 1.2243 - val_accuracy: 0.5341\n",
            "Epoch 5/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8337 - accuracy: 0.6381 - val_loss: 0.6082 - val_accuracy: 0.7273\n",
            "Epoch 6/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6909 - accuracy: 0.6846 - val_loss: 0.8473 - val_accuracy: 0.5455\n",
            "Epoch 7/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6295 - accuracy: 0.7164 - val_loss: 0.4926 - val_accuracy: 0.7841\n",
            "Epoch 8/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.8020 - val_loss: 0.4204 - val_accuracy: 0.7727\n",
            "Epoch 9/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7971 - val_loss: 0.5037 - val_accuracy: 0.7727\n",
            "Epoch 10/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8117 - val_loss: 0.3514 - val_accuracy: 0.8409\n",
            "Epoch 11/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.8313 - val_loss: 0.4032 - val_accuracy: 0.7955\n",
            "Epoch 12/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3571 - accuracy: 0.8435 - val_loss: 0.5728 - val_accuracy: 0.6932\n",
            "Epoch 13/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.5472 - accuracy: 0.7677 - val_loss: 0.6150 - val_accuracy: 0.7386\n",
            "Epoch 14/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8313 - val_loss: 0.4110 - val_accuracy: 0.7955\n",
            "Epoch 15/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3990 - accuracy: 0.8191 - val_loss: 0.6271 - val_accuracy: 0.7159\n",
            "Epoch 16/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3756 - accuracy: 0.8117 - val_loss: 0.3460 - val_accuracy: 0.8409\n",
            "Epoch 17/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3254 - accuracy: 0.8509 - val_loss: 0.2987 - val_accuracy: 0.9091\n",
            "Epoch 18/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2908 - accuracy: 0.8704 - val_loss: 0.2859 - val_accuracy: 0.8977\n",
            "Epoch 19/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2671 - accuracy: 0.8949 - val_loss: 0.2791 - val_accuracy: 0.8523\n",
            "Epoch 20/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2678 - accuracy: 0.8826 - val_loss: 0.6052 - val_accuracy: 0.6477\n",
            "Epoch 21/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4006 - accuracy: 0.8142 - val_loss: 0.5300 - val_accuracy: 0.7841\n",
            "Epoch 22/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3638 - accuracy: 0.8166 - val_loss: 0.3550 - val_accuracy: 0.8409\n",
            "Epoch 23/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2698 - accuracy: 0.8924 - val_loss: 0.3263 - val_accuracy: 0.8523\n",
            "Epoch 24/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2844 - accuracy: 0.8680 - val_loss: 0.3632 - val_accuracy: 0.8409\n",
            "Epoch 25/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7751 - val_loss: 0.4273 - val_accuracy: 0.7955\n",
            "Epoch 26/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3301 - accuracy: 0.8557 - val_loss: 0.3388 - val_accuracy: 0.8750\n",
            "Epoch 27/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2907 - accuracy: 0.8802 - val_loss: 0.2957 - val_accuracy: 0.8636\n",
            "Epoch 28/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2412 - accuracy: 0.9022 - val_loss: 0.2627 - val_accuracy: 0.9091\n",
            "Epoch 29/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2131 - accuracy: 0.9218 - val_loss: 0.2567 - val_accuracy: 0.9091\n",
            "Epoch 30/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8509 - val_loss: 0.6309 - val_accuracy: 0.7500\n",
            "Epoch 31/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3141 - accuracy: 0.8582 - val_loss: 0.3011 - val_accuracy: 0.8523\n",
            "Epoch 32/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2661 - accuracy: 0.8973 - val_loss: 0.3150 - val_accuracy: 0.8295\n",
            "Epoch 33/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2802 - accuracy: 0.8753 - val_loss: 0.2696 - val_accuracy: 0.9091\n",
            "Epoch 34/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2863 - accuracy: 0.8753 - val_loss: 0.2445 - val_accuracy: 0.8977\n",
            "Epoch 35/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2289 - accuracy: 0.9120 - val_loss: 0.2364 - val_accuracy: 0.9091\n",
            "Epoch 36/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2383 - accuracy: 0.8924 - val_loss: 0.2346 - val_accuracy: 0.9205\n",
            "Epoch 37/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1927 - accuracy: 0.9291 - val_loss: 0.2332 - val_accuracy: 0.9091\n",
            "Epoch 38/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2368 - accuracy: 0.9095 - val_loss: 0.2487 - val_accuracy: 0.9205\n",
            "Epoch 39/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.8313 - val_loss: 0.5444 - val_accuracy: 0.7727\n",
            "Epoch 40/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3436 - accuracy: 0.8533 - val_loss: 0.3745 - val_accuracy: 0.8295\n",
            "Epoch 41/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2218 - accuracy: 0.9364 - val_loss: 0.3489 - val_accuracy: 0.8295\n",
            "Epoch 42/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2195 - accuracy: 0.9144 - val_loss: 0.2222 - val_accuracy: 0.8977\n",
            "Epoch 43/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1842 - accuracy: 0.9389 - val_loss: 0.2285 - val_accuracy: 0.9205\n",
            "Epoch 44/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1912 - accuracy: 0.9242 - val_loss: 0.1982 - val_accuracy: 0.9432\n",
            "Epoch 45/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2907 - accuracy: 0.8753 - val_loss: 0.2674 - val_accuracy: 0.8636\n",
            "Epoch 46/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3600 - accuracy: 0.8435 - val_loss: 0.2390 - val_accuracy: 0.9091\n",
            "Epoch 47/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2668 - accuracy: 0.8875 - val_loss: 0.3919 - val_accuracy: 0.8523\n",
            "Epoch 48/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2762 - accuracy: 0.8778 - val_loss: 0.3116 - val_accuracy: 0.8409\n",
            "Epoch 49/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1862 - accuracy: 0.9340 - val_loss: 0.2470 - val_accuracy: 0.9205\n",
            "Epoch 50/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2178 - accuracy: 0.9120 - val_loss: 0.2382 - val_accuracy: 0.9091\n",
            "Epoch 51/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2016 - accuracy: 0.9267 - val_loss: 0.2683 - val_accuracy: 0.8750\n",
            "Epoch 52/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2771 - accuracy: 0.8900 - val_loss: 0.2587 - val_accuracy: 0.9091\n",
            "Epoch 53/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1784 - accuracy: 0.9364 - val_loss: 0.1988 - val_accuracy: 0.9205\n",
            "Epoch 54/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2039 - accuracy: 0.9144 - val_loss: 0.2712 - val_accuracy: 0.9091\n",
            "Epoch 55/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1880 - accuracy: 0.9242 - val_loss: 0.2720 - val_accuracy: 0.9205\n",
            "Epoch 56/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1803 - accuracy: 0.9267 - val_loss: 0.2455 - val_accuracy: 0.9318\n",
            "Epoch 57/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1644 - accuracy: 0.9462 - val_loss: 0.6048 - val_accuracy: 0.7727\n",
            "Epoch 58/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.3701 - accuracy: 0.8435 - val_loss: 0.2966 - val_accuracy: 0.8977\n",
            "Epoch 59/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2004 - accuracy: 0.9267 - val_loss: 0.2173 - val_accuracy: 0.9205\n",
            "Epoch 60/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1522 - accuracy: 0.9511 - val_loss: 0.2404 - val_accuracy: 0.8750\n",
            "Epoch 61/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2085 - accuracy: 0.9095 - val_loss: 0.2631 - val_accuracy: 0.8636\n",
            "Epoch 62/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2428 - accuracy: 0.9144 - val_loss: 0.2346 - val_accuracy: 0.8864\n",
            "Epoch 63/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.9315 - val_loss: 0.2058 - val_accuracy: 0.9432\n",
            "Epoch 64/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1536 - accuracy: 0.9487 - val_loss: 0.2085 - val_accuracy: 0.9318\n",
            "Epoch 65/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1846 - accuracy: 0.9315 - val_loss: 0.2148 - val_accuracy: 0.9318\n",
            "Epoch 66/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1183 - accuracy: 0.9682 - val_loss: 0.2058 - val_accuracy: 0.9318\n",
            "Epoch 67/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1848 - accuracy: 0.9340 - val_loss: 0.2868 - val_accuracy: 0.9091\n",
            "Epoch 68/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2065 - accuracy: 0.9267 - val_loss: 0.3187 - val_accuracy: 0.8750\n",
            "Epoch 69/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1826 - accuracy: 0.9193 - val_loss: 0.2338 - val_accuracy: 0.9318\n",
            "Epoch 70/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1360 - accuracy: 0.9487 - val_loss: 0.2102 - val_accuracy: 0.9318\n",
            "Epoch 71/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2428 - accuracy: 0.9022 - val_loss: 0.2748 - val_accuracy: 0.9205\n",
            "Epoch 72/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1995 - accuracy: 0.9218 - val_loss: 0.2239 - val_accuracy: 0.9318\n",
            "Epoch 73/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2145 - accuracy: 0.9046 - val_loss: 0.4354 - val_accuracy: 0.8636\n",
            "Epoch 74/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2172 - accuracy: 0.9144 - val_loss: 0.2077 - val_accuracy: 0.9205\n",
            "Epoch 75/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2009 - accuracy: 0.9169 - val_loss: 0.2596 - val_accuracy: 0.9091\n",
            "Epoch 76/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1481 - accuracy: 0.9462 - val_loss: 0.2330 - val_accuracy: 0.9318\n",
            "Epoch 77/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1358 - accuracy: 0.9584 - val_loss: 0.1722 - val_accuracy: 0.9318\n",
            "Epoch 78/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1071 - accuracy: 0.9780 - val_loss: 0.2274 - val_accuracy: 0.8864\n",
            "Epoch 79/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1909 - accuracy: 0.9193 - val_loss: 0.2960 - val_accuracy: 0.9205\n",
            "Epoch 80/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1323 - accuracy: 0.9584 - val_loss: 0.2396 - val_accuracy: 0.9318\n",
            "Epoch 81/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1398 - accuracy: 0.9487 - val_loss: 0.1804 - val_accuracy: 0.9318\n",
            "Epoch 82/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1707 - accuracy: 0.9340 - val_loss: 0.4430 - val_accuracy: 0.8295\n",
            "Epoch 83/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2476 - accuracy: 0.8973 - val_loss: 0.2680 - val_accuracy: 0.8636\n",
            "Epoch 84/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1425 - accuracy: 0.9511 - val_loss: 0.2571 - val_accuracy: 0.8750\n",
            "Epoch 85/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1612 - accuracy: 0.9364 - val_loss: 0.2331 - val_accuracy: 0.9318\n",
            "Epoch 86/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1920 - accuracy: 0.9193 - val_loss: 0.1869 - val_accuracy: 0.9432\n",
            "Epoch 87/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1326 - accuracy: 0.9511 - val_loss: 0.1844 - val_accuracy: 0.9432\n",
            "Epoch 88/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1323 - accuracy: 0.9511 - val_loss: 0.2362 - val_accuracy: 0.9432\n",
            "Epoch 89/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1374 - accuracy: 0.9511 - val_loss: 0.2906 - val_accuracy: 0.8295\n",
            "Epoch 90/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1492 - accuracy: 0.9487 - val_loss: 0.2050 - val_accuracy: 0.9432\n",
            "Epoch 91/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1380 - accuracy: 0.9462 - val_loss: 0.2212 - val_accuracy: 0.9432\n",
            "Epoch 92/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1583 - accuracy: 0.9389 - val_loss: 0.2291 - val_accuracy: 0.9318\n",
            "Epoch 93/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1578 - accuracy: 0.9364 - val_loss: 0.2411 - val_accuracy: 0.8864\n",
            "Epoch 94/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1298 - accuracy: 0.9584 - val_loss: 0.2125 - val_accuracy: 0.9432\n",
            "Epoch 95/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1125 - accuracy: 0.9633 - val_loss: 0.1890 - val_accuracy: 0.9432\n",
            "Epoch 96/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1234 - accuracy: 0.9511 - val_loss: 0.2044 - val_accuracy: 0.9205\n",
            "Epoch 97/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1055 - accuracy: 0.9682 - val_loss: 0.1649 - val_accuracy: 0.9545\n",
            "Epoch 98/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0866 - accuracy: 0.9731 - val_loss: 0.1849 - val_accuracy: 0.9432\n",
            "Epoch 99/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1034 - accuracy: 0.9633 - val_loss: 0.1691 - val_accuracy: 0.9432\n",
            "Epoch 100/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2720 - accuracy: 0.9120 - val_loss: 0.3112 - val_accuracy: 0.9205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Loss & Accuracy\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "val_acc=history.history['val_accuracy']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "aea2615b-c41f-4980-8986-4814b702f3f1",
        "id": "t_B9kXsaZWOd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVhGfS0clhjB",
        "outputId": "4ce3df1e-d180-4906-860c-2a38078c0d82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step - loss: 0.2421 - accuracy: 0.9091\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.24211058020591736, 0.9090909361839294]"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.evaluate(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeWGNOZlS89P",
        "outputId": "6ab3db8e-0c4c-4980-f707-dd2c7be02cec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 2ms/step - loss: 0.1864 - accuracy: 0.9340\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.18637190759181976, 0.9339853525161743]"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Prediction**"
      ],
      "metadata": {
        "id": "shB4VHxc8Ysm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions=model_4.predict(X_test, batch_size=None)"
      ],
      "metadata": {
        "id": "20z3V9goWfpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions=np.argmax(predictions, axis = 1)"
      ],
      "metadata": {
        "id": "pYrRgwn-Wll_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing = pd.DataFrame()\n",
        "testing['Stability'] = y_test\n",
        "testing['Pred_Stability'] = predictions"
      ],
      "metadata": {
        "id": "PaWLyNGHTNAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rpn2pFs3a3Jy",
        "outputId": "b811e142-f2c3-4000-dce4-a9e3396f4433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Stability  Pred_Stability\n",
              "0          1               2\n",
              "1          1               2\n",
              "2          2               1\n",
              "3          1               1\n",
              "4          0               0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0febf4be-1f09-4b3a-9163-22f68922dd6c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Stability</th>\n",
              "      <th>Pred_Stability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0febf4be-1f09-4b3a-9163-22f68922dd6c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0febf4be-1f09-4b3a-9163-22f68922dd6c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0febf4be-1f09-4b3a-9163-22f68922dd6c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(testing['Stability'].values, testing['Pred_Stability'].values, zero_division=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1blFMJyTrXC",
        "outputId": "5cb06af4-caac-46ca-d3ff-aa4251c78cb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98        27\n",
            "           1       1.00      0.77      0.87        31\n",
            "           2       0.79      1.00      0.88        30\n",
            "\n",
            "    accuracy                           0.91        88\n",
            "   macro avg       0.93      0.91      0.91        88\n",
            "weighted avg       0.93      0.91      0.91        88\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stability_list = list(df['Relabel_6'].unique())"
      ],
      "metadata": {
        "id": "LYYwtmBNriLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(8,6))\n",
        "matrix = ConfusionMatrixDisplay.from_predictions(testing['Stability'].values, testing['Pred_Stability'].values, display_labels=stability_list, cmap='Blues', ax=ax)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "v0KGsm43q7B1",
        "outputId": "ba2e2a53-cdff-4593-ecbe-0234ff7bb7a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Training with 10 Folds CV**"
      ],
      "metadata": {
        "id": "51B8rocCJfBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Requirements"
      ],
      "metadata": {
        "id": "XdqWvRqJNmNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "# Merge inputs and targets\n",
        "inputs = np.concatenate((X_train, X_valid), axis=0)\n",
        "targets = np.concatenate((y_train, y_valid), axis=0)\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=10, shuffle=True)"
      ],
      "metadata": {
        "id": "TVP0tjKgNtvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam = Adam(learning_rate=0.001)"
      ],
      "metadata": {
        "id": "07aYzDEZKGiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Callback\n",
        "callback = EarlyStopping(\n",
        "    monitor=\"accuracy\",\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    mode='auto'\n",
        ")"
      ],
      "metadata": {
        "id": "UgKgjnYvKJ3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average=[]\n",
        "def Average(lst):\n",
        "    return sum(lst) / len(lst)"
      ],
      "metadata": {
        "id": "HZsOyqD_M0DY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc=[]\n",
        "cv_acc=[]"
      ],
      "metadata": {
        "id": "kgdxLNaBaOeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc=[]"
      ],
      "metadata": {
        "id": "2t1B_hTHj5fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model 1 (Linear)"
      ],
      "metadata": {
        "id": "WNFtSoo8N52v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc_per_fold=[]\n",
        "loss_per_fold=[]"
      ],
      "metadata": {
        "id": "k9zRNdg-RGEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model_1 = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(512, input_shape=[4],activation=tf.keras.activations.linear),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.linear),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.linear),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.keras.activations.linear),\n",
        "                                    tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
        "                                    ])\n",
        "\n",
        "  # Compile the model\n",
        "  model_1.compile(loss=\"SparseCategoricalCrossentropy\",\n",
        "                optimizer=adam,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model_1.fit(inputs[train], targets[train],\n",
        "              batch_size=16,\n",
        "              epochs=100,\n",
        "              verbose=1,\n",
        "              callbacks=callback)\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model_1.evaluate(inputs[test], targets[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model_1.metrics_names[0]} of {scores[0]}; {model_1.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAwE-1azJjRw",
        "outputId": "43f637e3-a5ab-405b-ff32-da0b415470ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 18.7140 - accuracy: 0.3533\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 6.5211 - accuracy: 0.2772\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5583 - accuracy: 0.4783\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1883 - accuracy: 0.5435\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0704 - accuracy: 0.5163\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2463 - accuracy: 0.4293\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1730 - accuracy: 0.4674\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9164 - accuracy: 0.5272\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8226 - accuracy: 0.6739\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8119 - accuracy: 0.5815\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8040 - accuracy: 0.6304\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7741 - accuracy: 0.6467\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7834 - accuracy: 0.6141\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8556 - accuracy: 0.6250\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3862 - accuracy: 0.5109\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2842 - accuracy: 0.4402\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8722 - accuracy: 0.6304\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7896 - accuracy: 0.6141\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7843 - accuracy: 0.6576\n",
            "Score for fold 1: loss of 0.7759312391281128; accuracy of 61.90476417541504%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 32.8263 - accuracy: 0.3043\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 5.3987 - accuracy: 0.2989\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0898 - accuracy: 0.4348\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5034 - accuracy: 0.5163\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0004 - accuracy: 0.5761\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8552 - accuracy: 0.6793\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7418 - accuracy: 0.6413\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7482 - accuracy: 0.6739\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8017 - accuracy: 0.6250\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8783 - accuracy: 0.5870\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6551 - accuracy: 0.7011\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.7337\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6300 - accuracy: 0.7717\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6133 - accuracy: 0.7228\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6962 - accuracy: 0.6522\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9606 - accuracy: 0.6304\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7384 - accuracy: 0.6576\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.7337\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7031 - accuracy: 0.7446\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6700 - accuracy: 0.6739\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6720 - accuracy: 0.7120\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6259 - accuracy: 0.7337\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7880\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8935 - accuracy: 0.5978\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7900 - accuracy: 0.6522\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6840 - accuracy: 0.6522\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6220 - accuracy: 0.7120\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6547 - accuracy: 0.7011\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5973 - accuracy: 0.7065\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.7228\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6248 - accuracy: 0.7228\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6001 - accuracy: 0.7446\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5988 - accuracy: 0.7228\n",
            "Score for fold 2: loss of 0.9953641295433044; accuracy of 52.3809552192688%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 56.4380 - accuracy: 0.3261\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 20.7702 - accuracy: 0.3533\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.2542 - accuracy: 0.4348\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8092 - accuracy: 0.3424\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5165 - accuracy: 0.5326\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9076 - accuracy: 0.6033\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8474 - accuracy: 0.6250\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7616 - accuracy: 0.6848\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7737 - accuracy: 0.6250\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7175 - accuracy: 0.6630\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6909 - accuracy: 0.6848\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7150 - accuracy: 0.6957\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7362 - accuracy: 0.6522\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.6630\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6525 - accuracy: 0.7337\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6578 - accuracy: 0.6739\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6946 - accuracy: 0.6196\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6718 - accuracy: 0.7609\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6490 - accuracy: 0.6902\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6683 - accuracy: 0.7065\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7156 - accuracy: 0.6304\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7163 - accuracy: 0.6413\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6708 - accuracy: 0.7337\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5984 - accuracy: 0.7609\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7823 - accuracy: 0.6413\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6876 - accuracy: 0.6630\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6073 - accuracy: 0.7446\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6461 - accuracy: 0.7120\n",
            "Score for fold 3: loss of 0.766167938709259; accuracy of 76.1904776096344%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 4ms/step - loss: 58.4056 - accuracy: 0.4076\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 24.9943 - accuracy: 0.3152\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.9890 - accuracy: 0.4348\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.3173 - accuracy: 0.4620\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2916 - accuracy: 0.4511\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1192 - accuracy: 0.5761\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8864 - accuracy: 0.5924\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7426 - accuracy: 0.6467\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7241 - accuracy: 0.6522\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6854 - accuracy: 0.7065\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6835 - accuracy: 0.7011\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6992 - accuracy: 0.6902\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6790 - accuracy: 0.6413\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6561 - accuracy: 0.6630\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6579 - accuracy: 0.6685\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6222 - accuracy: 0.7228\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6239 - accuracy: 0.7337\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6381 - accuracy: 0.7174\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6917 - accuracy: 0.7011\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6961 - accuracy: 0.6250\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6860 - accuracy: 0.6957\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7195 - accuracy: 0.6522\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8148 - accuracy: 0.6087\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6958 - accuracy: 0.6413\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6303 - accuracy: 0.7554\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6359 - accuracy: 0.7500\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6459 - accuracy: 0.6793\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6625 - accuracy: 0.6848\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6902 - accuracy: 0.6359\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7603 - accuracy: 0.6576\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7259 - accuracy: 0.6902\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6525 - accuracy: 0.7120\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6556 - accuracy: 0.6359\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.7283\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6468 - accuracy: 0.6630\n",
            "Score for fold 4: loss of 0.5687341094017029; accuracy of 66.66666865348816%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 4ms/step - loss: 65.0818 - accuracy: 0.3098\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.6725 - accuracy: 0.3370\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3.7783 - accuracy: 0.4348\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1982 - accuracy: 0.4891\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5770 - accuracy: 0.4783\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8900 - accuracy: 0.5870\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8211 - accuracy: 0.6304\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8117 - accuracy: 0.5815\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7977 - accuracy: 0.6413\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8051 - accuracy: 0.5870\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7532 - accuracy: 0.6087\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7880 - accuracy: 0.5761\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7327 - accuracy: 0.6304\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7446 - accuracy: 0.6793\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7632 - accuracy: 0.6196\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7808 - accuracy: 0.6087\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7053 - accuracy: 0.6957\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6505 - accuracy: 0.7011\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6631 - accuracy: 0.7011\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6499 - accuracy: 0.6957\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6972 - accuracy: 0.6848\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6794 - accuracy: 0.6739\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6653 - accuracy: 0.7174\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7279 - accuracy: 0.6957\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6587 - accuracy: 0.6630\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6241 - accuracy: 0.7174\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6211 - accuracy: 0.7500\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6235 - accuracy: 0.7065\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6129 - accuracy: 0.7717\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6293 - accuracy: 0.7120\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6358 - accuracy: 0.7065\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6628 - accuracy: 0.7283\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6852 - accuracy: 0.6630\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7370 - accuracy: 0.6902\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6155 - accuracy: 0.7174\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6264 - accuracy: 0.6957\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6145 - accuracy: 0.7337\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6197 - accuracy: 0.7011\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6403 - accuracy: 0.6902\n",
            "Score for fold 5: loss of 0.7645360827445984; accuracy of 47.61904776096344%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 6 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 5ms/step - loss: 88.9723 - accuracy: 0.2595\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 18.0085 - accuracy: 0.2919\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.3250 - accuracy: 0.3568\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.8914 - accuracy: 0.3622\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1503 - accuracy: 0.4703\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8557 - accuracy: 0.5676\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7711 - accuracy: 0.6162\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7914 - accuracy: 0.6270\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7319 - accuracy: 0.6865\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7047 - accuracy: 0.6486\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7285 - accuracy: 0.7081\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6452 - accuracy: 0.7405\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6394 - accuracy: 0.6757\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6406 - accuracy: 0.7243\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5914 - accuracy: 0.7568\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6294 - accuracy: 0.6703\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6123 - accuracy: 0.7135\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6132 - accuracy: 0.6973\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7499 - accuracy: 0.6432\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7032 - accuracy: 0.6595\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6196 - accuracy: 0.7081\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5930 - accuracy: 0.7189\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6040 - accuracy: 0.6973\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5758 - accuracy: 0.6865\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6263 - accuracy: 0.6973\n",
            "Score for fold 6: loss of 0.793686032295227; accuracy of 55.000001192092896%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 7 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 5ms/step - loss: 75.9813 - accuracy: 0.3838\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 13.6362 - accuracy: 0.3946\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3.5056 - accuracy: 0.4432\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.7743 - accuracy: 0.3892\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5768 - accuracy: 0.5135\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9083 - accuracy: 0.5730\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8509 - accuracy: 0.5892\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8322 - accuracy: 0.6757\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7607 - accuracy: 0.6486\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6595\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7568 - accuracy: 0.6703\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6963 - accuracy: 0.6649\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6684 - accuracy: 0.6757\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6695 - accuracy: 0.6865\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6704 - accuracy: 0.6973\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6322 - accuracy: 0.7243\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6088 - accuracy: 0.7189\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6138 - accuracy: 0.7189\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6157 - accuracy: 0.7243\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6118 - accuracy: 0.7189\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6555 - accuracy: 0.7135\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6152 - accuracy: 0.7514\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6390 - accuracy: 0.7297\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6666 - accuracy: 0.7081\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6475 - accuracy: 0.6703\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6342 - accuracy: 0.7081\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6190 - accuracy: 0.7351\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6462 - accuracy: 0.7135\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6007 - accuracy: 0.7351\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6128 - accuracy: 0.6973\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.7027\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5942 - accuracy: 0.7189\n",
            "Score for fold 7: loss of 0.4878615438938141; accuracy of 80.0000011920929%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 8 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 5ms/step - loss: 59.8669 - accuracy: 0.3405\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.9857 - accuracy: 0.3189\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.4454 - accuracy: 0.4432\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3122 - accuracy: 0.4108\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1173 - accuracy: 0.5838\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9063 - accuracy: 0.5243\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7999 - accuracy: 0.6486\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7633 - accuracy: 0.6541\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7094 - accuracy: 0.7135\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7066 - accuracy: 0.6865\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6673 - accuracy: 0.7081\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7168 - accuracy: 0.6649\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7194 - accuracy: 0.6703\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7083 - accuracy: 0.6486\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6754 - accuracy: 0.7081\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6678 - accuracy: 0.7189\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6371 - accuracy: 0.6973\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6568 - accuracy: 0.7243\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7454 - accuracy: 0.6378\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6149 - accuracy: 0.7459\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6222 - accuracy: 0.7027\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6248 - accuracy: 0.7405\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.7568\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5936 - accuracy: 0.7351\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6068 - accuracy: 0.7027\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6033 - accuracy: 0.7081\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7817 - accuracy: 0.6757\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6846 - accuracy: 0.6811\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5873 - accuracy: 0.7189\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6235 - accuracy: 0.7135\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7511 - accuracy: 0.6541\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6777 - accuracy: 0.6595\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6383 - accuracy: 0.7135\n",
            "Score for fold 8: loss of 0.5789768695831299; accuracy of 80.0000011920929%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 9 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 69.9108 - accuracy: 0.3027\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 11.1927 - accuracy: 0.3351\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.1597 - accuracy: 0.4216\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6808 - accuracy: 0.3568\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3283 - accuracy: 0.5405\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9347 - accuracy: 0.5676\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8414 - accuracy: 0.5892\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7564 - accuracy: 0.6703\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7023 - accuracy: 0.6486\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6733 - accuracy: 0.6811\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6729 - accuracy: 0.7243\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.6919\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6748 - accuracy: 0.6973\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6148 - accuracy: 0.7351\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6229 - accuracy: 0.7189\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6737 - accuracy: 0.7027\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6130 - accuracy: 0.7081\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6243 - accuracy: 0.7027\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.7351\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6238 - accuracy: 0.7297\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9095 - accuracy: 0.5676\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7454 - accuracy: 0.6486\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7718 - accuracy: 0.6324\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6798 - accuracy: 0.6757\n",
            "Score for fold 9: loss of 0.5579414367675781; accuracy of 80.0000011920929%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 10 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 60.9908 - accuracy: 0.3405\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 9.3071 - accuracy: 0.3784\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.0921 - accuracy: 0.4108\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6523 - accuracy: 0.4595\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4214 - accuracy: 0.5189\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8840 - accuracy: 0.6054\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8627 - accuracy: 0.6054\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7539 - accuracy: 0.6486\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6701 - accuracy: 0.6865\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6448 - accuracy: 0.7243\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.7189\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6296 - accuracy: 0.6919\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6175 - accuracy: 0.7351\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6091 - accuracy: 0.7189\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.6595\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7758 - accuracy: 0.6432\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2358 - accuracy: 0.4865\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8719 - accuracy: 0.5405\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7549 - accuracy: 0.6054\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7293 - accuracy: 0.6270\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7128 - accuracy: 0.6811\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.6811\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6263 - accuracy: 0.7243\n",
            "Score for fold 10: loss of 0.6831619739532471; accuracy of 75.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_acc.append(acc_per_fold)"
      ],
      "metadata": {
        "id": "-3dDp-ucXmaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc.append(model_1.evaluate(X_test,y_test)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e8Cu6cSXqkm",
        "outputId": "d23abbbb-c5c5-4118-e1f3-76105c5442a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc.append(model_1.evaluate(X_train,y_train)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoxYIf2LjyMh",
        "outputId": "b94796ff-2215-4608-f418-99908be9bd1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5800 - accuracy: 0.7607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average.append(round(Average(acc_per_fold),2))"
      ],
      "metadata": {
        "id": "-eDiNMsTNAzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model 2 (ReLU)"
      ],
      "metadata": {
        "id": "k8pCcA6AOAYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc_per_fold=[]\n",
        "loss_per_fold=[]"
      ],
      "metadata": {
        "id": "oJaGMlQgRnla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model_2 = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(512, input_shape=[4],activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
        "                                    ])\n",
        "\n",
        "  # Compile the model\n",
        "  model_2.compile(loss=\"SparseCategoricalCrossentropy\",\n",
        "                optimizer=adam,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model_2.fit(inputs[train], targets[train],\n",
        "              batch_size=16,\n",
        "              epochs=100,\n",
        "              verbose=1,\n",
        "              callbacks=callback)\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model_2.evaluate(inputs[test], targets[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model_2.metrics_names[0]} of {scores[0]}; {model_2.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbBt_H41ODav",
        "outputId": "8072f9a2-cedd-45e6-dde6-21283dc18df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.2790 - accuracy: 0.3315\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.3715 - accuracy: 0.3315\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1046 - accuracy: 0.4565\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0735 - accuracy: 0.4620\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0198 - accuracy: 0.4293\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9284 - accuracy: 0.5326\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9650 - accuracy: 0.5435\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9127 - accuracy: 0.5543\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7582 - accuracy: 0.6413\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7897 - accuracy: 0.6033\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7510 - accuracy: 0.6304\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6051 - accuracy: 0.7174\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.6957\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.6902\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5618 - accuracy: 0.7283\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7717\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4898 - accuracy: 0.7935\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5023 - accuracy: 0.7663\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6665 - accuracy: 0.6685\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7391\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7283\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.8315\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7880\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.8152\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7935\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3856 - accuracy: 0.8424\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3920 - accuracy: 0.7989\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3500 - accuracy: 0.8587\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3404 - accuracy: 0.8261\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3695 - accuracy: 0.8261\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8207\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.8370\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7717\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7935\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7826\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3999 - accuracy: 0.8207\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3662 - accuracy: 0.8478\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.8696\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.7989\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8370\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8424\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3484 - accuracy: 0.8261\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3187 - accuracy: 0.8859\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3702 - accuracy: 0.7989\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2907 - accuracy: 0.8641\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2926 - accuracy: 0.8478\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8261\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2843 - accuracy: 0.8750\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.8641\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2740 - accuracy: 0.8750\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2650 - accuracy: 0.8587\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3446 - accuracy: 0.8478\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7935\n",
            "Score for fold 1: loss of 0.4827101528644562; accuracy of 76.1904776096344%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 4.1253 - accuracy: 0.3587\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2789 - accuracy: 0.3804\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1316 - accuracy: 0.4348\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0836 - accuracy: 0.4891\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9426 - accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8707 - accuracy: 0.5543\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9441 - accuracy: 0.4565\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8005 - accuracy: 0.6739\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.6685\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6786 - accuracy: 0.6902\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8568 - accuracy: 0.6141\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9544 - accuracy: 0.4293\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9064 - accuracy: 0.4620\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7312 - accuracy: 0.6793\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7456 - accuracy: 0.6196\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.7228\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.7663\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.7717\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.7609\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7935\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7663\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.7826\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7717\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7717\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7826\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3678 - accuracy: 0.8261\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3877 - accuracy: 0.8261\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7880\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7011\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7880\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8370\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.7772\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8370\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3361 - accuracy: 0.8533\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3776 - accuracy: 0.8370\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7989\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.8043\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8424\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8152\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8261\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3278 - accuracy: 0.8478\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3238 - accuracy: 0.8261\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8370\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3553 - accuracy: 0.8261\n",
            "Score for fold 2: loss of 0.20240481197834015; accuracy of 90.47619104385376%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 3ms/step - loss: 4.8260 - accuracy: 0.2935\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1865 - accuracy: 0.3587\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1475 - accuracy: 0.3696\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0583 - accuracy: 0.4511\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9576 - accuracy: 0.4946\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7615 - accuracy: 0.5978\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8589 - accuracy: 0.5870\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6631 - accuracy: 0.6739\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6097 - accuracy: 0.6793\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7337\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7609\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6181 - accuracy: 0.6902\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5914 - accuracy: 0.7065\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0392 - accuracy: 0.5326\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7122 - accuracy: 0.6467\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9041 - accuracy: 0.7120\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7652 - accuracy: 0.6685\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7663\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7880\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.7717\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3554 - accuracy: 0.8207\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7500\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7500\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7717\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7228\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7554\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7663\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.7989\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8207\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.8098\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3835 - accuracy: 0.7935\n",
            "Score for fold 3: loss of 0.478242963552475; accuracy of 80.95238208770752%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 4.3823 - accuracy: 0.3587\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3266 - accuracy: 0.3750\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0947 - accuracy: 0.4348\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1063 - accuracy: 0.4565\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9637 - accuracy: 0.4946\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9394 - accuracy: 0.5924\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8616 - accuracy: 0.5761\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.6685\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6625 - accuracy: 0.7283\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8679 - accuracy: 0.6196\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6501 - accuracy: 0.7065\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.7446\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7391\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.8043\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7826\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7228\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6572 - accuracy: 0.7228\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.6848\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7880\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7705 - accuracy: 0.6793\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6902 - accuracy: 0.6413\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7055 - accuracy: 0.6630\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.7989\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.7826\n",
            "Score for fold 4: loss of 0.625981867313385; accuracy of 66.66666865348816%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 4.5522 - accuracy: 0.3641\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2540 - accuracy: 0.4130\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1531 - accuracy: 0.4402\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1017 - accuracy: 0.4293\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9589 - accuracy: 0.4837\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8821 - accuracy: 0.5761\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8520 - accuracy: 0.5707\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7237 - accuracy: 0.6250\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6969 - accuracy: 0.6576\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5633 - accuracy: 0.7391\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7065\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8486 - accuracy: 0.6304\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7406 - accuracy: 0.6033\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5944 - accuracy: 0.7337\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.6848\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.7174\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5645 - accuracy: 0.7500\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7609\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.7609\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7935\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.8043\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4004 - accuracy: 0.8098\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8098\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7446\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.8207\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3607 - accuracy: 0.8424\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3810 - accuracy: 0.8043\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3430 - accuracy: 0.8587\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 0.8043\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3818 - accuracy: 0.8315\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3253 - accuracy: 0.8478\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3224 - accuracy: 0.8587\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.7554\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7826\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.7772\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3469 - accuracy: 0.7989\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7826\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3578 - accuracy: 0.8261\n",
            "Score for fold 5: loss of 0.3306943476200104; accuracy of 85.71428656578064%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 6 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 4.4339 - accuracy: 0.3351\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.3149 - accuracy: 0.3243\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2404 - accuracy: 0.3568\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0721 - accuracy: 0.4919\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0470 - accuracy: 0.4000\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9179 - accuracy: 0.4919\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8118 - accuracy: 0.6000\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7150 - accuracy: 0.6216\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6051 - accuracy: 0.7027\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5558 - accuracy: 0.7351\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1204 - accuracy: 0.6108\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9612 - accuracy: 0.5081\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7662 - accuracy: 0.6541\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6639 - accuracy: 0.6595\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7351\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7084 - accuracy: 0.6324\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6788 - accuracy: 0.6757\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6272 - accuracy: 0.7135\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6663 - accuracy: 0.7135\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.7189\n",
            "Score for fold 6: loss of 0.9225583076477051; accuracy of 60.00000238418579%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 7 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 5.4637 - accuracy: 0.2811\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3588 - accuracy: 0.3514\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1427 - accuracy: 0.3622\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0404 - accuracy: 0.4162\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0164 - accuracy: 0.4811\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9227 - accuracy: 0.5514\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9228 - accuracy: 0.5622\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7857 - accuracy: 0.6595\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7037 - accuracy: 0.7243\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0304 - accuracy: 0.4541\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8278 - accuracy: 0.5784\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0157 - accuracy: 0.5027\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9047 - accuracy: 0.5838\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6973\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6536 - accuracy: 0.6973\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6603 - accuracy: 0.6703\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.7676\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7622\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.7676\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.7784\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7622\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.8000\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.8000\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.8000\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.7568\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8216\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3668 - accuracy: 0.8162\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3967 - accuracy: 0.7892\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8216\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.8162\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3169 - accuracy: 0.8595\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3696 - accuracy: 0.8216\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.8541\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3206 - accuracy: 0.8595\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.8054\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3874 - accuracy: 0.8162\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7313 - accuracy: 0.7135\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7098 - accuracy: 0.7027\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6093 - accuracy: 0.6703\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.7892\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3842 - accuracy: 0.8270\n",
            "Score for fold 7: loss of 0.4304201006889343; accuracy of 75.0%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 8 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.3328 - accuracy: 0.3351\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3662 - accuracy: 0.3730\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1397 - accuracy: 0.4649\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0160 - accuracy: 0.4432\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9469 - accuracy: 0.5135\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9393 - accuracy: 0.5297\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9799 - accuracy: 0.4324\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8558 - accuracy: 0.5784\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7472 - accuracy: 0.6811\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8997 - accuracy: 0.6054\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7965 - accuracy: 0.6216\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7856 - accuracy: 0.6811\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6744 - accuracy: 0.6432\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7536 - accuracy: 0.6108\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.7297\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.7243\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.7568\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.7622\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8559 - accuracy: 0.5622\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7234 - accuracy: 0.5838\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6210 - accuracy: 0.7459\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7827 - accuracy: 0.6270\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6147 - accuracy: 0.7135\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6298 - accuracy: 0.6919\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7568\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7405\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.7784\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7622\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7730\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.8162\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.7459\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7946\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7514\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.7189\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6861 - accuracy: 0.6757\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7784\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8054\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3887 - accuracy: 0.8270\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3657 - accuracy: 0.8270\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3586 - accuracy: 0.8270\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3757 - accuracy: 0.8216\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3332 - accuracy: 0.8270\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3343 - accuracy: 0.8270\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3523 - accuracy: 0.8270\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3550 - accuracy: 0.8378\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.8054\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.7622\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3841 - accuracy: 0.8162\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3731 - accuracy: 0.7946\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3403 - accuracy: 0.8432\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.7676\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7892\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3642 - accuracy: 0.8378\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3252 - accuracy: 0.8378\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3006 - accuracy: 0.8703\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3041 - accuracy: 0.8703\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3247 - accuracy: 0.8324\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3557 - accuracy: 0.8378\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3968 - accuracy: 0.8162\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.7892\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7946\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.8216\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3560 - accuracy: 0.8270\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8486\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3001 - accuracy: 0.8486\n",
            "Score for fold 8: loss of 0.268270343542099; accuracy of 94.9999988079071%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 9 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.6270 - accuracy: 0.3297\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.7613 - accuracy: 0.3189\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1546 - accuracy: 0.4000\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1156 - accuracy: 0.4378\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0362 - accuracy: 0.5027\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9566 - accuracy: 0.4595\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8742 - accuracy: 0.5946\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9096 - accuracy: 0.5189\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8378 - accuracy: 0.5622\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8150 - accuracy: 0.5838\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7415 - accuracy: 0.6270\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8818 - accuracy: 0.5784\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8352 - accuracy: 0.5568\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.6703\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6386 - accuracy: 0.7189\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5408 - accuracy: 0.7459\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7622\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6271 - accuracy: 0.6757\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6112 - accuracy: 0.7027\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.7459\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.7568\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7676\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.7189\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7892\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7568\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3760 - accuracy: 0.8162\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3892 - accuracy: 0.8054\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8000\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3923 - accuracy: 0.8108\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7568\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3557 - accuracy: 0.8270\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3411 - accuracy: 0.8162\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3186 - accuracy: 0.8486\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3535 - accuracy: 0.8378\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3729 - accuracy: 0.8000\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3365 - accuracy: 0.8270\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3218 - accuracy: 0.8432\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3302 - accuracy: 0.8378\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3718 - accuracy: 0.8270\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.7838\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.7676\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3946 - accuracy: 0.8378\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3398 - accuracy: 0.8378\n",
            "Score for fold 9: loss of 0.46727466583251953; accuracy of 89.99999761581421%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 10 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 4.7491 - accuracy: 0.3297\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1647 - accuracy: 0.3946\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0805 - accuracy: 0.4757\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9635 - accuracy: 0.5351\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9202 - accuracy: 0.4865\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7706 - accuracy: 0.6054\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7894 - accuracy: 0.6216\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8972 - accuracy: 0.5946\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7258 - accuracy: 0.6216\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6449 - accuracy: 0.6649\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5673 - accuracy: 0.7297\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5804 - accuracy: 0.6919\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7351\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.7351\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7784\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7892\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8000\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5983 - accuracy: 0.6649\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.7297\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.7946\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3726 - accuracy: 0.8324\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.7946\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3480 - accuracy: 0.8432\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3459 - accuracy: 0.8162\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3583 - accuracy: 0.8108\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3931 - accuracy: 0.8378\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3535 - accuracy: 0.8486\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3299 - accuracy: 0.8649\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3126 - accuracy: 0.8486\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.7946\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3572 - accuracy: 0.8162\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3182 - accuracy: 0.8595\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3106 - accuracy: 0.8811\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3809 - accuracy: 0.8324\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.8270\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.8324\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7676\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7351\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3554 - accuracy: 0.8486\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2906 - accuracy: 0.8649\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2539 - accuracy: 0.8973\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2496 - accuracy: 0.9081\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2376 - accuracy: 0.9081\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3254 - accuracy: 0.8378\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7730\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.8054\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3467 - accuracy: 0.8486\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3068 - accuracy: 0.8486\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2838 - accuracy: 0.8757\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2752 - accuracy: 0.8757\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3046 - accuracy: 0.8649\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2659 - accuracy: 0.8811\n",
            "Score for fold 10: loss of 0.5864781141281128; accuracy of 80.0000011920929%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_acc.append(acc_per_fold)"
      ],
      "metadata": {
        "id": "tNGryvxhSadC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc.append(model_2.evaluate(X_test,y_test)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFKg32xwX14H",
        "outputId": "c1802eca-44ea-4c53-b845-ebb15cb23f55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc.append(model_2.evaluate(X_train,y_train)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEMdwi0xkAap",
        "outputId": "5dcf4fef-5b9c-4a07-c359-0fc6822989d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2955 - accuracy: 0.9060\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average.append(round(Average(acc_per_fold),2))"
      ],
      "metadata": {
        "id": "yKdGqu7ROVXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model 3 (ELU)"
      ],
      "metadata": {
        "id": "im9vmLQZQDtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc_per_fold=[]\n",
        "loss_per_fold=[]"
      ],
      "metadata": {
        "id": "C0K7HZmSSb43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model_3 = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(512, input_shape=[4],activation=tf.keras.activations.elu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.elu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.elu),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.keras.activations.elu),\n",
        "                                    tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
        "                                    ])\n",
        "\n",
        "  # Compile the model\n",
        "  model_3.compile(loss=\"SparseCategoricalCrossentropy\",\n",
        "                optimizer=adam,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model_3.fit(inputs[train], targets[train],\n",
        "              batch_size=16,\n",
        "              epochs=100,\n",
        "              verbose=1,\n",
        "              callbacks=callback)\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model_3.evaluate(inputs[test], targets[test], verbose=1)\n",
        "  print(f'Score for fold {fold_no}: {model_3.metrics_names[0]} of {scores[0]}; {model_3.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYSBXNEVQI4D",
        "outputId": "eb58844d-9f19-4e97-e486-0bc62f06e568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 6.0606 - accuracy: 0.3587\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.9627 - accuracy: 0.4022\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2013 - accuracy: 0.4293\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1214 - accuracy: 0.4674\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1491 - accuracy: 0.3478\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9698 - accuracy: 0.5109\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8942 - accuracy: 0.5543\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8231 - accuracy: 0.5924\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9764 - accuracy: 0.5000\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8443 - accuracy: 0.5870\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8378 - accuracy: 0.5924\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7690 - accuracy: 0.6359\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6963 - accuracy: 0.6685\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6476 - accuracy: 0.7065\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6644 - accuracy: 0.6522\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5413 - accuracy: 0.7283\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5795 - accuracy: 0.7446\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7500\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.7880\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7545 - accuracy: 0.6304\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7614 - accuracy: 0.6902\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.7228\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.8043\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7989\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.7935\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6028 - accuracy: 0.7228\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7609\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3882 - accuracy: 0.8696\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3319 - accuracy: 0.8261\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8098\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2971 - accuracy: 0.8750\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8261\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3265 - accuracy: 0.8859\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.8098\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.8152\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8587\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8478\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3103 - accuracy: 0.8587\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3213 - accuracy: 0.8641\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8261\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7717\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3083 - accuracy: 0.8641\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2949 - accuracy: 0.8913\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2323 - accuracy: 0.9293\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2516 - accuracy: 0.8750\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2325 - accuracy: 0.9239\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.9348\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2394 - accuracy: 0.9022\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3855 - accuracy: 0.8370\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8533\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2874 - accuracy: 0.8804\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.9185\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2355 - accuracy: 0.9022\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2195 - accuracy: 0.9402\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.8152\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2914 - accuracy: 0.8750\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2137 - accuracy: 0.9130\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2012 - accuracy: 0.9293\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8424\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2254 - accuracy: 0.9185\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1794 - accuracy: 0.9457\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1884 - accuracy: 0.9293\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9348\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8587\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2720 - accuracy: 0.8750\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.9130\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2596 - accuracy: 0.8967\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2537 - accuracy: 0.8804\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2245 - accuracy: 0.9022\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2620 - accuracy: 0.9130\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2033 - accuracy: 0.9076\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.2530 - accuracy: 0.8571\n",
            "Score for fold 1: loss of 0.25299128890037537; accuracy of 85.71428656578064%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 7.7494 - accuracy: 0.2772\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.3192 - accuracy: 0.3152\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2053 - accuracy: 0.3696\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0705 - accuracy: 0.4239\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0763 - accuracy: 0.4239\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0347 - accuracy: 0.4674\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1720 - accuracy: 0.4076\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9928 - accuracy: 0.4565\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8850 - accuracy: 0.5163\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8367 - accuracy: 0.5870\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7298 - accuracy: 0.6359\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7242 - accuracy: 0.6467\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7549 - accuracy: 0.6304\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7056 - accuracy: 0.6467\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.7228\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8016 - accuracy: 0.6685\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.7228\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.7554\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7717\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.8152\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7935\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7772\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5554 - accuracy: 0.7609\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6477 - accuracy: 0.6902\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.7772\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7880\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7446\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7880\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.7446\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.7772\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.5430 - accuracy: 0.7619\n",
            "Score for fold 2: loss of 0.5429633259773254; accuracy of 76.1904776096344%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 6.9437 - accuracy: 0.4076\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4836 - accuracy: 0.3696\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1161 - accuracy: 0.3967\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0901 - accuracy: 0.4239\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0793 - accuracy: 0.3913\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0782 - accuracy: 0.4674\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8895 - accuracy: 0.5652\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8084 - accuracy: 0.5924\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7926 - accuracy: 0.6087\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7547 - accuracy: 0.6467\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7495 - accuracy: 0.6522\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6416 - accuracy: 0.6467\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.7446\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.7554\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7446\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7935\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.8098\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9484 - accuracy: 0.6033\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8136 - accuracy: 0.5652\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6277 - accuracy: 0.7228\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5672 - accuracy: 0.7446\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.7500\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5589 - accuracy: 0.7283\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7772\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7717\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7609\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.7717\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.3153 - accuracy: 0.9048\n",
            "Score for fold 3: loss of 0.3153342604637146; accuracy of 90.47619104385376%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 6.8697 - accuracy: 0.3478\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.9252 - accuracy: 0.3424\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1725 - accuracy: 0.3098\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1143 - accuracy: 0.4457\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1699 - accuracy: 0.3804\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0287 - accuracy: 0.4946\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0109 - accuracy: 0.5109\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9924 - accuracy: 0.4620\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9542 - accuracy: 0.5109\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8668 - accuracy: 0.5707\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8190 - accuracy: 0.6250\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7536 - accuracy: 0.6413\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6747 - accuracy: 0.7065\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7295 - accuracy: 0.6467\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5651 - accuracy: 0.7283\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.7391\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7922 - accuracy: 0.6413\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6588 - accuracy: 0.6413\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7500\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.8315\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7772\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7772\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3617 - accuracy: 0.8533\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3748 - accuracy: 0.8207\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.8152\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.7717\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3619 - accuracy: 0.8370\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3380 - accuracy: 0.8696\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3223 - accuracy: 0.8533\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2897 - accuracy: 0.8696\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3308 - accuracy: 0.8804\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2961 - accuracy: 0.8478\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7663\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2969 - accuracy: 0.8641\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5957 - accuracy: 0.7120\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.7174\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8478\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3570 - accuracy: 0.8152\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3214 - accuracy: 0.8587\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2751 - accuracy: 0.8750\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.9130\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2538 - accuracy: 0.8750\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.8967\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2440 - accuracy: 0.8913\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2338 - accuracy: 0.9022\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3050 - accuracy: 0.8696\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.8370\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3066 - accuracy: 0.8587\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2988 - accuracy: 0.8641\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3360 - accuracy: 0.8207\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3194 - accuracy: 0.8750\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.4863 - accuracy: 0.9048\n",
            "Score for fold 4: loss of 0.4862746298313141; accuracy of 90.47619104385376%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 8.2597 - accuracy: 0.3152\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3776 - accuracy: 0.4185\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2057 - accuracy: 0.4185\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1499 - accuracy: 0.3152\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0626 - accuracy: 0.4348\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0286 - accuracy: 0.4293\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9738 - accuracy: 0.5435\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0774 - accuracy: 0.3967\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8718 - accuracy: 0.5163\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8694 - accuracy: 0.5435\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7157 - accuracy: 0.7065\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7893 - accuracy: 0.5924\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.7500\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6773 - accuracy: 0.6739\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5788 - accuracy: 0.7228\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.7772\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7772\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7717\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7849 - accuracy: 0.6250\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7391\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5679 - accuracy: 0.7283\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5274 - accuracy: 0.7935\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4025 - accuracy: 0.7989\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7989\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7104 - accuracy: 0.7120\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7554\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.8315\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3893 - accuracy: 0.8098\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.7609\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4041 - accuracy: 0.8207\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.8478\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3257 - accuracy: 0.8641\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3292 - accuracy: 0.8641\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3167 - accuracy: 0.8587\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5275 - accuracy: 0.7663\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7500\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.8098\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7609\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3620 - accuracy: 0.8370\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3358 - accuracy: 0.8641\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3460 - accuracy: 0.8424\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3304 - accuracy: 0.8478\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.2833 - accuracy: 0.9048\n",
            "Score for fold 5: loss of 0.2833448052406311; accuracy of 90.47619104385376%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 6 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 7.6895 - accuracy: 0.2649\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4137 - accuracy: 0.3459\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1855 - accuracy: 0.3892\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0806 - accuracy: 0.4432\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0647 - accuracy: 0.4973\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9836 - accuracy: 0.5081\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0503 - accuracy: 0.4757\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0564 - accuracy: 0.5676\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9264 - accuracy: 0.6000\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.6324\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.6595\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7459\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6890 - accuracy: 0.7243\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7443 - accuracy: 0.6054\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7261 - accuracy: 0.6595\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5965 - accuracy: 0.7081\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.7946\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.8000\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.7730\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.8054\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3665 - accuracy: 0.8432\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5503 - accuracy: 0.7405\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7508 - accuracy: 0.6703\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.7459\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.8270\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3523 - accuracy: 0.8270\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3341 - accuracy: 0.8703\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.8000\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3791 - accuracy: 0.8432\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3374 - accuracy: 0.8541\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3003 - accuracy: 0.8811\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3859 - accuracy: 0.8270\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3440 - accuracy: 0.8432\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.8000\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2823 - accuracy: 0.8649\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3535 - accuracy: 0.8486\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2994 - accuracy: 0.8432\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.8378\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3069 - accuracy: 0.8432\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2560 - accuracy: 0.8811\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2294 - accuracy: 0.8973\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2673 - accuracy: 0.8865\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3199 - accuracy: 0.8486\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2891 - accuracy: 0.8541\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3061 - accuracy: 0.8703\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3562 - accuracy: 0.8162\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2746 - accuracy: 0.8703\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2180 - accuracy: 0.9297\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2586 - accuracy: 0.9081\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3146 - accuracy: 0.8541\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3161 - accuracy: 0.8541\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2924 - accuracy: 0.8811\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2557 - accuracy: 0.8919\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2935 - accuracy: 0.8757\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2317 - accuracy: 0.9135\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3283 - accuracy: 0.8541\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3022 - accuracy: 0.8865\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2369 - accuracy: 0.9027\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.3390 - accuracy: 0.8500\n",
            "Score for fold 6: loss of 0.3389599621295929; accuracy of 85.00000238418579%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 7 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 7.1132 - accuracy: 0.3243\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5588 - accuracy: 0.3243\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1429 - accuracy: 0.3784\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0924 - accuracy: 0.4162\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0766 - accuracy: 0.3784\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1103 - accuracy: 0.4270\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0384 - accuracy: 0.4919\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0071 - accuracy: 0.4811\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9663 - accuracy: 0.4811\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7810 - accuracy: 0.6649\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7388 - accuracy: 0.6216\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7620 - accuracy: 0.6216\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6301 - accuracy: 0.7081\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6126 - accuracy: 0.6973\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6128 - accuracy: 0.7189\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7622\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7568\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5002 - accuracy: 0.7405\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6135 - accuracy: 0.7297\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7135\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.6865\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7676\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.8000\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7730\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5985 - accuracy: 0.6919\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.7568\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.8432\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.8432\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3496 - accuracy: 0.8486\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3332 - accuracy: 0.8595\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.8000\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3696 - accuracy: 0.8378\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5477 - accuracy: 0.7568\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4984 - accuracy: 0.7892\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3733 - accuracy: 0.8432\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3425 - accuracy: 0.8811\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3046 - accuracy: 0.8649\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3144 - accuracy: 0.8595\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2858 - accuracy: 0.9027\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2781 - accuracy: 0.8973\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3108 - accuracy: 0.8919\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2857 - accuracy: 0.8973\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2937 - accuracy: 0.8486\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2498 - accuracy: 0.9081\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2672 - accuracy: 0.9027\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3573 - accuracy: 0.8541\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3229 - accuracy: 0.8324\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2780 - accuracy: 0.8919\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2658 - accuracy: 0.8973\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2708 - accuracy: 0.9027\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2430 - accuracy: 0.9027\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2858 - accuracy: 0.8811\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.8054\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.7838\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.5067 - accuracy: 0.7500\n",
            "Score for fold 7: loss of 0.5067145824432373; accuracy of 75.0%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 8 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 7.4463 - accuracy: 0.3784\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.7239 - accuracy: 0.4162\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2108 - accuracy: 0.3838\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1732 - accuracy: 0.3568\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1576 - accuracy: 0.4216\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0611 - accuracy: 0.4108\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0398 - accuracy: 0.4432\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9749 - accuracy: 0.4811\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9839 - accuracy: 0.4703\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9035 - accuracy: 0.4865\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8059 - accuracy: 0.5568\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.6595\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7617 - accuracy: 0.6432\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7288 - accuracy: 0.6324\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6657 - accuracy: 0.7297\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6692 - accuracy: 0.6865\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6180 - accuracy: 0.7243\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.7081\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.7459\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6063 - accuracy: 0.7027\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.7459\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7946\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7730\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.8054\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.7459\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5992 - accuracy: 0.6757\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7459\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.7946\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6149 - accuracy: 0.6865\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5305 - accuracy: 0.7514\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.8000\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3719 - accuracy: 0.8324\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3856 - accuracy: 0.8216\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8270\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7892\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3616 - accuracy: 0.8270\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3505 - accuracy: 0.8703\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3457 - accuracy: 0.8486\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3195 - accuracy: 0.8595\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3732 - accuracy: 0.8541\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3506 - accuracy: 0.8595\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2798 - accuracy: 0.9027\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3444 - accuracy: 0.8703\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7676\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.7784\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7838\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7892\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3812 - accuracy: 0.8270\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7676\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8162\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3321 - accuracy: 0.8595\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3291 - accuracy: 0.8649\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.7096 - accuracy: 0.7500\n",
            "Score for fold 8: loss of 0.709626317024231; accuracy of 75.0%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 9 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 6.6372 - accuracy: 0.3459\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2149 - accuracy: 0.3892\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1490 - accuracy: 0.3946\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1028 - accuracy: 0.3784\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9575 - accuracy: 0.4649\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9932 - accuracy: 0.4919\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8874 - accuracy: 0.5892\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0137 - accuracy: 0.5189\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9108 - accuracy: 0.5297\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9202 - accuracy: 0.5622\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7740 - accuracy: 0.5676\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7070 - accuracy: 0.6486\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6046 - accuracy: 0.7351\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6154 - accuracy: 0.6649\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5421 - accuracy: 0.7189\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.7135\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7324 - accuracy: 0.6811\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7066 - accuracy: 0.6486\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7135\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7568\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7946\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.8000\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.7946\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.7730\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.7784\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.8108\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3932 - accuracy: 0.7892\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3866 - accuracy: 0.8270\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.7676\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7892\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.7784\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7189\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7838\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7892\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8270\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3293 - accuracy: 0.8649\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8000\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3549 - accuracy: 0.8162\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3128 - accuracy: 0.8541\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3181 - accuracy: 0.8703\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.8108\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7730\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3470 - accuracy: 0.8486\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3036 - accuracy: 0.8703\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3322 - accuracy: 0.8703\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3276 - accuracy: 0.8541\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2819 - accuracy: 0.8811\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3121 - accuracy: 0.8595\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3097 - accuracy: 0.8703\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3052 - accuracy: 0.8595\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3271 - accuracy: 0.8324\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5592 - accuracy: 0.7730\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3627 - accuracy: 0.8216\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2878 - accuracy: 0.8919\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2666 - accuracy: 0.8757\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2658 - accuracy: 0.9027\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2552 - accuracy: 0.8811\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2742 - accuracy: 0.9135\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3896 - accuracy: 0.8216\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2776 - accuracy: 0.8811\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3009 - accuracy: 0.8811\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2536 - accuracy: 0.9081\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3180 - accuracy: 0.8270\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3695 - accuracy: 0.8162\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2904 - accuracy: 0.8703\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2955 - accuracy: 0.8649\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2473 - accuracy: 0.9189\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2357 - accuracy: 0.9027\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2534 - accuracy: 0.8865\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3780 - accuracy: 0.8216\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3118 - accuracy: 0.8649\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2576 - accuracy: 0.8973\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2363 - accuracy: 0.8973\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2766 - accuracy: 0.8811\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.8973\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.8270\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.8162\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.2308 - accuracy: 0.9500\n",
            "Score for fold 9: loss of 0.23076696693897247; accuracy of 94.9999988079071%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 10 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 6ms/step - loss: 7.3289 - accuracy: 0.2486\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2515 - accuracy: 0.3459\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1057 - accuracy: 0.4216\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1571 - accuracy: 0.4108\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0703 - accuracy: 0.4324\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9344 - accuracy: 0.5514\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8052 - accuracy: 0.5946\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8026 - accuracy: 0.5946\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6459 - accuracy: 0.6541\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7045 - accuracy: 0.6324\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6743 - accuracy: 0.6865\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8741 - accuracy: 0.5838\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.6216\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.7189\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7243\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.6865\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.8216\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.7892\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.8216\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.8541\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7946\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.8054\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3715 - accuracy: 0.8270\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3404 - accuracy: 0.8541\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3710 - accuracy: 0.8486\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.8054\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1088 - accuracy: 0.5784\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7290 - accuracy: 0.5622\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7405\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.8000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.2319 - accuracy: 0.9000\n",
            "Score for fold 10: loss of 0.23185360431671143; accuracy of 89.99999761581421%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_acc.append(acc_per_fold)"
      ],
      "metadata": {
        "id": "kQaXKItRSd6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc.append(model_3.evaluate(X_test,y_test)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6LPkYpSX787",
        "outputId": "8f388a24-b419-4a7f-b07f-eb12e9e52c67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3418 - accuracy: 0.8697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc.append(model_3.evaluate(X_train,y_train)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27CLGUsykG8d",
        "outputId": "b7e89b6c-89ff-4fdf-bc80-2d3bcd889ce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average.append(round(Average(acc_per_fold),2))"
      ],
      "metadata": {
        "id": "zsg1YPjFQI4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model 4 (GELU)"
      ],
      "metadata": {
        "id": "Vu5GioZjT6zS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc_per_fold=[]\n",
        "loss_per_fold=[]"
      ],
      "metadata": {
        "id": "40s-DFVsUA6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model_4 = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(512, input_shape=[4],activation=tf.keras.activations.gelu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.gelu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.gelu),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.keras.activations.gelu),\n",
        "                                    tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
        "                                    ])\n",
        "\n",
        "  # Compile the model\n",
        "  model_4.compile(loss=\"SparseCategoricalCrossentropy\",\n",
        "                optimizer=adam,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model_4.fit(inputs[train], targets[train],\n",
        "              batch_size=16,\n",
        "              epochs=100,\n",
        "              verbose=1,\n",
        "              callbacks=callback)\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model_4.evaluate(inputs[test], targets[test], verbose=1)\n",
        "  print(f'Score for fold {fold_no}: {model_4.metrics_names[0]} of {scores[0]}; {model_4.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ccdd783-7a52-42de-eb1f-39508d7da5d1",
        "id": "7rgG2phbUA6v"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 3ms/step - loss: 5.2058 - accuracy: 0.3261\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2144 - accuracy: 0.4293\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0654 - accuracy: 0.3967\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9757 - accuracy: 0.4348\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8475 - accuracy: 0.6033\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8359 - accuracy: 0.6033\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9179 - accuracy: 0.5598\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6804 - accuracy: 0.6739\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6047 - accuracy: 0.7391\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7283\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7500\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7609\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.8152\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.8043\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.7989\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3877 - accuracy: 0.8370\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8261\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.8315\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3185 - accuracy: 0.8587\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6530 - accuracy: 0.7174\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7552 - accuracy: 0.7011\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5878 - accuracy: 0.6902\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.7935\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3757 - accuracy: 0.8315\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8533\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3286 - accuracy: 0.8533\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3015 - accuracy: 0.8859\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2822 - accuracy: 0.8913\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3767 - accuracy: 0.8370\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3197 - accuracy: 0.8478\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2784 - accuracy: 0.9076\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2727 - accuracy: 0.8859\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2607 - accuracy: 0.9185\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2761 - accuracy: 0.8804\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2814 - accuracy: 0.8859\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7663\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.7717\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.7989\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7609\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3736 - accuracy: 0.8043\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3630 - accuracy: 0.8261\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3583 - accuracy: 0.8587\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3973 - accuracy: 0.8043\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.2932 - accuracy: 0.9524\n",
            "Score for fold 1: loss of 0.2932153344154358; accuracy of 95.23809552192688%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 3ms/step - loss: 4.8604 - accuracy: 0.3043\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5147 - accuracy: 0.4076\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1155 - accuracy: 0.3804\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9945 - accuracy: 0.4402\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8557 - accuracy: 0.5761\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.6413\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7831 - accuracy: 0.6141\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5979 - accuracy: 0.7717\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7880\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.8152\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.7609\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6315 - accuracy: 0.7554\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8069 - accuracy: 0.6304\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7120 - accuracy: 0.6630\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5479 - accuracy: 0.7500\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.7880\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.7772\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.8261\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3714 - accuracy: 0.8424\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2857 - accuracy: 0.9130\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3212 - accuracy: 0.8804\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7826\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7826\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7772\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7609\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7880\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3593 - accuracy: 0.8641\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3284 - accuracy: 0.8587\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3061 - accuracy: 0.8696\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2650 - accuracy: 0.8913\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.4951 - accuracy: 0.8571\n",
            "Score for fold 2: loss of 0.49510061740875244; accuracy of 85.71428656578064%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 3ms/step - loss: 3.9297 - accuracy: 0.3750\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6651 - accuracy: 0.3478\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2356 - accuracy: 0.3098\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1174 - accuracy: 0.3641\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9787 - accuracy: 0.4674\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8538 - accuracy: 0.6196\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8020 - accuracy: 0.6033\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6960 - accuracy: 0.6196\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.6630\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5975 - accuracy: 0.6848\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.7011\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.7283\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6915 - accuracy: 0.6739\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.7120\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7609\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8043\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.7989\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7989\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7446\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3433 - accuracy: 0.8750\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3561 - accuracy: 0.8261\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3818 - accuracy: 0.8587\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3959 - accuracy: 0.8261\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3228 - accuracy: 0.8370\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3069 - accuracy: 0.8913\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3303 - accuracy: 0.8315\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.8098\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3146 - accuracy: 0.8696\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3452 - accuracy: 0.8315\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3222 - accuracy: 0.8750\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2849 - accuracy: 0.8804\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2837 - accuracy: 0.8804\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2549 - accuracy: 0.8913\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2684 - accuracy: 0.9022\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2949 - accuracy: 0.8750\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3428 - accuracy: 0.8478\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3454 - accuracy: 0.8533\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2347 - accuracy: 0.9239\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2237 - accuracy: 0.9076\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2629 - accuracy: 0.8967\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2879 - accuracy: 0.8696\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3203 - accuracy: 0.8152\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3528 - accuracy: 0.7989\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2991 - accuracy: 0.8696\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2257 - accuracy: 0.9293\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1939 - accuracy: 0.9293\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1783 - accuracy: 0.9130\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2050 - accuracy: 0.9185\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3098 - accuracy: 0.8859\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2300 - accuracy: 0.9076\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2005 - accuracy: 0.9185\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2165 - accuracy: 0.9130\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1706 - accuracy: 0.9402\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1683 - accuracy: 0.9565\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2756 - accuracy: 0.8804\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1723 - accuracy: 0.9239\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.9185\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2152 - accuracy: 0.9130\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2924 - accuracy: 0.8533\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.8152\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7283\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3714 - accuracy: 0.8478\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2547 - accuracy: 0.9130\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2199 - accuracy: 0.9022\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.4101 - accuracy: 0.7619\n",
            "Score for fold 3: loss of 0.41010260581970215; accuracy of 76.1904776096344%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 3ms/step - loss: 3.8487 - accuracy: 0.3913\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1517 - accuracy: 0.4511\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0500 - accuracy: 0.4402\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9805 - accuracy: 0.4674\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9560 - accuracy: 0.5109\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7276 - accuracy: 0.6685\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8225 - accuracy: 0.6359\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9371 - accuracy: 0.5543\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7497 - accuracy: 0.6413\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5621 - accuracy: 0.7772\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6098 - accuracy: 0.7228\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.7826\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6098 - accuracy: 0.7391\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.7663\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.7283\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5376 - accuracy: 0.7283\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7663\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7935\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.8043\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.8098\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.6467\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5753 - accuracy: 0.7554\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.8043\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3612 - accuracy: 0.8804\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3431 - accuracy: 0.8641\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4009 - accuracy: 0.8424\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.8152\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3637 - accuracy: 0.8424\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3241 - accuracy: 0.8533\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3102 - accuracy: 0.8804\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3082 - accuracy: 0.8641\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2957 - accuracy: 0.8967\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2870 - accuracy: 0.9022\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3049 - accuracy: 0.8913\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3200 - accuracy: 0.8587\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3874 - accuracy: 0.8424\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3041 - accuracy: 0.8859\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2624 - accuracy: 0.9076\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2412 - accuracy: 0.9022\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2410 - accuracy: 0.9239\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2622 - accuracy: 0.8967\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2517 - accuracy: 0.9022\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 0.9130\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2593 - accuracy: 0.8913\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2123 - accuracy: 0.9348\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2434 - accuracy: 0.9130\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3481 - accuracy: 0.8370\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7989\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3424 - accuracy: 0.8587\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2960 - accuracy: 0.8641\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2726 - accuracy: 0.8967\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2637 - accuracy: 0.8804\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2150 - accuracy: 0.9130\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2173 - accuracy: 0.9022\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2668 - accuracy: 0.8696\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.3341 - accuracy: 0.8095\n",
            "Score for fold 4: loss of 0.334086537361145; accuracy of 80.95238208770752%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 3ms/step - loss: 6.1704 - accuracy: 0.3370\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.3770 - accuracy: 0.4076\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2602 - accuracy: 0.3804\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0616 - accuracy: 0.4076\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0504 - accuracy: 0.4402\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9865 - accuracy: 0.4457\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9333 - accuracy: 0.5543\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8460 - accuracy: 0.5598\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7793 - accuracy: 0.5870\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7737 - accuracy: 0.6413\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6771 - accuracy: 0.6630\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.7500\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.7065\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7500\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.7772\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7554\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7446\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.7446\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7989\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4913 - accuracy: 0.7772\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.7989\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3639 - accuracy: 0.8424\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3455 - accuracy: 0.8587\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.7446\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7772\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7935\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3336 - accuracy: 0.8641\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3067 - accuracy: 0.9239\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3056 - accuracy: 0.8804\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3079 - accuracy: 0.8641\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3234 - accuracy: 0.8696\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2896 - accuracy: 0.8859\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2576 - accuracy: 0.8967\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3092 - accuracy: 0.8696\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7717\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3637 - accuracy: 0.8641\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3141 - accuracy: 0.8533\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3055 - accuracy: 0.8913\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.3997 - accuracy: 0.7619\n",
            "Score for fold 5: loss of 0.3996584415435791; accuracy of 76.1904776096344%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 6 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 3ms/step - loss: 7.6786 - accuracy: 0.2757\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.7887 - accuracy: 0.3622\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1471 - accuracy: 0.3730\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0280 - accuracy: 0.4811\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9806 - accuracy: 0.5297\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9092 - accuracy: 0.5676\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8961 - accuracy: 0.5568\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8836 - accuracy: 0.5514\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7935 - accuracy: 0.6432\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6610 - accuracy: 0.6973\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.7622\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7246 - accuracy: 0.6324\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.7027\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5496 - accuracy: 0.7459\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.8108\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.8054\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.8054\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7838\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.7838\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3973 - accuracy: 0.8000\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3742 - accuracy: 0.8486\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3729 - accuracy: 0.8432\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3527 - accuracy: 0.8378\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3720 - accuracy: 0.8108\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3506 - accuracy: 0.8378\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3566 - accuracy: 0.8162\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3799 - accuracy: 0.8270\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3429 - accuracy: 0.8432\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7730\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.8108\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.7730\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.3074 - accuracy: 0.8500\n",
            "Score for fold 6: loss of 0.30741363763809204; accuracy of 85.00000238418579%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 7 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 3ms/step - loss: 5.1026 - accuracy: 0.3297\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5398 - accuracy: 0.3568\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0551 - accuracy: 0.4378\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8795 - accuracy: 0.5730\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0031 - accuracy: 0.5351\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0023 - accuracy: 0.4919\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8158 - accuracy: 0.5784\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7488 - accuracy: 0.5784\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6588 - accuracy: 0.6811\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.8054\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6817 - accuracy: 0.6378\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6593 - accuracy: 0.6378\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5960 - accuracy: 0.7081\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.8054\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3820 - accuracy: 0.8162\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.8270\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7730\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.8486\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3727 - accuracy: 0.7946\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3358 - accuracy: 0.8378\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3860 - accuracy: 0.8378\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.8108\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3316 - accuracy: 0.8649\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3779 - accuracy: 0.8378\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2984 - accuracy: 0.8919\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3349 - accuracy: 0.8649\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3451 - accuracy: 0.8649\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8649\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2909 - accuracy: 0.8541\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2595 - accuracy: 0.9027\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.9081\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2526 - accuracy: 0.9243\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3251 - accuracy: 0.8649\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.8865\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2671 - accuracy: 0.8919\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2336 - accuracy: 0.9081\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2258 - accuracy: 0.9243\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2735 - accuracy: 0.8757\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3013 - accuracy: 0.8595\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7838\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2907 - accuracy: 0.8703\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.8973\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.3118 - accuracy: 0.9000\n",
            "Score for fold 7: loss of 0.31182846426963806; accuracy of 89.99999761581421%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 8 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 3ms/step - loss: 4.8806 - accuracy: 0.3622\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4571 - accuracy: 0.4000\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1716 - accuracy: 0.4000\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0935 - accuracy: 0.4000\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0085 - accuracy: 0.4541\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0038 - accuracy: 0.4595\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9047 - accuracy: 0.5730\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8200 - accuracy: 0.6108\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7474 - accuracy: 0.6541\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7050 - accuracy: 0.6432\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.7027\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7784\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.8000\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7717 - accuracy: 0.6216\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5559 - accuracy: 0.7297\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.7351\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5299 - accuracy: 0.7514\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6433 - accuracy: 0.6757\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5683 - accuracy: 0.7405\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7946\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8216\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3657 - accuracy: 0.8649\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3209 - accuracy: 0.8703\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3033 - accuracy: 0.8757\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3052 - accuracy: 0.8703\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.8000\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3562 - accuracy: 0.8541\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7676\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7568\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.8000\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.8216\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8541\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3298 - accuracy: 0.8757\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2751 - accuracy: 0.8919\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2628 - accuracy: 0.9081\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2797 - accuracy: 0.8811\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2668 - accuracy: 0.8973\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2569 - accuracy: 0.8973\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3030 - accuracy: 0.8703\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2682 - accuracy: 0.8865\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2874 - accuracy: 0.8811\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2737 - accuracy: 0.9027\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2586 - accuracy: 0.9027\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3521 - accuracy: 0.8270\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3026 - accuracy: 0.8541\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.3065 - accuracy: 0.8500\n",
            "Score for fold 8: loss of 0.3064562678337097; accuracy of 85.00000238418579%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 9 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 3ms/step - loss: 5.3469 - accuracy: 0.3946\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6175 - accuracy: 0.4216\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1705 - accuracy: 0.3838\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0731 - accuracy: 0.4432\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9928 - accuracy: 0.4757\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9023 - accuracy: 0.5297\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7789 - accuracy: 0.6162\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.6703\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5844 - accuracy: 0.7081\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.7405\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7676\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.7892\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6009 - accuracy: 0.7135\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8205 - accuracy: 0.5946\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5963 - accuracy: 0.6919\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7730\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.8000\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3895 - accuracy: 0.8432\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3718 - accuracy: 0.8378\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3549 - accuracy: 0.7838\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3741 - accuracy: 0.8432\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7946\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7351\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7838\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3644 - accuracy: 0.8324\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3104 - accuracy: 0.8757\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3439 - accuracy: 0.8378\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3250 - accuracy: 0.8541\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3292 - accuracy: 0.8757\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2743 - accuracy: 0.9081\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2822 - accuracy: 0.8919\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2955 - accuracy: 0.8541\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3064 - accuracy: 0.8703\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2519 - accuracy: 0.9189\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2891 - accuracy: 0.8811\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2772 - accuracy: 0.9081\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3581 - accuracy: 0.8486\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.8000\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3481 - accuracy: 0.8541\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3076 - accuracy: 0.8703\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2670 - accuracy: 0.9027\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2183 - accuracy: 0.9243\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2221 - accuracy: 0.9243\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2318 - accuracy: 0.8919\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3483 - accuracy: 0.8541\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2894 - accuracy: 0.8541\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2953 - accuracy: 0.8865\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2300 - accuracy: 0.9243\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2800 - accuracy: 0.8649\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2685 - accuracy: 0.9027\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2041 - accuracy: 0.9351\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2261 - accuracy: 0.9081\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1948 - accuracy: 0.9297\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2147 - accuracy: 0.9081\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2026 - accuracy: 0.9189\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1994 - accuracy: 0.9135\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3027 - accuracy: 0.8595\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2640 - accuracy: 0.8919\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2265 - accuracy: 0.9189\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2050 - accuracy: 0.9297\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2556 - accuracy: 0.8919\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.3697 - accuracy: 0.8500\n",
            "Score for fold 9: loss of 0.3697220981121063; accuracy of 85.00000238418579%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 10 ...\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 3ms/step - loss: 4.8041 - accuracy: 0.3622\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3468 - accuracy: 0.3676\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2295 - accuracy: 0.3514\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0407 - accuracy: 0.4541\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9495 - accuracy: 0.5027\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8386 - accuracy: 0.5892\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7449 - accuracy: 0.6541\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7792 - accuracy: 0.6216\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7296 - accuracy: 0.6649\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6127 - accuracy: 0.7405\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5714 - accuracy: 0.7405\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7892\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.7081\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7001 - accuracy: 0.6703\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5747 - accuracy: 0.7135\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7892\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7838\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6973\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5680 - accuracy: 0.7459\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7730\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3777 - accuracy: 0.8378\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3622 - accuracy: 0.8216\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3272 - accuracy: 0.8378\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3164 - accuracy: 0.8757\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2925 - accuracy: 0.8595\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3511 - accuracy: 0.8649\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7838\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.7946\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4044 - accuracy: 0.8054\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3141 - accuracy: 0.8541\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3128 - accuracy: 0.8595\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2854 - accuracy: 0.8865\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2626 - accuracy: 0.8919\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2901 - accuracy: 0.8595\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2513 - accuracy: 0.8865\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2807 - accuracy: 0.8595\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2765 - accuracy: 0.8865\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3288 - accuracy: 0.8541\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2767 - accuracy: 0.8649\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2772 - accuracy: 0.8649\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2427 - accuracy: 0.8919\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2111 - accuracy: 0.9189\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2180 - accuracy: 0.9243\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2205 - accuracy: 0.9189\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1949 - accuracy: 0.9189\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2050 - accuracy: 0.9297\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2104 - accuracy: 0.9243\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2105 - accuracy: 0.9189\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2239 - accuracy: 0.9081\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1955 - accuracy: 0.9351\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2418 - accuracy: 0.8757\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.8973\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2218 - accuracy: 0.9243\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2285 - accuracy: 0.9189\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1930 - accuracy: 0.9297\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1844 - accuracy: 0.9405\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3047 - accuracy: 0.8973\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2342 - accuracy: 0.9027\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2722 - accuracy: 0.8919\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2135 - accuracy: 0.9297\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2430 - accuracy: 0.8865\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2096 - accuracy: 0.9135\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2194 - accuracy: 0.9027\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2098 - accuracy: 0.9297\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1865 - accuracy: 0.9297\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1634 - accuracy: 0.9351\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.2958 - accuracy: 0.9000\n",
            "Score for fold 10: loss of 0.29581528902053833; accuracy of 89.99999761581421%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_acc.append(acc_per_fold)"
      ],
      "metadata": {
        "id": "-jSpYZjjUA6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc.append(model_4.evaluate(X_test,y_test)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIOCVE8ZYAbf",
        "outputId": "d0c5507d-bd64-4588-bd4e-ff9dea4afcd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.8056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc.append(model_4.evaluate(X_train,y_train)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7xtlWwHkOpT",
        "outputId": "8cfffe3e-965c-44d5-cf6c-fb47120388f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average.append(round(Average(acc_per_fold),2))"
      ],
      "metadata": {
        "id": "p-HeLnt3UA6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hasil Prediksi"
      ],
      "metadata": {
        "id": "CCYL3USTbUB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ry98YYqYbSlM",
        "outputId": "a543a422-c0f9-454c-92d1-b650063e0d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[61.90476417541504,\n",
              "  52.3809552192688,\n",
              "  76.1904776096344,\n",
              "  66.66666865348816,\n",
              "  47.61904776096344,\n",
              "  55.000001192092896,\n",
              "  80.0000011920929,\n",
              "  80.0000011920929,\n",
              "  80.0000011920929,\n",
              "  75.0],\n",
              " [76.1904776096344,\n",
              "  90.47619104385376,\n",
              "  80.95238208770752,\n",
              "  66.66666865348816,\n",
              "  85.71428656578064,\n",
              "  60.00000238418579,\n",
              "  75.0,\n",
              "  94.9999988079071,\n",
              "  89.99999761581421,\n",
              "  80.0000011920929],\n",
              " [85.71428656578064,\n",
              "  76.1904776096344,\n",
              "  90.47619104385376,\n",
              "  90.47619104385376,\n",
              "  90.47619104385376,\n",
              "  85.00000238418579,\n",
              "  75.0,\n",
              "  75.0,\n",
              "  94.9999988079071,\n",
              "  89.99999761581421],\n",
              " [95.23809552192688,\n",
              "  85.71428656578064,\n",
              "  76.1904776096344,\n",
              "  80.95238208770752,\n",
              "  76.1904776096344,\n",
              "  85.00000238418579,\n",
              "  89.99999761581421,\n",
              "  85.00000238418579,\n",
              "  85.00000238418579,\n",
              "  89.99999761581421]]"
            ]
          },
          "metadata": {},
          "execution_count": 404
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDrjwi8_bJYn",
        "outputId": "cc5f95bd-dec4-4b79-f6c5-b037d1d9075a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7606837749481201,\n",
              " 0.8376068472862244,\n",
              " 0.8696581125259399,\n",
              " 0.8055555820465088]"
            ]
          },
          "metadata": {},
          "execution_count": 405
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyFbo2s5kUVw",
        "outputId": "33020ff0-03f0-49eb-c061-93345e11605c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7606837749481201,\n",
              " 0.9059829115867615,\n",
              " 0.8717948794364929,\n",
              " 0.8547008633613586]"
            ]
          },
          "metadata": {},
          "execution_count": 406
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLEu4EC7VHcY",
        "outputId": "447f4ce7-10bd-4c69-f9aa-fa7af870b6b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[67.48, 80.0, 85.33, 84.93]"
            ]
          },
          "metadata": {},
          "execution_count": 407
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Ensemble Learning**"
      ],
      "metadata": {
        "id": "1azmdpMgL4qK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adam = Adam(learning_rate=0.001)"
      ],
      "metadata": {
        "id": "wvkyGR3D_cNA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Callback\n",
        "callback = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    mode='auto'\n",
        ")"
      ],
      "metadata": {
        "id": "Tkkb0OA8_cNA"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ensemble Learning (ReLU, ELU, GELU)"
      ],
      "metadata": {
        "id": "ZG1hFF90EdFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(512, input_shape=[4],activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
        "                                    ])\n",
        "model_2 = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(512, input_shape=[4],activation=tf.keras.activations.elu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.elu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.elu),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.keras.activations.elu),\n",
        "                                    tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
        "                                    ])\n",
        "model_3 = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(512, input_shape=[4],activation=tf.keras.activations.gelu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.gelu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.gelu),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.keras.activations.gelu),\n",
        "                                    tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
        "                                    ])\n",
        "model_1.compile(loss=SparseCategoricalCrossentropy(from_logits=False),optimizer=adam,metrics=['accuracy'])\n",
        "model_2.compile(loss=SparseCategoricalCrossentropy(from_logits=False),optimizer=adam,metrics=['accuracy'])\n",
        "model_3.compile(loss=SparseCategoricalCrossentropy(from_logits=False),optimizer=adam,metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "9DFEoLTCEfjP"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_1 = model_1.fit(X_train, y_train,batch_size=16,epochs=100,verbose=1,callbacks=callback)\n",
        "history_2 = model_2.fit(X_train, y_train,batch_size=16,epochs=100,verbose=1,callbacks=callback)\n",
        "history_3 = model_3.fit(X_train, y_train,batch_size=16,epochs=100,verbose=1,callbacks=callback)"
      ],
      "metadata": {
        "id": "DMcB19NZwjfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_1 = model_1.fit(X_train, y_train,validation_data=(X_valid, y_valid),batch_size=16,epochs=100,verbose=1,callbacks=callback)\n",
        "history_2 = model_2.fit(X_train, y_train,validation_data=(X_valid, y_valid),batch_size=16,epochs=100,verbose=1,callbacks=callback)\n",
        "history_3 = model_3.fit(X_train, y_train,validation_data=(X_valid, y_valid),batch_size=16,epochs=100,verbose=1,callbacks=callback)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sz9l63PnwkFK",
        "outputId": "b422d41e-da21-4ef1-a5d9-2c2beb9b4c29"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 2.2142 - accuracy: 0.3483 - val_loss: 1.1298 - val_accuracy: 0.3448\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.9386 - accuracy: 0.5919 - val_loss: 0.8034 - val_accuracy: 0.5862\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.8467 - accuracy: 0.6132 - val_loss: 0.8721 - val_accuracy: 0.5862\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.6352 - accuracy: 0.7179 - val_loss: 0.9709 - val_accuracy: 0.4828\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.6433 - accuracy: 0.6816 - val_loss: 0.7103 - val_accuracy: 0.7241\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4847 - accuracy: 0.7927 - val_loss: 0.9878 - val_accuracy: 0.6897\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.5669 - accuracy: 0.7436 - val_loss: 0.6386 - val_accuracy: 0.6207\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.4512 - accuracy: 0.8013 - val_loss: 0.8154 - val_accuracy: 0.7241\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.4324 - accuracy: 0.8162 - val_loss: 0.5323 - val_accuracy: 0.6897\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.4359 - accuracy: 0.7778 - val_loss: 0.4540 - val_accuracy: 0.6897\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3800 - accuracy: 0.8184 - val_loss: 0.4820 - val_accuracy: 0.6897\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.4165 - accuracy: 0.7842 - val_loss: 0.6332 - val_accuracy: 0.6207\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.4909 - accuracy: 0.7863 - val_loss: 0.6063 - val_accuracy: 0.7241\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.3706 - accuracy: 0.8333 - val_loss: 0.6486 - val_accuracy: 0.7586\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.4013 - accuracy: 0.8034 - val_loss: 0.5432 - val_accuracy: 0.7241\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.3830 - accuracy: 0.8312 - val_loss: 0.4426 - val_accuracy: 0.7241\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.3687 - accuracy: 0.8312 - val_loss: 0.4019 - val_accuracy: 0.7586\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.3810 - accuracy: 0.8056 - val_loss: 0.4539 - val_accuracy: 0.6897\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3849 - accuracy: 0.8291 - val_loss: 0.4367 - val_accuracy: 0.7241\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3545 - accuracy: 0.8397 - val_loss: 0.4053 - val_accuracy: 0.7931\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.5014 - accuracy: 0.7692 - val_loss: 0.6187 - val_accuracy: 0.6207\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.4775 - accuracy: 0.7585 - val_loss: 0.4486 - val_accuracy: 0.6897\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3614 - accuracy: 0.8440 - val_loss: 0.3960 - val_accuracy: 0.7241\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3474 - accuracy: 0.8333 - val_loss: 0.5196 - val_accuracy: 0.6897\n",
            "Epoch 25/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.3843 - accuracy: 0.8120 - val_loss: 0.4397 - val_accuracy: 0.7241\n",
            "Epoch 26/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.3515 - accuracy: 0.8312 - val_loss: 0.4065 - val_accuracy: 0.7931\n",
            "Epoch 27/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3930 - accuracy: 0.8269 - val_loss: 0.4192 - val_accuracy: 0.7931\n",
            "Epoch 28/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3126 - accuracy: 0.8846 - val_loss: 0.3902 - val_accuracy: 0.7241\n",
            "Epoch 29/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3088 - accuracy: 0.8675 - val_loss: 0.4542 - val_accuracy: 0.7931\n",
            "Epoch 30/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.4186 - accuracy: 0.8162 - val_loss: 0.4833 - val_accuracy: 0.7586\n",
            "Epoch 31/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3673 - accuracy: 0.8355 - val_loss: 0.4927 - val_accuracy: 0.7586\n",
            "Epoch 32/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.3108 - accuracy: 0.8739 - val_loss: 0.4745 - val_accuracy: 0.7586\n",
            "Epoch 33/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.4429 - accuracy: 0.8098 - val_loss: 0.6099 - val_accuracy: 0.6552\n",
            "Epoch 34/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.4596 - accuracy: 0.7906 - val_loss: 0.4324 - val_accuracy: 0.6897\n",
            "Epoch 35/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.3409 - accuracy: 0.8526 - val_loss: 0.4663 - val_accuracy: 0.7241\n",
            "Epoch 36/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3212 - accuracy: 0.8654 - val_loss: 0.4421 - val_accuracy: 0.7586\n",
            "Epoch 37/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.3064 - accuracy: 0.8761 - val_loss: 0.6727 - val_accuracy: 0.7241\n",
            "Epoch 38/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3496 - accuracy: 0.8376 - val_loss: 0.4023 - val_accuracy: 0.7586\n",
            "Epoch 1/100\n",
            "30/30 [==============================] - 1s 12ms/step - loss: 3.6503 - accuracy: 0.3611 - val_loss: 1.0835 - val_accuracy: 0.4483\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 1.2052 - accuracy: 0.3718 - val_loss: 1.0176 - val_accuracy: 0.4138\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 1.0010 - accuracy: 0.4744 - val_loss: 0.8573 - val_accuracy: 0.5172\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.8637 - accuracy: 0.5919 - val_loss: 0.7865 - val_accuracy: 0.5172\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.6296 - accuracy: 0.7137 - val_loss: 0.5776 - val_accuracy: 0.6897\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.6020 - accuracy: 0.7265 - val_loss: 0.6880 - val_accuracy: 0.6897\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.5681 - accuracy: 0.7244 - val_loss: 0.8903 - val_accuracy: 0.7931\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.5689 - accuracy: 0.7201 - val_loss: 0.5570 - val_accuracy: 0.6897\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.5139 - accuracy: 0.7457 - val_loss: 0.5941 - val_accuracy: 0.7241\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.4461 - accuracy: 0.8056 - val_loss: 0.4085 - val_accuracy: 0.8276\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3781 - accuracy: 0.8397 - val_loss: 0.3726 - val_accuracy: 0.8966\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.4142 - accuracy: 0.8355 - val_loss: 0.5409 - val_accuracy: 0.6897\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3841 - accuracy: 0.8333 - val_loss: 0.5222 - val_accuracy: 0.6552\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.4004 - accuracy: 0.8269 - val_loss: 0.4134 - val_accuracy: 0.6897\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3458 - accuracy: 0.8269 - val_loss: 0.3430 - val_accuracy: 0.7586\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3190 - accuracy: 0.8483 - val_loss: 0.4347 - val_accuracy: 0.7586\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2883 - accuracy: 0.8868 - val_loss: 0.6680 - val_accuracy: 0.7931\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4044 - accuracy: 0.8184 - val_loss: 0.3050 - val_accuracy: 0.8276\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2890 - accuracy: 0.8889 - val_loss: 0.2516 - val_accuracy: 0.8621\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.3241 - accuracy: 0.8483 - val_loss: 0.2836 - val_accuracy: 0.8276\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.3054 - accuracy: 0.8803 - val_loss: 0.3272 - val_accuracy: 0.8966\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3857 - accuracy: 0.8504 - val_loss: 0.4350 - val_accuracy: 0.7931\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3957 - accuracy: 0.8162 - val_loss: 0.3953 - val_accuracy: 0.7931\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2922 - accuracy: 0.8739 - val_loss: 0.3082 - val_accuracy: 0.8276\n",
            "Epoch 25/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3083 - accuracy: 0.8846 - val_loss: 0.5257 - val_accuracy: 0.7931\n",
            "Epoch 26/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3688 - accuracy: 0.8440 - val_loss: 0.2391 - val_accuracy: 0.8966\n",
            "Epoch 27/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3386 - accuracy: 0.8654 - val_loss: 0.3213 - val_accuracy: 0.7586\n",
            "Epoch 28/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2488 - accuracy: 0.9017 - val_loss: 0.2508 - val_accuracy: 0.8621\n",
            "Epoch 29/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.3046 - accuracy: 0.8803 - val_loss: 0.6044 - val_accuracy: 0.7931\n",
            "Epoch 30/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3758 - accuracy: 0.8355 - val_loss: 0.2725 - val_accuracy: 0.8621\n",
            "Epoch 31/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2908 - accuracy: 0.8761 - val_loss: 0.8768 - val_accuracy: 0.6897\n",
            "Epoch 32/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3009 - accuracy: 0.8697 - val_loss: 0.3902 - val_accuracy: 0.7931\n",
            "Epoch 33/100\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.2382 - accuracy: 0.8996 - val_loss: 0.2411 - val_accuracy: 0.8276\n",
            "Epoch 34/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2618 - accuracy: 0.9038 - val_loss: 0.4585 - val_accuracy: 0.7586\n",
            "Epoch 35/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3565 - accuracy: 0.8291 - val_loss: 0.2182 - val_accuracy: 0.8966\n",
            "Epoch 36/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2514 - accuracy: 0.8953 - val_loss: 0.2622 - val_accuracy: 0.8621\n",
            "Epoch 37/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2955 - accuracy: 0.8739 - val_loss: 0.3012 - val_accuracy: 0.7931\n",
            "Epoch 38/100\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.2896 - accuracy: 0.8782 - val_loss: 0.3161 - val_accuracy: 0.8621\n",
            "Epoch 39/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3040 - accuracy: 0.8590 - val_loss: 0.2632 - val_accuracy: 0.8966\n",
            "Epoch 40/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2655 - accuracy: 0.8953 - val_loss: 0.2586 - val_accuracy: 0.8621\n",
            "Epoch 41/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2571 - accuracy: 0.8910 - val_loss: 0.5277 - val_accuracy: 0.7586\n",
            "Epoch 42/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3177 - accuracy: 0.8611 - val_loss: 0.2587 - val_accuracy: 0.8621\n",
            "Epoch 43/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.2297 - accuracy: 0.9145 - val_loss: 0.5057 - val_accuracy: 0.7586\n",
            "Epoch 44/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4364 - accuracy: 0.8077 - val_loss: 0.3196 - val_accuracy: 0.8276\n",
            "Epoch 45/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2492 - accuracy: 0.9081 - val_loss: 0.2148 - val_accuracy: 0.9310\n",
            "Epoch 46/100\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.2608 - accuracy: 0.8953 - val_loss: 0.2851 - val_accuracy: 0.8276\n",
            "Epoch 47/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2136 - accuracy: 0.9209 - val_loss: 0.2306 - val_accuracy: 0.8621\n",
            "Epoch 48/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.1968 - accuracy: 0.9124 - val_loss: 0.1961 - val_accuracy: 0.8966\n",
            "Epoch 49/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1848 - accuracy: 0.9231 - val_loss: 0.2414 - val_accuracy: 0.8966\n",
            "Epoch 50/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2160 - accuracy: 0.9231 - val_loss: 0.2624 - val_accuracy: 0.8621\n",
            "Epoch 51/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.1996 - accuracy: 0.9188 - val_loss: 0.5443 - val_accuracy: 0.7586\n",
            "Epoch 52/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3388 - accuracy: 0.8590 - val_loss: 0.2798 - val_accuracy: 0.8621\n",
            "Epoch 53/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2980 - accuracy: 0.8910 - val_loss: 0.2469 - val_accuracy: 0.8621\n",
            "Epoch 54/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2700 - accuracy: 0.8953 - val_loss: 0.2486 - val_accuracy: 0.8621\n",
            "Epoch 55/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2118 - accuracy: 0.9316 - val_loss: 0.1956 - val_accuracy: 0.9310\n",
            "Epoch 56/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1874 - accuracy: 0.9359 - val_loss: 0.1396 - val_accuracy: 0.9310\n",
            "Epoch 57/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2725 - accuracy: 0.8910 - val_loss: 0.2933 - val_accuracy: 0.8966\n",
            "Epoch 58/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2344 - accuracy: 0.9145 - val_loss: 0.2758 - val_accuracy: 0.8621\n",
            "Epoch 59/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1743 - accuracy: 0.9380 - val_loss: 0.1548 - val_accuracy: 0.9310\n",
            "Epoch 60/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2322 - accuracy: 0.9017 - val_loss: 0.1559 - val_accuracy: 0.9655\n",
            "Epoch 61/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1881 - accuracy: 0.9338 - val_loss: 0.2180 - val_accuracy: 0.8621\n",
            "Epoch 62/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.1938 - accuracy: 0.9274 - val_loss: 0.2909 - val_accuracy: 0.8621\n",
            "Epoch 63/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2024 - accuracy: 0.9231 - val_loss: 0.2538 - val_accuracy: 0.8276\n",
            "Epoch 64/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1791 - accuracy: 0.9274 - val_loss: 0.1253 - val_accuracy: 0.9655\n",
            "Epoch 65/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.1690 - accuracy: 0.9402 - val_loss: 0.3660 - val_accuracy: 0.7586\n",
            "Epoch 66/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2128 - accuracy: 0.9188 - val_loss: 0.4254 - val_accuracy: 0.7931\n",
            "Epoch 67/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1955 - accuracy: 0.9188 - val_loss: 0.1336 - val_accuracy: 0.9310\n",
            "Epoch 68/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1926 - accuracy: 0.9338 - val_loss: 0.1677 - val_accuracy: 0.9310\n",
            "Epoch 69/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2896 - accuracy: 0.8782 - val_loss: 0.2216 - val_accuracy: 0.8966\n",
            "Epoch 70/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2591 - accuracy: 0.8846 - val_loss: 0.1976 - val_accuracy: 0.8966\n",
            "Epoch 71/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1781 - accuracy: 0.9338 - val_loss: 0.2670 - val_accuracy: 0.9310\n",
            "Epoch 72/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2021 - accuracy: 0.9231 - val_loss: 0.1905 - val_accuracy: 0.9310\n",
            "Epoch 73/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1590 - accuracy: 0.9380 - val_loss: 0.1924 - val_accuracy: 0.8966\n",
            "Epoch 74/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1569 - accuracy: 0.9295 - val_loss: 0.2206 - val_accuracy: 0.9310\n",
            "Epoch 1/100\n",
            "30/30 [==============================] - 2s 14ms/step - loss: 2.9512 - accuracy: 0.3718 - val_loss: 1.2195 - val_accuracy: 0.3103\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 1.0898 - accuracy: 0.4081 - val_loss: 1.0147 - val_accuracy: 0.5172\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.8254 - accuracy: 0.6132 - val_loss: 0.9445 - val_accuracy: 0.5517\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.6261 - accuracy: 0.6880 - val_loss: 0.5806 - val_accuracy: 0.6897\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.6592 - accuracy: 0.6688 - val_loss: 0.5841 - val_accuracy: 0.7241\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.5769 - accuracy: 0.7201 - val_loss: 0.5252 - val_accuracy: 0.7241\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.4472 - accuracy: 0.8034 - val_loss: 0.4536 - val_accuracy: 0.7586\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3957 - accuracy: 0.8034 - val_loss: 0.4549 - val_accuracy: 0.7586\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4436 - accuracy: 0.8269 - val_loss: 0.3883 - val_accuracy: 0.7586\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3641 - accuracy: 0.8419 - val_loss: 0.3482 - val_accuracy: 0.8276\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.4797 - accuracy: 0.7863 - val_loss: 0.6569 - val_accuracy: 0.6207\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.5323 - accuracy: 0.7286 - val_loss: 0.4119 - val_accuracy: 0.7241\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3791 - accuracy: 0.8269 - val_loss: 0.3768 - val_accuracy: 0.7586\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3268 - accuracy: 0.8462 - val_loss: 0.3104 - val_accuracy: 0.7931\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2909 - accuracy: 0.8846 - val_loss: 0.3146 - val_accuracy: 0.7931\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2772 - accuracy: 0.8782 - val_loss: 0.2801 - val_accuracy: 0.8276\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.4380 - accuracy: 0.8184 - val_loss: 0.5778 - val_accuracy: 0.6552\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3926 - accuracy: 0.8184 - val_loss: 0.3560 - val_accuracy: 0.7931\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2798 - accuracy: 0.8910 - val_loss: 0.3739 - val_accuracy: 0.8276\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2908 - accuracy: 0.8910 - val_loss: 0.5175 - val_accuracy: 0.6207\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2991 - accuracy: 0.8782 - val_loss: 0.3097 - val_accuracy: 0.8276\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2499 - accuracy: 0.8889 - val_loss: 0.3375 - val_accuracy: 0.8621\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3299 - accuracy: 0.8504 - val_loss: 0.2743 - val_accuracy: 0.7931\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2599 - accuracy: 0.9081 - val_loss: 0.5035 - val_accuracy: 0.7931\n",
            "Epoch 25/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2581 - accuracy: 0.8953 - val_loss: 0.3118 - val_accuracy: 0.8621\n",
            "Epoch 26/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2273 - accuracy: 0.9081 - val_loss: 0.4483 - val_accuracy: 0.7931\n",
            "Epoch 27/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2396 - accuracy: 0.9124 - val_loss: 0.2206 - val_accuracy: 0.8621\n",
            "Epoch 28/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.2449 - accuracy: 0.9231 - val_loss: 0.2849 - val_accuracy: 0.7931\n",
            "Epoch 29/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2214 - accuracy: 0.9167 - val_loss: 0.2261 - val_accuracy: 0.8276\n",
            "Epoch 30/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2065 - accuracy: 0.9188 - val_loss: 0.2060 - val_accuracy: 0.9310\n",
            "Epoch 31/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2818 - accuracy: 0.8739 - val_loss: 0.4317 - val_accuracy: 0.7586\n",
            "Epoch 32/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2533 - accuracy: 0.8953 - val_loss: 0.3457 - val_accuracy: 0.7586\n",
            "Epoch 33/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2703 - accuracy: 0.8910 - val_loss: 0.2145 - val_accuracy: 0.8621\n",
            "Epoch 34/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2517 - accuracy: 0.9017 - val_loss: 0.2389 - val_accuracy: 0.8966\n",
            "Epoch 35/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2120 - accuracy: 0.9295 - val_loss: 0.4602 - val_accuracy: 0.7586\n",
            "Epoch 36/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2004 - accuracy: 0.9274 - val_loss: 0.1783 - val_accuracy: 0.9310\n",
            "Epoch 37/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2247 - accuracy: 0.9274 - val_loss: 0.2009 - val_accuracy: 0.8966\n",
            "Epoch 38/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2640 - accuracy: 0.8782 - val_loss: 0.2464 - val_accuracy: 0.8966\n",
            "Epoch 39/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2715 - accuracy: 0.9017 - val_loss: 0.2753 - val_accuracy: 0.8621\n",
            "Epoch 40/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2043 - accuracy: 0.9252 - val_loss: 0.2205 - val_accuracy: 0.8966\n",
            "Epoch 41/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2638 - accuracy: 0.8846 - val_loss: 0.3502 - val_accuracy: 0.7931\n",
            "Epoch 42/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1821 - accuracy: 0.9338 - val_loss: 0.1843 - val_accuracy: 0.9310\n",
            "Epoch 43/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2006 - accuracy: 0.9252 - val_loss: 0.1543 - val_accuracy: 0.9655\n",
            "Epoch 44/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.2154 - accuracy: 0.9060 - val_loss: 0.1404 - val_accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1677 - accuracy: 0.9551 - val_loss: 0.2218 - val_accuracy: 0.8276\n",
            "Epoch 46/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2202 - accuracy: 0.9124 - val_loss: 0.1586 - val_accuracy: 0.9655\n",
            "Epoch 47/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2062 - accuracy: 0.9252 - val_loss: 0.2870 - val_accuracy: 0.8621\n",
            "Epoch 48/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1509 - accuracy: 0.9551 - val_loss: 0.1347 - val_accuracy: 0.9310\n",
            "Epoch 49/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1635 - accuracy: 0.9295 - val_loss: 0.2981 - val_accuracy: 0.7931\n",
            "Epoch 50/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2091 - accuracy: 0.9167 - val_loss: 0.1642 - val_accuracy: 0.9655\n",
            "Epoch 51/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1189 - accuracy: 0.9637 - val_loss: 0.1507 - val_accuracy: 0.9655\n",
            "Epoch 52/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1428 - accuracy: 0.9530 - val_loss: 0.1045 - val_accuracy: 0.9655\n",
            "Epoch 53/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.1297 - accuracy: 0.9594 - val_loss: 0.1692 - val_accuracy: 0.9310\n",
            "Epoch 54/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1893 - accuracy: 0.9252 - val_loss: 0.2015 - val_accuracy: 0.8966\n",
            "Epoch 55/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2024 - accuracy: 0.9338 - val_loss: 0.1314 - val_accuracy: 0.9655\n",
            "Epoch 56/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1711 - accuracy: 0.9402 - val_loss: 0.3271 - val_accuracy: 0.8276\n",
            "Epoch 57/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2113 - accuracy: 0.9124 - val_loss: 0.1349 - val_accuracy: 0.9655\n",
            "Epoch 58/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.1502 - accuracy: 0.9423 - val_loss: 0.4307 - val_accuracy: 0.7586\n",
            "Epoch 59/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2464 - accuracy: 0.8868 - val_loss: 0.3141 - val_accuracy: 0.8276\n",
            "Epoch 60/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2304 - accuracy: 0.9188 - val_loss: 0.2936 - val_accuracy: 0.8966\n",
            "Epoch 61/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2234 - accuracy: 0.9038 - val_loss: 0.3043 - val_accuracy: 0.8621\n",
            "Epoch 62/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2708 - accuracy: 0.8803 - val_loss: 0.1952 - val_accuracy: 0.9310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_1=model_1.predict(X_test, batch_size=None)\n",
        "predictions_2=model_2.predict(X_test, batch_size=None)\n",
        "predictions_3=model_3.predict(X_test, batch_size=None)"
      ],
      "metadata": {
        "id": "-q6Xu1FbG6Rp"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_1=model_1.predict(X_train, batch_size=None)\n",
        "predictions_2=model_2.predict(X_train, batch_size=None)\n",
        "predictions_3=model_3.predict(X_train, batch_size=None)"
      ],
      "metadata": {
        "id": "4BFVPEMdqQxp"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_1=np.argmax(predictions_1, axis = 1)\n",
        "label_2=np.argmax(predictions_2, axis = 1)\n",
        "label_3=np.argmax(predictions_3, axis = 1)"
      ],
      "metadata": {
        "id": "1n6roOcbAoyl"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing = pd.DataFrame()\n",
        "testing['Stability'] = y_train\n",
        "testing['Pred_Stability_1'] = label_1\n",
        "testing['Pred_Stability_2'] = label_2\n",
        "testing['Pred_Stability_3'] = label_3"
      ],
      "metadata": {
        "id": "JhHcv2YGG6Rq"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing['final_prediction'] = testing.mode(axis=1)[0]\n",
        "testing['final_prediction'] = testing['final_prediction'].astype(\"int64\")"
      ],
      "metadata": {
        "id": "DnqytMXqIIrF"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing.tail()"
      ],
      "metadata": {
        "id": "u6JERI-3I-v-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "4c0b8f8f-850d-4f68-a0b0-bfe2dc053226"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Stability  Pred_Stability_1  Pred_Stability_2  Pred_Stability_3  \\\n",
              "83          0                 0                 0                 0   \n",
              "84          1                 2                 1                 1   \n",
              "85          2                 2                 2                 1   \n",
              "86          1                 1                 1                 1   \n",
              "87          0                 0                 0                 0   \n",
              "\n",
              "    final_prediction  \n",
              "83                 0  \n",
              "84                 1  \n",
              "85                 2  \n",
              "86                 1  \n",
              "87                 0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f2aca3e-846e-4efc-b901-c00c185f7dc0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Stability</th>\n",
              "      <th>Pred_Stability_1</th>\n",
              "      <th>Pred_Stability_2</th>\n",
              "      <th>Pred_Stability_3</th>\n",
              "      <th>final_prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f2aca3e-846e-4efc-b901-c00c185f7dc0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4f2aca3e-846e-4efc-b901-c00c185f7dc0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4f2aca3e-846e-4efc-b901-c00c185f7dc0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(testing['Stability'].values, testing['final_prediction'].values, zero_division=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSfsXHkSJHlz",
        "outputId": "b4800967-226b-40cb-b05e-fce9dc2233f2"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00       153\n",
            "           1       1.00      0.94      0.97       153\n",
            "           2       0.94      1.00      0.97       162\n",
            "\n",
            "    accuracy                           0.98       468\n",
            "   macro avg       0.98      0.98      0.98       468\n",
            "weighted avg       0.98      0.98      0.98       468\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ensemble Learning (3 Linear)"
      ],
      "metadata": {
        "id": "eD6t28-iMtQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(512, input_shape=[4],activation=tf.keras.activations.linear),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.linear),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.linear),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.keras.activations.linear),\n",
        "                                    tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
        "                                    ])\n",
        "model_2 = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(512, input_shape=[4],activation=tf.keras.activations.linear),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.linear),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.linear),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.keras.activations.linear),\n",
        "                                    tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
        "                                    ])\n",
        "model_3 = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(512, input_shape=[4],activation=tf.keras.activations.linear),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.linear),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.linear),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.keras.activations.linear),\n",
        "                                    tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
        "                                    ])\n",
        "model_1.compile(loss=SparseCategoricalCrossentropy(from_logits=False),optimizer=adam,metrics=['accuracy'])\n",
        "model_2.compile(loss=SparseCategoricalCrossentropy(from_logits=False),optimizer=adam,metrics=['accuracy'])\n",
        "model_3.compile(loss=SparseCategoricalCrossentropy(from_logits=False),optimizer=adam,metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "qlWis8vaMtQN"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_1 = model_1.fit(X_train, y_train,batch_size=16,epochs=100,verbose=1,callbacks=callback)\n",
        "history_2 = model_2.fit(X_train, y_train,batch_size=16,epochs=100,verbose=1,callbacks=callback)\n",
        "history_3 = model_3.fit(X_train, y_train,batch_size=16,epochs=100,verbose=1,callbacks=callback)"
      ],
      "metadata": {
        "id": "Z-sxR--4yIdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_1 = model_1.fit(X_train, y_train,validation_data=(X_valid, y_valid),batch_size=16,epochs=100,verbose=1,callbacks=callback)\n",
        "history_2 = model_2.fit(X_train, y_train,validation_data=(X_valid, y_valid),batch_size=16,epochs=100,verbose=1,callbacks=callback)\n",
        "history_3 = model_3.fit(X_train, y_train,validation_data=(X_valid, y_valid),batch_size=16,epochs=100,verbose=1,callbacks=callback)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqYmYBSPyIdx",
        "outputId": "c32a785e-8129-41ec-ccde-41cadf5f12e1"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "26/26 [==============================] - 1s 16ms/step - loss: 42.2122 - accuracy: 0.3203 - val_loss: 4.1199 - val_accuracy: 0.4432\n",
            "Epoch 2/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2.9443 - accuracy: 0.3814 - val_loss: 0.9000 - val_accuracy: 0.6818\n",
            "Epoch 3/100\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.7895 - accuracy: 0.6210 - val_loss: 0.8038 - val_accuracy: 0.6250\n",
            "Epoch 4/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.6598 - accuracy: 0.6895 - val_loss: 0.5782 - val_accuracy: 0.7386\n",
            "Epoch 5/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.6369 - accuracy: 0.7017 - val_loss: 0.5641 - val_accuracy: 0.7159\n",
            "Epoch 6/100\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.5711 - accuracy: 0.7457 - val_loss: 0.5533 - val_accuracy: 0.7841\n",
            "Epoch 7/100\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.5572 - accuracy: 0.7604 - val_loss: 0.5038 - val_accuracy: 0.8068\n",
            "Epoch 8/100\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.5524 - accuracy: 0.7604 - val_loss: 0.5736 - val_accuracy: 0.7500\n",
            "Epoch 9/100\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.5596 - accuracy: 0.7335 - val_loss: 0.6739 - val_accuracy: 0.7045\n",
            "Epoch 10/100\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.5410 - accuracy: 0.7408 - val_loss: 0.5312 - val_accuracy: 0.8182\n",
            "Epoch 11/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.5629 - accuracy: 0.7408 - val_loss: 0.6112 - val_accuracy: 0.6591\n",
            "Epoch 12/100\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.5577 - accuracy: 0.7457 - val_loss: 0.5103 - val_accuracy: 0.8068\n",
            "Epoch 13/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.6341 - accuracy: 0.7237 - val_loss: 0.5287 - val_accuracy: 0.7614\n",
            "Epoch 14/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.5313 - accuracy: 0.7628 - val_loss: 0.6314 - val_accuracy: 0.7159\n",
            "Epoch 15/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.5135 - accuracy: 0.7555 - val_loss: 0.5336 - val_accuracy: 0.7614\n",
            "Epoch 16/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.5819 - accuracy: 0.7213 - val_loss: 0.6002 - val_accuracy: 0.6932\n",
            "Epoch 17/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.5890 - accuracy: 0.7066 - val_loss: 0.6899 - val_accuracy: 0.6477\n",
            "Epoch 1/100\n",
            "26/26 [==============================] - 1s 13ms/step - loss: 59.3120 - accuracy: 0.3594 - val_loss: 10.4282 - val_accuracy: 0.4545\n",
            "Epoch 2/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 4.4374 - accuracy: 0.4621 - val_loss: 0.8902 - val_accuracy: 0.6136\n",
            "Epoch 3/100\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.9903 - accuracy: 0.6112 - val_loss: 0.9725 - val_accuracy: 0.6023\n",
            "Epoch 4/100\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.7106 - accuracy: 0.6650 - val_loss: 0.6521 - val_accuracy: 0.7955\n",
            "Epoch 5/100\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.7051 - accuracy: 0.6797 - val_loss: 0.5666 - val_accuracy: 0.7614\n",
            "Epoch 6/100\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.6792 - accuracy: 0.6699 - val_loss: 0.7851 - val_accuracy: 0.6023\n",
            "Epoch 7/100\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.5827 - accuracy: 0.7359 - val_loss: 0.5422 - val_accuracy: 0.7614\n",
            "Epoch 8/100\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.5859 - accuracy: 0.7359 - val_loss: 0.5258 - val_accuracy: 0.7841\n",
            "Epoch 9/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.5700 - accuracy: 0.7115 - val_loss: 0.6070 - val_accuracy: 0.7273\n",
            "Epoch 10/100\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.5523 - accuracy: 0.7408 - val_loss: 0.5295 - val_accuracy: 0.7727\n",
            "Epoch 11/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.5651 - accuracy: 0.7531 - val_loss: 0.5734 - val_accuracy: 0.7386\n",
            "Epoch 12/100\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.5676 - accuracy: 0.7311 - val_loss: 0.5608 - val_accuracy: 0.7273\n",
            "Epoch 13/100\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.6796 - accuracy: 0.6919 - val_loss: 0.5075 - val_accuracy: 0.8182\n",
            "Epoch 14/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.7064 - accuracy: 0.6675 - val_loss: 0.6106 - val_accuracy: 0.7045\n",
            "Epoch 15/100\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.5409 - accuracy: 0.7311 - val_loss: 0.5806 - val_accuracy: 0.8182\n",
            "Epoch 16/100\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.5717 - accuracy: 0.7359 - val_loss: 0.5190 - val_accuracy: 0.7955\n",
            "Epoch 17/100\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.5785 - accuracy: 0.7335 - val_loss: 0.5573 - val_accuracy: 0.7045\n",
            "Epoch 18/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.5457 - accuracy: 0.7482 - val_loss: 0.6605 - val_accuracy: 0.6591\n",
            "Epoch 19/100\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.5867 - accuracy: 0.7384 - val_loss: 0.5610 - val_accuracy: 0.6818\n",
            "Epoch 20/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.5715 - accuracy: 0.7433 - val_loss: 0.4989 - val_accuracy: 0.8068\n",
            "Epoch 21/100\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.5518 - accuracy: 0.7408 - val_loss: 0.5474 - val_accuracy: 0.7614\n",
            "Epoch 22/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.5426 - accuracy: 0.7506 - val_loss: 0.7313 - val_accuracy: 0.6364\n",
            "Epoch 23/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.5520 - accuracy: 0.7408 - val_loss: 0.6064 - val_accuracy: 0.6818\n",
            "Epoch 24/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.6027 - accuracy: 0.7139 - val_loss: 0.6383 - val_accuracy: 0.7045\n",
            "Epoch 25/100\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.6331 - accuracy: 0.6919 - val_loss: 0.5943 - val_accuracy: 0.7045\n",
            "Epoch 26/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.5358 - accuracy: 0.7579 - val_loss: 0.5633 - val_accuracy: 0.7273\n",
            "Epoch 27/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.5189 - accuracy: 0.7384 - val_loss: 0.5942 - val_accuracy: 0.7500\n",
            "Epoch 28/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.5239 - accuracy: 0.7531 - val_loss: 0.7043 - val_accuracy: 0.6818\n",
            "Epoch 29/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.5530 - accuracy: 0.7531 - val_loss: 0.5582 - val_accuracy: 0.7045\n",
            "Epoch 30/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.5388 - accuracy: 0.7457 - val_loss: 0.6463 - val_accuracy: 0.6591\n",
            "Epoch 1/100\n",
            "26/26 [==============================] - 1s 13ms/step - loss: 58.8163 - accuracy: 0.3374 - val_loss: 14.3778 - val_accuracy: 0.2955\n",
            "Epoch 2/100\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 3.7858 - accuracy: 0.4377 - val_loss: 0.9705 - val_accuracy: 0.6364\n",
            "Epoch 3/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.8719 - accuracy: 0.6406 - val_loss: 0.7087 - val_accuracy: 0.6705\n",
            "Epoch 4/100\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.6712 - accuracy: 0.6870 - val_loss: 0.8431 - val_accuracy: 0.5114\n",
            "Epoch 5/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.6327 - accuracy: 0.7262 - val_loss: 0.9051 - val_accuracy: 0.5568\n",
            "Epoch 6/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.6405 - accuracy: 0.7017 - val_loss: 0.5910 - val_accuracy: 0.7386\n",
            "Epoch 7/100\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.5723 - accuracy: 0.7433 - val_loss: 0.5569 - val_accuracy: 0.7727\n",
            "Epoch 8/100\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.5611 - accuracy: 0.7384 - val_loss: 0.5763 - val_accuracy: 0.7386\n",
            "Epoch 9/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.5730 - accuracy: 0.7090 - val_loss: 0.6214 - val_accuracy: 0.7386\n",
            "Epoch 10/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.7311 - accuracy: 0.6553 - val_loss: 0.6536 - val_accuracy: 0.6818\n",
            "Epoch 11/100\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.6035 - accuracy: 0.7384 - val_loss: 0.5074 - val_accuracy: 0.8068\n",
            "Epoch 12/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.5972 - accuracy: 0.7262 - val_loss: 0.7639 - val_accuracy: 0.6705\n",
            "Epoch 13/100\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.6338 - accuracy: 0.7188 - val_loss: 0.6494 - val_accuracy: 0.6477\n",
            "Epoch 14/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.5502 - accuracy: 0.7262 - val_loss: 0.5114 - val_accuracy: 0.7955\n",
            "Epoch 15/100\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.6068 - accuracy: 0.7164 - val_loss: 0.5234 - val_accuracy: 0.8523\n",
            "Epoch 16/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.5585 - accuracy: 0.7482 - val_loss: 0.5117 - val_accuracy: 0.7614\n",
            "Epoch 17/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.5295 - accuracy: 0.7408 - val_loss: 0.5244 - val_accuracy: 0.8182\n",
            "Epoch 18/100\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.5597 - accuracy: 0.7213 - val_loss: 0.5176 - val_accuracy: 0.7841\n",
            "Epoch 19/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.5595 - accuracy: 0.7311 - val_loss: 0.5385 - val_accuracy: 0.7159\n",
            "Epoch 20/100\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.5747 - accuracy: 0.7311 - val_loss: 0.5618 - val_accuracy: 0.7841\n",
            "Epoch 21/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.6036 - accuracy: 0.7384 - val_loss: 0.4995 - val_accuracy: 0.7955\n",
            "Epoch 22/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.5215 - accuracy: 0.7628 - val_loss: 0.5319 - val_accuracy: 0.8182\n",
            "Epoch 23/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.5529 - accuracy: 0.7384 - val_loss: 0.6337 - val_accuracy: 0.6932\n",
            "Epoch 24/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.6161 - accuracy: 0.7311 - val_loss: 0.7086 - val_accuracy: 0.6818\n",
            "Epoch 25/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.5303 - accuracy: 0.7408 - val_loss: 0.6548 - val_accuracy: 0.7045\n",
            "Epoch 26/100\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.5292 - accuracy: 0.7433 - val_loss: 0.5357 - val_accuracy: 0.7614\n",
            "Epoch 27/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.5285 - accuracy: 0.7555 - val_loss: 0.5417 - val_accuracy: 0.7614\n",
            "Epoch 28/100\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.5229 - accuracy: 0.7384 - val_loss: 0.5496 - val_accuracy: 0.7386\n",
            "Epoch 29/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.5602 - accuracy: 0.7384 - val_loss: 0.5015 - val_accuracy: 0.8068\n",
            "Epoch 30/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.5421 - accuracy: 0.7555 - val_loss: 0.7741 - val_accuracy: 0.7159\n",
            "Epoch 31/100\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.7114 - accuracy: 0.6577 - val_loss: 0.7189 - val_accuracy: 0.7386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_1=model_1.predict(X_test, batch_size=None)\n",
        "predictions_2=model_2.predict(X_test, batch_size=None)\n",
        "predictions_3=model_3.predict(X_test, batch_size=None)"
      ],
      "metadata": {
        "id": "pGWFg_D5MtQO"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_1=model_1.predict(X_train, batch_size=None)\n",
        "predictions_2=model_2.predict(X_train, batch_size=None)\n",
        "predictions_3=model_3.predict(X_train, batch_size=None)"
      ],
      "metadata": {
        "id": "ftAEXCqCqv_H"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_1=np.argmax(predictions_1, axis = 1)\n",
        "label_2=np.argmax(predictions_2, axis = 1)\n",
        "label_3=np.argmax(predictions_3, axis = 1)"
      ],
      "metadata": {
        "id": "snFxdGEjDCI5"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing = pd.DataFrame()\n",
        "testing['Stability'] = y_train\n",
        "testing['Pred_Stability_1'] = label_1\n",
        "testing['Pred_Stability_2'] = label_2\n",
        "testing['Pred_Stability_3'] = label_3"
      ],
      "metadata": {
        "id": "VjdEud6UMtQP"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing['final_prediction'] = testing.mode(axis=1)[0]\n",
        "testing['final_prediction'] = testing['final_prediction'].astype(\"int64\")"
      ],
      "metadata": {
        "id": "DaPBQC0LMtQQ"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing.head()"
      ],
      "metadata": {
        "id": "uaf_tvyiMtQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(testing['Stability'].values, testing['final_prediction'].values, zero_division=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ac78bda-9b46-4f86-fa8f-f1acfd453e65",
        "id": "7YfQUdqSMtQQ"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.98      0.93       127\n",
            "           1       0.90      0.61      0.73       142\n",
            "           2       0.67      0.81      0.73       140\n",
            "\n",
            "    accuracy                           0.79       409\n",
            "   macro avg       0.81      0.80      0.80       409\n",
            "weighted avg       0.81      0.79      0.79       409\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ensemble Learning (3 ReLU)"
      ],
      "metadata": {
        "id": "QIova5ZnLkfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(512, input_shape=[4],activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
        "                                    ])\n",
        "model_2 = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(512, input_shape=[4],activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
        "                                    ])\n",
        "model_3 = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(512, input_shape=[4],activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
        "                                    ])\n",
        "model_1.compile(loss=SparseCategoricalCrossentropy(from_logits=False),optimizer=adam,metrics=['accuracy'])\n",
        "model_2.compile(loss=SparseCategoricalCrossentropy(from_logits=False),optimizer=adam,metrics=['accuracy'])\n",
        "model_3.compile(loss=SparseCategoricalCrossentropy(from_logits=False),optimizer=adam,metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Y424s4MlLkfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_1 = model_1.fit(X_train, y_train,batch_size=16,epochs=100,verbose=1,callbacks=callback)\n",
        "history_2 = model_2.fit(X_train, y_train,batch_size=16,epochs=100,verbose=1,callbacks=callback)\n",
        "history_3 = model_3.fit(X_train, y_train,batch_size=16,epochs=100,verbose=1,callbacks=callback)"
      ],
      "metadata": {
        "id": "uAa48xkMyrf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_1 = model_1.fit(X_train, y_train,validation_data=(X_valid, y_valid),batch_size=16,epochs=100,verbose=1,callbacks=callback)\n",
        "history_2 = model_2.fit(X_train, y_train,validation_data=(X_valid, y_valid),batch_size=16,epochs=100,verbose=1,callbacks=callback)\n",
        "history_3 = model_3.fit(X_train, y_train,validation_data=(X_valid, y_valid),batch_size=16,epochs=100,verbose=1,callbacks=callback)"
      ],
      "metadata": {
        "id": "8p-JS-xByrf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_1=model_1.predict(X_test, batch_size=None)\n",
        "predictions_2=model_2.predict(X_test, batch_size=None)\n",
        "predictions_3=model_3.predict(X_test, batch_size=None)"
      ],
      "metadata": {
        "id": "6OuuSezELkfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_1=model_1.predict(X_train, batch_size=None)\n",
        "predictions_2=model_2.predict(X_train, batch_size=None)\n",
        "predictions_3=model_3.predict(X_train, batch_size=None)"
      ],
      "metadata": {
        "id": "deycHWJHrkKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_1=[]\n",
        "for i in range(len(predictions_1)):\n",
        "  if predictions_1[i][0]>0.5:\n",
        "    label_1.append(1)\n",
        "  else:\n",
        "    label_1.append(0)"
      ],
      "metadata": {
        "id": "Z_jQxlW8Lkfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_2=[]\n",
        "for i in range(len(predictions_2)):\n",
        "  if predictions_2[i][0]>0.5:\n",
        "    label_2.append(1)\n",
        "  else:\n",
        "    label_2.append(0)"
      ],
      "metadata": {
        "id": "WpalJES8Lkfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_3=[]\n",
        "for i in range(len(predictions_3)):\n",
        "  if predictions_3[i][0]>0.5:\n",
        "    label_3.append(1)\n",
        "  else:\n",
        "    label_3.append(0)"
      ],
      "metadata": {
        "id": "JxZx4U8WLkfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing = pd.DataFrame()\n",
        "testing['Stability'] = y_train\n",
        "testing['Pred_Stability_1'] = label_1\n",
        "testing['Pred_Stability_2'] = label_2\n",
        "testing['Pred_Stability_3'] = label_3"
      ],
      "metadata": {
        "id": "iiMu6iMELkfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing['final_prediction'] = testing.mode(axis=1)[0]\n",
        "testing['final_prediction'] = testing['final_prediction'].astype(\"int64\")"
      ],
      "metadata": {
        "id": "ZzpQmjaNLkfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing.head()"
      ],
      "metadata": {
        "id": "NJn9rxEuLkfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(testing['Stability'].values, testing['final_prediction'].values, zero_division=1))"
      ],
      "metadata": {
        "id": "EqnwkSGqLkfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ensemble Learning (3 ELU)"
      ],
      "metadata": {
        "id": "Oe_XU7ZJMQZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(512, input_shape=[4],activation=tf.keras.activations.elu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.elu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.elu),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.keras.activations.elu),\n",
        "                                    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
        "                                    ])\n",
        "model_2 = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(512, input_shape=[4],activation=tf.keras.activations.elu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.elu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.elu),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.keras.activations.elu),\n",
        "                                    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
        "                                    ])\n",
        "model_3 = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(512, input_shape=[4],activation=tf.keras.activations.elu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.elu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.elu),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.keras.activations.elu),\n",
        "                                    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
        "                                    ])\n",
        "model_1.compile(loss=\"binary_crossentropy\",optimizer=adam,metrics=['accuracy'])\n",
        "model_2.compile(loss=\"binary_crossentropy\",optimizer=adam,metrics=['accuracy'])\n",
        "model_3.compile(loss=\"binary_crossentropy\",optimizer=adam,metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "N2TAkcqrMQZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_1 = model_1.fit(X_train, y_train,batch_size=16,epochs=100,verbose=1,callbacks=callback)\n",
        "history_2 = model_2.fit(X_train, y_train,batch_size=16,epochs=100,verbose=1,callbacks=callback)\n",
        "history_3 = model_3.fit(X_train, y_train,batch_size=16,epochs=100,verbose=1,callbacks=callback)"
      ],
      "metadata": {
        "id": "_zaxDTBSziX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_1 = model_1.fit(X_train, y_train,validation_data=(X_valid, y_valid),batch_size=16,epochs=100,verbose=1,callbacks=callback)\n",
        "history_2 = model_2.fit(X_train, y_train,validation_data=(X_valid, y_valid),batch_size=16,epochs=100,verbose=1,callbacks=callback)\n",
        "history_3 = model_3.fit(X_train, y_train,validation_data=(X_valid, y_valid),batch_size=16,epochs=100,verbose=1,callbacks=callback)"
      ],
      "metadata": {
        "id": "Ei20dNNnziX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_1=model_1.predict(X_test, batch_size=None)\n",
        "predictions_2=model_2.predict(X_test, batch_size=None)\n",
        "predictions_3=model_3.predict(X_test, batch_size=None)"
      ],
      "metadata": {
        "id": "serxJrLPMQZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_1=model_1.predict(X_train, batch_size=None)\n",
        "predictions_2=model_2.predict(X_train, batch_size=None)\n",
        "predictions_3=model_3.predict(X_train, batch_size=None)"
      ],
      "metadata": {
        "id": "_QSYSzSRr_Fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_1=[]\n",
        "for i in range(len(predictions_1)):\n",
        "  if predictions_1[i][0]>0.5:\n",
        "    label_1.append(1)\n",
        "  else:\n",
        "    label_1.append(0)"
      ],
      "metadata": {
        "id": "z2ONbqipMQZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_2=[]\n",
        "for i in range(len(predictions_2)):\n",
        "  if predictions_2[i][0]>0.5:\n",
        "    label_2.append(1)\n",
        "  else:\n",
        "    label_2.append(0)"
      ],
      "metadata": {
        "id": "3CHet58mMQZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_3=[]\n",
        "for i in range(len(predictions_3)):\n",
        "  if predictions_3[i][0]>0.5:\n",
        "    label_3.append(1)\n",
        "  else:\n",
        "    label_3.append(0)"
      ],
      "metadata": {
        "id": "4d21BEjhMQZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing = pd.DataFrame()\n",
        "testing['Stability'] = y_train\n",
        "testing['Pred_Stability_1'] = label_1\n",
        "testing['Pred_Stability_2'] = label_2\n",
        "testing['Pred_Stability_3'] = label_3"
      ],
      "metadata": {
        "id": "fcHOUbL-MQZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing['final_prediction'] = testing.mode(axis=1)[0]\n",
        "testing['final_prediction'] = testing['final_prediction'].astype(\"int64\")"
      ],
      "metadata": {
        "id": "iXLQvftzMQZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing.head()"
      ],
      "metadata": {
        "id": "3JLnQ_kkMQZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(testing['Stability'].values, testing['final_prediction'].values, zero_division=1))"
      ],
      "metadata": {
        "id": "L0X7YVSjMQZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ensemble Learning (3 GELU)"
      ],
      "metadata": {
        "id": "Ehj_Y0-XKlxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(512, input_shape=[4],activation=tf.keras.activations.gelu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.gelu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.gelu),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.keras.activations.gelu),\n",
        "                                    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
        "                                    ])\n",
        "model_2 = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(512, input_shape=[4],activation=tf.keras.activations.gelu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.gelu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.gelu),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.keras.activations.gelu),\n",
        "                                    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
        "                                    ])\n",
        "model_3 = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(512, input_shape=[4],activation=tf.keras.activations.gelu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.gelu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.keras.activations.gelu),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.keras.activations.gelu),\n",
        "                                    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
        "                                    ])\n",
        "model_1.compile(loss=\"binary_crossentropy\",optimizer=adam,metrics=['accuracy'])\n",
        "model_2.compile(loss=\"binary_crossentropy\",optimizer=adam,metrics=['accuracy'])\n",
        "model_3.compile(loss=\"binary_crossentropy\",optimizer=adam,metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "F8ioikeCKvYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_1 = model_1.fit(X_train, y_train,batch_size=16,epochs=100,verbose=1,callbacks=callback)\n",
        "history_2 = model_2.fit(X_train, y_train,batch_size=16,epochs=100,verbose=1,callbacks=callback)\n",
        "history_3 = model_3.fit(X_train, y_train,batch_size=16,epochs=100,verbose=1,callbacks=callback)"
      ],
      "metadata": {
        "id": "d3kVEk-L0DjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_1 = model_1.fit(X_train, y_train,validation_data=(X_valid, y_valid),batch_size=16,epochs=100,verbose=1,callbacks=callback)\n",
        "history_2 = model_2.fit(X_train, y_train,validation_data=(X_valid, y_valid),batch_size=16,epochs=100,verbose=1,callbacks=callback)\n",
        "history_3 = model_3.fit(X_train, y_train,validation_data=(X_valid, y_valid),batch_size=16,epochs=100,verbose=1,callbacks=callback)"
      ],
      "metadata": {
        "id": "QS0yJBpO0DjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_1=model_1.predict(X_test, batch_size=None)\n",
        "predictions_2=model_2.predict(X_test, batch_size=None)\n",
        "predictions_3=model_3.predict(X_test, batch_size=None)"
      ],
      "metadata": {
        "id": "V4sgzMo4KvYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_1=model_1.predict(X_train, batch_size=None)\n",
        "predictions_2=model_2.predict(X_train, batch_size=None)\n",
        "predictions_3=model_3.predict(X_train, batch_size=None)"
      ],
      "metadata": {
        "id": "RnacVMGRsUPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_1=[]\n",
        "for i in range(len(predictions_1)):\n",
        "  if predictions_1[i][0]>0.5:\n",
        "    label_1.append(1)\n",
        "  else:\n",
        "    label_1.append(0)"
      ],
      "metadata": {
        "id": "MNRFk4bsKvYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_2=[]\n",
        "for i in range(len(predictions_2)):\n",
        "  if predictions_2[i][0]>0.5:\n",
        "    label_2.append(1)\n",
        "  else:\n",
        "    label_2.append(0)"
      ],
      "metadata": {
        "id": "8BWb-yevKvYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_3=[]\n",
        "for i in range(len(predictions_3)):\n",
        "  if predictions_3[i][0]>0.5:\n",
        "    label_3.append(1)\n",
        "  else:\n",
        "    label_3.append(0)"
      ],
      "metadata": {
        "id": "mLpf1WD6KvYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing = pd.DataFrame()\n",
        "testing['Stability'] = y_train\n",
        "testing['Pred_Stability_1'] = label_1\n",
        "testing['Pred_Stability_2'] = label_2\n",
        "testing['Pred_Stability_3'] = label_3"
      ],
      "metadata": {
        "id": "Q30GZXNXKvYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing['final_prediction'] = testing.mode(axis=1)[0]\n",
        "testing['final_prediction'] = testing['final_prediction'].astype(\"int64\")"
      ],
      "metadata": {
        "id": "ynzyxTB0KvYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing.head()"
      ],
      "metadata": {
        "id": "h8x0jz2GKvYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(testing['Stability'].values, testing['final_prediction'].values, zero_division=1))"
      ],
      "metadata": {
        "id": "mXe6M-wbKvYa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}